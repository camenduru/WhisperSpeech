<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>WhisperSpeech - Text to semantic tokens model</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


<link rel="stylesheet" href="styles.css">
<meta property="og:title" content="WhisperSpeech - Text to semantic tokens model">
<meta property="og:description" content="">
<meta property="og:image" content="https://collabora.github.io/WhisperSpeech/5B. Text to semantic token modeling_files/figure-html/cell-13-output-4.png">
<meta property="og:site-name" content="WhisperSpeech">
<meta property="og:image:height" content="486">
<meta property="og:image:width" content="853">
<meta name="twitter:title" content="WhisperSpeech - Text to semantic tokens model">
<meta name="twitter:description" content="">
<meta name="twitter:image" content="https://collabora.github.io/WhisperSpeech/5B. Text to semantic token modeling_files/figure-html/cell-13-output-4.png">
<meta name="twitter:image-height" content="486">
<meta name="twitter:image-width" content="853">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a href="./index.html" class="navbar-brand navbar-brand-logo">
    <img src="./logo.svg" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">WhisperSpeech</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/collabora/WhisperSpeech" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item">Text to semantic tokens model</li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">WhisperSpeech</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./dataset preparation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">I can has speech? What data WhisperSpeech needs?</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#dataset" id="toc-dataset" class="nav-link active" data-scroll-target="#dataset">Dataset</a>
  <ul>
  <li><a href="#load_datasets" id="toc-load_datasets" class="nav-link" data-scroll-target="#load_datasets">load_datasets</a></li>
  </ul></li>
  <li><a href="#modeling" id="toc-modeling" class="nav-link" data-scroll-target="#modeling">Modeling</a>
  <ul>
  <li><a href="#tunables" id="toc-tunables" class="nav-link" data-scroll-target="#tunables">Tunables</a></li>
  <li><a href="#rand" id="toc-rand" class="nav-link" data-scroll-target="#rand">rand</a></li>
  <li><a href="#encoder" id="toc-encoder" class="nav-link" data-scroll-target="#encoder">Encoder</a></li>
  <li><a href="#decoder" id="toc-decoder" class="nav-link" data-scroll-target="#decoder">Decoder</a></li>
  <li><a href="#tsartransformer" id="toc-tsartransformer" class="nav-link" data-scroll-target="#tsartransformer">TSARTransformer</a></li>
  <li><a href="#make_model" id="toc-make_model" class="nav-link" data-scroll-target="#make_model">make_model</a></li>
  <li><a href="#codebook-dim-and-vq-codes" id="toc-codebook-dim-and-vq-codes" class="nav-link" data-scroll-target="#codebook-dim-and-vq-codes">Codebook dim and VQ codes</a></li>
  <li><a href="#optimize-the-sampling-parameters" id="toc-optimize-the-sampling-parameters" class="nav-link" data-scroll-target="#optimize-the-sampling-parameters">Optimize the sampling parameters</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/collabora/WhisperSpeech/issues/new" class="toc-action">Report an issue</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Text to semantic tokens model</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> whisperspeech.wer_metrics <span class="im">import</span> <span class="op">*</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchaudio</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastprogress <span class="im">import</span> master_bar</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="dataset" class="level1">
<h1>Dataset</h1>
<hr>
<p><a href="https://github.com/collabora/WhisperSpeech/blob/master/whisperspeech/t2s_up_wds.py#L92" target="_blank" style="float:right; font-size:smaller">source</a></p>
<section id="load_datasets" class="level3">
<h3 class="anchored" data-anchor-id="load_datasets">load_datasets</h3>
<blockquote class="blockquote">
<pre><code> load_datasets (input:str, samples:int, subsample:float=1,
                val_samples:int=512, vq_codes:int=4096)</code></pre>
</blockquote>
<table class="table">
<thead>
<tr class="header">
<th></th>
<th><strong>Type</strong></th>
<th><strong>Default</strong></th>
<th><strong>Details</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>input</td>
<td>str</td>
<td></td>
<td>webdataset folder or shard list</td>
</tr>
<tr class="even">
<td>samples</td>
<td>int</td>
<td></td>
<td>samples per epoch</td>
</tr>
<tr class="odd">
<td>subsample</td>
<td>float</td>
<td>1</td>
<td>use a fraction of the files</td>
</tr>
<tr class="even">
<td>val_samples</td>
<td>int</td>
<td>512</td>
<td></td>
</tr>
<tr class="odd">
<td>vq_codes</td>
<td>int</td>
<td>4096</td>
<td></td>
</tr>
</tbody>
</table>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>train_ds, val_ds <span class="op">=</span> load_datasets(<span class="st">'t2s-6454/*.tar.gz'</span>, <span class="dv">67000</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> s <span class="kw">in</span> val_ds: <span class="cf">break</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>s</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>[tensor([[ 65,  32, 102,  ...,   0,   0,   0],
         [109, 101, 110,  ...,   0,   0,   0],
         [ 89, 101, 116,  ...,   0,   0,   0],
         ...,
         [ 66, 117, 116,  ...,   0,   0,   0],
         [ 66, 117, 116,  ...,   0,   0,   0],
         [ 70, 114, 111,  ...,   0,   0,   0]]),
 tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),
 array([14.75      , 12.22044728, 15.20618557, 14.76470588, 15.        ,
        14.85943775, 14.4       , 16.25      , 13.85714286, 17.17687075,
        16.36500754, 15.2       , 12.77372263, 13.84026258, 15.85      ,
        11.39705882, 16.33333333, 15.68877551, 13.64705882, 16.13729508,
        13.7245841 , 15.27272727, 14.46078431, 16.35294118, 17.15976331,
        15.09090909, 12.0625    , 14.52483801, 13.62645349, 13.20033956,
        14.23076923, 14.39130435, 14.85185185, 17.33333333, 15.35388128,
        15.2173913 , 14.94117647, 12.4375    , 15.26360544, 12.89808917,
        12.71459227, 16.84782609, 15.43348281, 14.6       , 14.42105263,
        16.        , 15.28571429, 13.94736842, 14.66666667, 13.10720268,
        12.58333333, 14.        , 12.76923077, 16.17100372, 14.3       ,
        15.27255639, 16.11111111, 15.17857143, 16.70168067,  7.9       ,
         8.85416667, 13.97058824, 14.38053097, 15.61111111]),
 tensor([[4095,  717, 3599,  ..., 4095, 4095, 4095],
         [4095, 1698, 1885,  ..., 4095, 4095, 4095],
         [4095, 1738, 2952,  ..., 4095, 4095, 4095],
         ...,
         [4095,   30,   30,  ..., 4095, 4095, 4095],
         [4095,  328, 1241,  ..., 4095, 4095, 4095],
         [4095, 1927, 1156,  ..., 4095, 4095, 4095]]),
 tensor([[ 717, 3599, 3998,  ..., 4095, 4095, 4095],
         [1698, 1885, 3930,  ..., 4095, 4095, 4095],
         [1738, 2952, 3344,  ..., 4095, 4095, 4095],
         ...,
         [  30,   30, 2863,  ..., 4095, 4095, 4095],
         [ 328, 1241,  777,  ..., 4095, 4095, 4095],
         [1927, 1156,  449,  ..., 4095, 4095, 4095]])]</code></pre>
</div>
</div>
</section>
</section>
<section id="modeling" class="level1">
<h1>Modeling</h1>
<hr>
<p><a href="https://github.com/collabora/WhisperSpeech/blob/master/whisperspeech/vq_stoks.py#L161" target="_blank" style="float:right; font-size:smaller">source</a></p>
<section id="tunables" class="level3">
<h3 class="anchored" data-anchor-id="tunables">Tunables</h3>
<blockquote class="blockquote">
<pre><code> Tunables (init_std:float=1, embeddings_std:float=0.01,
           embeddings_lr_scale:float=5,
           embedding_projector_lr_scale:float=2.5, output_mult:float=0.35,
           query_mult:float=1, encoder_depth_ratio:float=0.25,
           eot_dropout_p:float=0.5, cps_input:bool=True, cps_bins:int=32,
           lr0:float=0.0015, clip_gradient_norm:float=0.2,
           weight_decay:float=0.1, warmup_steps:float=4000,
           random:bool=False)</code></pre>
</blockquote>
<hr>
<p><a href="https://github.com/collabora/WhisperSpeech/blob/master/whisperspeech/vq_stoks.py#L154" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="rand" class="level3">
<h3 class="anchored" data-anchor-id="rand">rand</h3>
<blockquote class="blockquote">
<pre><code> rand (start, end)</code></pre>
</blockquote>
<hr>
<p><a href="https://github.com/collabora/WhisperSpeech/blob/master/whisperspeech/t2s_up_wds_mlang_enclm.py#L219" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="encoder" class="level3">
<h3 class="anchored" data-anchor-id="encoder">Encoder</h3>
<blockquote class="blockquote">
<pre><code> Encoder (depth=6, width=384, n_head=6, length=1500, codes=1024,
          emb_width=384, ffn_mult=4, pos_embs=None,
          tunables=Tunables(init_std=1, embeddings_std=0.01,
          embeddings_lr_scale=5, embedding_projector_lr_scale=2.5,
          output_mult=0.35, query_mult=1, encoder_depth_ratio=0.25,
          eot_dropout_p=0.5, cps_input=True, cps_bins=32, lr0=0.0015,
          clip_gradient_norm=0.2, weight_decay=0.1, warmup_steps=4000,
          random=False))</code></pre>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::</p>
<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))</code></pre>
<p>Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>.. note:: As per the example above, an <code>__init__()</code> call to the parent class must be made before assignment on the child.</p>
<p>:ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool</p>
<hr>
<p><a href="https://github.com/collabora/WhisperSpeech/blob/master/whisperspeech/t2s_up_wds_mlang_enclm.py#L249" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="decoder" class="level3">
<h3 class="anchored" data-anchor-id="decoder">Decoder</h3>
<blockquote class="blockquote">
<pre><code> Decoder (depth=6, stoks_width=384, width=384, n_head=6, length=1500,
          codes=1024, ffn_mult=4, pos_embs=None,
          tunables=Tunables(init_std=1, embeddings_std=0.01,
          embeddings_lr_scale=5, embedding_projector_lr_scale=2.5,
          output_mult=0.35, query_mult=1, encoder_depth_ratio=0.25,
          eot_dropout_p=0.5, cps_input=True, cps_bins=32, lr0=0.0015,
          clip_gradient_norm=0.2, weight_decay=0.1, warmup_steps=4000,
          random=False))</code></pre>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::</p>
<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))</code></pre>
<p>Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>.. note:: As per the example above, an <code>__init__()</code> call to the parent class must be made before assignment on the child.</p>
<p>:ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool</p>
<hr>
<p><a href="https://github.com/collabora/WhisperSpeech/blob/master/whisperspeech/t2s_up_wds_mlang_enclm.py#L286" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="tsartransformer" class="level3">
<h3 class="anchored" data-anchor-id="tsartransformer">TSARTransformer</h3>
<blockquote class="blockquote">
<pre><code> TSARTransformer (depth=6, n_head=6, head_width=64, ffn_mult=4,
                  language='en', ttoks_len=200, ttoks_codes=50364,
                  ttoks_width=None, stoks_len=1500, stoks_codes=1024,
                  stoks_width=None, tunables=Tunables(init_std=1,
                  embeddings_std=0.01, embeddings_lr_scale=5,
                  embedding_projector_lr_scale=2.5, output_mult=0.35,
                  query_mult=1, encoder_depth_ratio=0.25,
                  eot_dropout_p=0.5, cps_input=True, cps_bins=32,
                  lr0=0.0015, clip_gradient_norm=0.2, weight_decay=0.1,
                  warmup_steps=4000, random=False))</code></pre>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::</p>
<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))</code></pre>
<p>Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>.. note:: As per the example above, an <code>__init__()</code> call to the parent class must be made before assignment on the child.</p>
<p>:ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool</p>
<hr>
<p><a href="https://github.com/collabora/WhisperSpeech/blob/master/whisperspeech/vq_stoks.py#L457" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="make_model" class="level3">
<h3 class="anchored" data-anchor-id="make_model">make_model</h3>
<blockquote class="blockquote">
<pre><code> make_model (size:str, frozen_embeddings_model:str=None,
             tunables:__main__.Tunables=Tunables(init_std=1,
             embeddings_std=0.01, embeddings_lr_scale=5,
             embedding_projector_lr_scale=2.5, output_mult=0.35,
             query_mult=1, encoder_depth_ratio=0.25, eot_dropout_p=0.5,
             cps_input=True, cps_bins=32, lr0=0.0015,
             clip_gradient_norm=0.2, weight_decay=0.1, warmup_steps=4000,
             random=False), dataset:torch.utils.data.dataset.Dataset=None)</code></pre>
</blockquote>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># make sure it works at all</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>train_ds, val_ds <span class="op">=</span> load_datasets(<span class="st">'t2s-6454/*.tar.gz'</span>, <span class="dv">67000</span>)</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> make_model(<span class="st">'micro'</span>, dataset<span class="op">=</span>train_ds, ttoks_codes<span class="op">=</span><span class="dv">256</span>, tunables<span class="op">=</span>Tunables(weight_decay<span class="op">=</span><span class="fl">1e-3</span>, encoder_depth_ratio<span class="op">=</span><span class="fl">.5</span>)).cuda()</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>train(<span class="st">"tsar-wx"</span>, model, train_ds, val_ds, half<span class="op">=</span><span class="va">True</span>, bs<span class="op">=</span><span class="dv">64</span>, lr<span class="op">=</span>model.tunables.lr0, epochs<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>      warmup_steps<span class="op">=</span><span class="dv">1500</span>, weight_decay<span class="op">=</span>model.tunables.weight_decay, clip_gradient_norm<span class="op">=</span>model.tunables.clip_gradient_norm,</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>      table_row_every_iters<span class="op">=</span><span class="dv">50000</span>, run_valid_every_iters<span class="op">=</span><span class="dv">10000</span>)</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a><span class="co"># model.save_model('t2s-chr-micro-base.en-2d-4096c-cosine32-padfix-premlp-learnpos-5e-large-6454.model')</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="4" class="" max="4" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [4/4 04:19&lt;00:00]
    </div>
    

<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">samples</th>
<th data-quarto-table-cell-role="th">train</th>
<th data-quarto-table-cell-role="th">val</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>50048</td>
<td>2.32671</td>
<td>2.54252</td>
<td>00:49</td>
</tr>
<tr class="even">
<td>100032</td>
<td>1.80803</td>
<td>1.89586</td>
<td>01:37</td>
</tr>
<tr class="odd">
<td>150016</td>
<td>1.54782</td>
<td>1.59268</td>
<td>02:26</td>
</tr>
<tr class="even">
<td>200000</td>
<td>1.35583</td>
<td>1.46361</td>
<td>03:13</td>
</tr>
<tr class="odd">
<td>250048</td>
<td>1.41018</td>
<td>1.41785</td>
<td>04:02</td>
</tr>
<tr class="even">
<td>267776</td>
<td>1.34585</td>
<td>1.41379</td>
<td>04:19</td>
</tr>
</tbody>
</table>
<p>

    </p><div>
      <progress value="1046" class="" max="1046" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [1046/1046 01:03&lt;00:00 #66944/67000 loss: 1.346 / 1.414]
    </div>
    
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-13-output-4.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># make sure it works at all</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>train_ds, val_ds <span class="op">=</span> load_datasets(<span class="st">'t2s-6454/*.tar.gz'</span>, <span class="dv">67000</span>)</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> make_model(<span class="st">'micro'</span>, dataset<span class="op">=</span>train_ds, ttoks_codes<span class="op">=</span><span class="dv">256</span>, stoks_width<span class="op">=</span><span class="dv">32</span>, tunables<span class="op">=</span>Tunables(weight_decay<span class="op">=</span><span class="fl">1e-3</span>, encoder_depth_ratio<span class="op">=</span><span class="fl">.5</span>)).cuda()</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>train(<span class="st">"tsar-wx"</span>, model, train_ds, val_ds, half<span class="op">=</span><span class="va">True</span>, bs<span class="op">=</span><span class="dv">64</span>, lr<span class="op">=</span>model.tunables.lr0, epochs<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>      warmup_steps<span class="op">=</span><span class="dv">1500</span>, weight_decay<span class="op">=</span>model.tunables.weight_decay, clip_gradient_norm<span class="op">=</span>model.tunables.clip_gradient_norm,</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>      table_row_every_iters<span class="op">=</span><span class="dv">50000</span>, run_valid_every_iters<span class="op">=</span><span class="dv">10000</span>)</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="co"># model.save_model('t2s-chr-micro-base.en-2d-4096c-cosine32-padfix-premlp-learnpos-5e-large-6454.model')</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="4" class="" max="4" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [4/4 04:14&lt;00:00]
    </div>
    

<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">samples</th>
<th data-quarto-table-cell-role="th">train</th>
<th data-quarto-table-cell-role="th">val</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>50048</td>
<td>3.30265</td>
<td>3.83503</td>
<td>00:48</td>
</tr>
<tr class="even">
<td>100032</td>
<td>2.02446</td>
<td>2.18862</td>
<td>01:35</td>
</tr>
<tr class="odd">
<td>150016</td>
<td>2.05050</td>
<td>2.01388</td>
<td>02:22</td>
</tr>
<tr class="even">
<td>200000</td>
<td>1.93012</td>
<td>1.95299</td>
<td>03:09</td>
</tr>
<tr class="odd">
<td>250048</td>
<td>1.94291</td>
<td>1.92251</td>
<td>03:57</td>
</tr>
<tr class="even">
<td>267776</td>
<td>1.89118</td>
<td>1.91820</td>
<td>04:14</td>
</tr>
</tbody>
</table>
<p>

    </p><div>
      <progress value="1046" class="" max="1046" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [1046/1046 01:01&lt;00:00 #66944/67000 loss: 1.891 / 1.918]
    </div>
    
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Exception ignored in: Exception ignored in: &lt;function _MultiProcessingDataLoaderIter.__del__&gt;&lt;function _MultiProcessingDataLoaderIter.__del__&gt;

Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1478, in __del__
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1478, in __del__
        self._shutdown_workers()self._shutdown_workers()

  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1461, in _shutdown_workers
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1461, in _shutdown_workers
        if w.is_alive():if w.is_alive():

  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 160, in is_alive
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 160, in is_alive
        assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'

AssertionErrorException ignored in: AssertionError: &lt;function _MultiProcessingDataLoaderIter.__del__&gt;: can only test a child processcan only test a child process


Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1478, in __del__
    self._shutdown_workers()
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1461, in _shutdown_workers
    if w.is_alive():
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
AssertionError: can only test a child process
Exception ignored in: &lt;function _MultiProcessingDataLoaderIter.__del__&gt;
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1478, in __del__
    self._shutdown_workers()
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1461, in _shutdown_workers
    if w.is_alive():
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
AssertionError: can only test a child process
Exception ignored in: &lt;function _MultiProcessingDataLoaderIter.__del__&gt;Exception ignored in: 
&lt;function _MultiProcessingDataLoaderIter.__del__&gt;Traceback (most recent call last):

  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1478, in __del__
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1478, in __del__
    self._shutdown_workers()    
self._shutdown_workers()  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1461, in _shutdown_workers

      File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1461, in _shutdown_workers
if w.is_alive():
    Exception ignored in:   File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 160, in is_alive
if w.is_alive():    
&lt;function _MultiProcessingDataLoaderIter.__del__&gt;assert self._parent_pid == os.getpid(), 'can only test a child process'  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 160, in is_alive


    Traceback (most recent call last):
AssertionErrorassert self._parent_pid == os.getpid(), 'can only test a child process'  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1478, in __del__
: 
can only test a child processAssertionError    
: self._shutdown_workers()can only test a child process

  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1461, in _shutdown_workers
    if w.is_alive():
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
AssertionError: can only test a child process
Exception ignored in: &lt;function _MultiProcessingDataLoaderIter.__del__&gt;
Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1478, in __del__
    
self._shutdown_workers()  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1461, in _shutdown_workers
    if w.is_alive():
  File "/opt/conda/lib/python3.10/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
AssertionError: can only test a child process</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-14-output-5.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># make sure it works at all</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>train_ds, val_ds <span class="op">=</span> load_datasets(<span class="st">'t2s-6454/*.tar.gz'</span>, <span class="dv">67000</span>)</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> make_model(<span class="st">'micro'</span>, dataset<span class="op">=</span>train_ds, ttoks_codes<span class="op">=</span><span class="dv">256</span>, stoks_width<span class="op">=</span><span class="dv">64</span>, tunables<span class="op">=</span>Tunables(weight_decay<span class="op">=</span><span class="fl">1e-3</span>, encoder_depth_ratio<span class="op">=</span><span class="fl">.5</span>)).cuda()</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>train(<span class="st">"tsar-wx"</span>, model, train_ds, val_ds, half<span class="op">=</span><span class="va">True</span>, bs<span class="op">=</span><span class="dv">64</span>, lr<span class="op">=</span>model.tunables.lr0, epochs<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>      warmup_steps<span class="op">=</span><span class="dv">1500</span>, weight_decay<span class="op">=</span>model.tunables.weight_decay, clip_gradient_norm<span class="op">=</span>model.tunables.clip_gradient_norm,</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>      table_row_every_iters<span class="op">=</span><span class="dv">50000</span>, run_valid_every_iters<span class="op">=</span><span class="dv">10000</span>)</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a><span class="co"># model.save_model('t2s-chr-micro-base.en-2d-4096c-cosine32-padfix-premlp-learnpos-5e-large-6454.model')</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="4" class="" max="4" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [4/4 04:17&lt;00:00]
    </div>
    

<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">samples</th>
<th data-quarto-table-cell-role="th">train</th>
<th data-quarto-table-cell-role="th">val</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>50048</td>
<td>2.89901</td>
<td>3.55692</td>
<td>00:48</td>
</tr>
<tr class="even">
<td>100032</td>
<td>1.98145</td>
<td>2.05116</td>
<td>01:36</td>
</tr>
<tr class="odd">
<td>150016</td>
<td>1.68419</td>
<td>1.85444</td>
<td>02:23</td>
</tr>
<tr class="even">
<td>200000</td>
<td>1.62686</td>
<td>1.66584</td>
<td>03:12</td>
</tr>
<tr class="odd">
<td>250048</td>
<td>1.55128</td>
<td>1.56165</td>
<td>04:00</td>
</tr>
<tr class="even">
<td>267776</td>
<td>1.53336</td>
<td>1.55427</td>
<td>04:17</td>
</tr>
</tbody>
</table>
<p>

    </p><div>
      <progress value="1046" class="" max="1046" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [1046/1046 01:02&lt;00:00 #66944/67000 loss: 1.533 / 1.554]
    </div>
    
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-15-output-4.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># make sure it works at all</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>train_ds, val_ds <span class="op">=</span> load_datasets(<span class="st">'t2s-6454/*.tar.gz'</span>, <span class="dv">67000</span>)</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> make_model(<span class="st">'micro'</span>, dataset<span class="op">=</span>train_ds, ttoks_codes<span class="op">=</span><span class="dv">256</span>, stoks_width<span class="op">=</span><span class="dv">128</span>, tunables<span class="op">=</span>Tunables(weight_decay<span class="op">=</span><span class="fl">1e-3</span>, encoder_depth_ratio<span class="op">=</span><span class="fl">.5</span>)).cuda()</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>train(<span class="st">"tsar-wx"</span>, model, train_ds, val_ds, half<span class="op">=</span><span class="va">True</span>, bs<span class="op">=</span><span class="dv">64</span>, lr<span class="op">=</span>model.tunables.lr0, epochs<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>      warmup_steps<span class="op">=</span><span class="dv">1500</span>, weight_decay<span class="op">=</span>model.tunables.weight_decay, clip_gradient_norm<span class="op">=</span>model.tunables.clip_gradient_norm,</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>      table_row_every_iters<span class="op">=</span><span class="dv">50000</span>, run_valid_every_iters<span class="op">=</span><span class="dv">10000</span>)</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a><span class="co"># model.save_model('t2s-chr-micro-base.en-2d-4096c-cosine32-padfix-premlp-learnpos-5e-large-6454.model')</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="4" class="" max="4" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [4/4 04:19&lt;00:00]
    </div>
    

<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">samples</th>
<th data-quarto-table-cell-role="th">train</th>
<th data-quarto-table-cell-role="th">val</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>50048</td>
<td>2.71431</td>
<td>3.25542</td>
<td>00:48</td>
</tr>
<tr class="even">
<td>100032</td>
<td>1.96834</td>
<td>1.97702</td>
<td>01:37</td>
</tr>
<tr class="odd">
<td>150016</td>
<td>1.67089</td>
<td>1.73445</td>
<td>02:25</td>
</tr>
<tr class="even">
<td>200000</td>
<td>1.48925</td>
<td>1.51701</td>
<td>03:12</td>
</tr>
<tr class="odd">
<td>250048</td>
<td>1.35983</td>
<td>1.45833</td>
<td>04:02</td>
</tr>
<tr class="even">
<td>267776</td>
<td>1.35444</td>
<td>1.45313</td>
<td>04:19</td>
</tr>
</tbody>
</table>
<p>

    </p><div>
      <progress value="1046" class="" max="1046" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [1046/1046 01:04&lt;00:00 #66944/67000 loss: 1.354 / 1.453]
    </div>
    
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-16-output-4.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># make sure it works at all</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>train_ds, val_ds <span class="op">=</span> load_datasets(<span class="st">'t2s-6454/*.tar.gz'</span>, <span class="dv">67000</span>)</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>vqmodel <span class="op">=</span> vq_stoks.RQBottleneckTransformer.load_model(local_filename<span class="op">=</span><span class="st">'vqmodel-4e-hyptuned-32gpu.model'</span>).cuda()</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> make_model(<span class="st">'micro'</span>, dataset<span class="op">=</span>train_ds, ttoks_codes<span class="op">=</span><span class="dv">256</span>, stoks_width<span class="op">=</span>vqmodel.codebook_dim, tunables<span class="op">=</span>Tunables(weight_decay<span class="op">=</span><span class="fl">1e-3</span>, encoder_depth_ratio<span class="op">=</span><span class="fl">.5</span>)).cuda()</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>model.load_frozen_semantic_embeddings(vqmodel)</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>train(<span class="st">"tsar-wx"</span>, model, train_ds, val_ds, half<span class="op">=</span><span class="va">True</span>, bs<span class="op">=</span><span class="dv">64</span>, lr<span class="op">=</span>model.tunables.lr0, epochs<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>      warmup_steps<span class="op">=</span><span class="dv">1500</span>, weight_decay<span class="op">=</span>model.tunables.weight_decay, clip_gradient_norm<span class="op">=</span>model.tunables.clip_gradient_norm,</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>      table_row_every_iters<span class="op">=</span><span class="dv">50000</span>, run_valid_every_iters<span class="op">=</span><span class="dv">10000</span>)</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a><span class="co"># model.save_model('t2s-chr-micro-base.en-2d-4096c-cosine32-padfix-premlp-learnpos-5e-large-6454.model')</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="4" class="" max="4" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [4/4 04:18&lt;00:00]
    </div>
    

<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">samples</th>
<th data-quarto-table-cell-role="th">train</th>
<th data-quarto-table-cell-role="th">val</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>50048</td>
<td>2.58822</td>
<td>2.71430</td>
<td>00:48</td>
</tr>
<tr class="even">
<td>100032</td>
<td>2.22865</td>
<td>2.29081</td>
<td>01:36</td>
</tr>
<tr class="odd">
<td>150016</td>
<td>2.24062</td>
<td>2.16505</td>
<td>02:24</td>
</tr>
<tr class="even">
<td>200000</td>
<td>2.15208</td>
<td>2.10129</td>
<td>03:12</td>
</tr>
<tr class="odd">
<td>250048</td>
<td>2.11630</td>
<td>2.06462</td>
<td>04:01</td>
</tr>
<tr class="even">
<td>267776</td>
<td>2.05746</td>
<td>2.05924</td>
<td>04:18</td>
</tr>
</tbody>
</table>
<p>

    </p><div>
      <progress value="1046" class="" max="1046" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [1046/1046 01:03&lt;00:00 #66944/67000 loss: 2.057 / 2.059]
    </div>
    
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-17-output-4.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># make sure it works at all</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>train_ds, val_ds <span class="op">=</span> load_datasets(<span class="st">'t2s-6454/*.tar.gz'</span>, <span class="dv">67000</span>)</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> make_model(<span class="st">'tiny'</span>, dataset<span class="op">=</span>train_ds, ttoks_codes<span class="op">=</span><span class="dv">256</span>, tunables<span class="op">=</span>Tunables(weight_decay<span class="op">=</span><span class="fl">1e-3</span>, encoder_depth_ratio<span class="op">=</span><span class="fl">.5</span>)).cuda()</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>train(<span class="st">"tsar-wx"</span>, model, train_ds, val_ds, half<span class="op">=</span><span class="va">True</span>, bs<span class="op">=</span><span class="dv">64</span>, lr<span class="op">=</span>model.tunables.lr0, epochs<span class="op">=</span><span class="dv">8</span>,</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>      warmup_steps<span class="op">=</span><span class="dv">1500</span>, weight_decay<span class="op">=</span>model.tunables.weight_decay, clip_gradient_norm<span class="op">=</span>model.tunables.clip_gradient_norm,</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>      table_row_every_iters<span class="op">=</span><span class="dv">50000</span>, run_valid_every_iters<span class="op">=</span><span class="dv">10000</span>)</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a><span class="co"># model.save_model('t2s-chr-micro-base.en-2d-4096c-cosine32-padfix-premlp-learnpos-5e-large-6454.model')</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="8" class="" max="8" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [8/8 20:49&lt;00:00]
    </div>
    

<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">samples</th>
<th data-quarto-table-cell-role="th">train</th>
<th data-quarto-table-cell-role="th">val</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>50048</td>
<td>2.40318</td>
<td>2.89732</td>
<td>01:57</td>
</tr>
<tr class="even">
<td>100032</td>
<td>1.82548</td>
<td>1.89599</td>
<td>03:53</td>
</tr>
<tr class="odd">
<td>150016</td>
<td>1.38077</td>
<td>1.49867</td>
<td>05:49</td>
</tr>
<tr class="even">
<td>200000</td>
<td>1.27140</td>
<td>1.38744</td>
<td>07:46</td>
</tr>
<tr class="odd">
<td>250048</td>
<td>1.18064</td>
<td>1.32460</td>
<td>09:43</td>
</tr>
<tr class="even">
<td>300032</td>
<td>1.18833</td>
<td>1.30813</td>
<td>11:39</td>
</tr>
<tr class="odd">
<td>350016</td>
<td>1.15768</td>
<td>1.30107</td>
<td>13:36</td>
</tr>
<tr class="even">
<td>400000</td>
<td>1.04729</td>
<td>1.32198</td>
<td>15:32</td>
</tr>
<tr class="odd">
<td>450048</td>
<td>1.01181</td>
<td>1.32959</td>
<td>17:28</td>
</tr>
<tr class="even">
<td>500032</td>
<td>1.07383</td>
<td>1.33221</td>
<td>19:25</td>
</tr>
<tr class="odd">
<td>535552</td>
<td>1.01036</td>
<td>1.32764</td>
<td>20:49</td>
</tr>
</tbody>
</table>
<p>

    </p><div>
      <progress value="1046" class="" max="1046" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [1046/1046 02:36&lt;00:00 #66944/67000 loss: 1.010 / 1.328]
    </div>
    
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-18-output-4.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># make sure it works at all</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>train_ds, val_ds <span class="op">=</span> load_datasets(<span class="st">'t2s-6454/*.tar.gz'</span>, <span class="dv">67000</span>)</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> make_model(<span class="st">'tiny'</span>, dataset<span class="op">=</span>train_ds, ttoks_codes<span class="op">=</span><span class="dv">256</span>, stoks_width<span class="op">=</span><span class="dv">32</span>, tunables<span class="op">=</span>Tunables(weight_decay<span class="op">=</span><span class="fl">1e-3</span>, encoder_depth_ratio<span class="op">=</span><span class="fl">.5</span>)).cuda()</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>train(<span class="st">"tsar-wx"</span>, model, train_ds, val_ds, half<span class="op">=</span><span class="va">True</span>, bs<span class="op">=</span><span class="dv">64</span>, lr<span class="op">=</span>model.tunables.lr0, epochs<span class="op">=</span><span class="dv">8</span>,</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>      warmup_steps<span class="op">=</span><span class="dv">1500</span>, weight_decay<span class="op">=</span>model.tunables.weight_decay, clip_gradient_norm<span class="op">=</span>model.tunables.clip_gradient_norm,</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>      table_row_every_iters<span class="op">=</span><span class="dv">50000</span>, run_valid_every_iters<span class="op">=</span><span class="dv">10000</span>)</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a><span class="co"># model.save_model('t2s-chr-micro-base.en-2d-4096c-cosine32-padfix-premlp-learnpos-5e-large-6454.model')</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="8" class="" max="8" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [8/8 20:24&lt;00:00]
    </div>
    

<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">samples</th>
<th data-quarto-table-cell-role="th">train</th>
<th data-quarto-table-cell-role="th">val</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>50048</td>
<td>3.75509</td>
<td>4.11667</td>
<td>01:54</td>
</tr>
<tr class="even">
<td>100032</td>
<td>2.25885</td>
<td>2.30041</td>
<td>03:48</td>
</tr>
<tr class="odd">
<td>150016</td>
<td>1.91093</td>
<td>1.95126</td>
<td>05:42</td>
</tr>
<tr class="even">
<td>200000</td>
<td>1.84764</td>
<td>1.86652</td>
<td>07:36</td>
</tr>
<tr class="odd">
<td>250048</td>
<td>1.77182</td>
<td>1.81652</td>
<td>09:31</td>
</tr>
<tr class="even">
<td>300032</td>
<td>1.79985</td>
<td>1.78369</td>
<td>11:25</td>
</tr>
<tr class="odd">
<td>350016</td>
<td>1.68099</td>
<td>1.75393</td>
<td>13:19</td>
</tr>
<tr class="even">
<td>400000</td>
<td>1.66937</td>
<td>1.71709</td>
<td>15:14</td>
</tr>
<tr class="odd">
<td>450048</td>
<td>1.60969</td>
<td>1.69115</td>
<td>17:08</td>
</tr>
<tr class="even">
<td>500032</td>
<td>1.52963</td>
<td>1.67443</td>
<td>19:02</td>
</tr>
<tr class="odd">
<td>535552</td>
<td>1.60160</td>
<td>1.67044</td>
<td>20:25</td>
</tr>
</tbody>
</table>
<p>

    </p><div>
      <progress value="1046" class="" max="1046" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [1046/1046 02:33&lt;00:00 #66944/67000 loss: 1.602 / 1.670]
    </div>
    
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-19-output-4.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># make sure it works at all</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>train_ds, val_ds <span class="op">=</span> load_datasets(<span class="st">'t2s-6454/*.tar.gz'</span>, <span class="dv">67000</span>)</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>vqmodel <span class="op">=</span> vq_stoks.RQBottleneckTransformer.load_model(local_filename<span class="op">=</span><span class="st">'vqmodel-4e-hyptuned-32gpu.model'</span>).cuda()</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> make_model(<span class="st">'tiny'</span>, dataset<span class="op">=</span>train_ds, ttoks_codes<span class="op">=</span><span class="dv">256</span>, stoks_width<span class="op">=</span>vqmodel.codebook_dim, tunables<span class="op">=</span>Tunables(weight_decay<span class="op">=</span><span class="fl">1e-3</span>, encoder_depth_ratio<span class="op">=</span><span class="fl">.5</span>)).cuda()</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>model.load_frozen_semantic_embeddings(vqmodel)</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>train(<span class="st">"tsar-wx"</span>, model, train_ds, val_ds, half<span class="op">=</span><span class="va">True</span>, bs<span class="op">=</span><span class="dv">64</span>, lr<span class="op">=</span>model.tunables.lr0, epochs<span class="op">=</span><span class="dv">8</span>,</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>      warmup_steps<span class="op">=</span><span class="dv">1500</span>, weight_decay<span class="op">=</span>model.tunables.weight_decay, clip_gradient_norm<span class="op">=</span>model.tunables.clip_gradient_norm,</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>      table_row_every_iters<span class="op">=</span><span class="dv">50000</span>, run_valid_every_iters<span class="op">=</span><span class="dv">10000</span>)</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a><span class="co"># model.save_model('t2s-chr-micro-base.en-2d-4096c-cosine32-padfix-premlp-learnpos-5e-large-6454.model')</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="8" class="" max="8" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [8/8 20:36&lt;00:00]
    </div>
    

<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">samples</th>
<th data-quarto-table-cell-role="th">train</th>
<th data-quarto-table-cell-role="th">val</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>50048</td>
<td>2.66129</td>
<td>3.17833</td>
<td>01:55</td>
</tr>
<tr class="even">
<td>100032</td>
<td>2.20422</td>
<td>2.25224</td>
<td>03:50</td>
</tr>
<tr class="odd">
<td>150016</td>
<td>1.81939</td>
<td>2.03050</td>
<td>05:46</td>
</tr>
<tr class="even">
<td>200000</td>
<td>1.89059</td>
<td>1.94665</td>
<td>07:41</td>
</tr>
<tr class="odd">
<td>250048</td>
<td>1.80682</td>
<td>1.90035</td>
<td>09:36</td>
</tr>
<tr class="even">
<td>300032</td>
<td>1.76392</td>
<td>1.87051</td>
<td>11:32</td>
</tr>
<tr class="odd">
<td>350016</td>
<td>1.74465</td>
<td>1.85350</td>
<td>13:27</td>
</tr>
<tr class="even">
<td>400000</td>
<td>1.67498</td>
<td>1.84700</td>
<td>15:22</td>
</tr>
<tr class="odd">
<td>450048</td>
<td>1.75115</td>
<td>1.83276</td>
<td>17:18</td>
</tr>
<tr class="even">
<td>500032</td>
<td>1.59461</td>
<td>1.82666</td>
<td>19:13</td>
</tr>
<tr class="odd">
<td>535552</td>
<td>1.70991</td>
<td>1.82844</td>
<td>20:36</td>
</tr>
</tbody>
</table>
<p>

    </p><div>
      <progress value="1046" class="" max="1046" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [1046/1046 02:35&lt;00:00 #66944/67000 loss: 1.710 / 1.828]
    </div>
    
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-20-output-4.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># make sure it works at all</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>train_ds, val_ds <span class="op">=</span> load_datasets(<span class="st">'t2s-6454/*.tar.gz'</span>, <span class="dv">67000</span>)</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>vqmodel <span class="op">=</span> vq_stoks.RQBottleneckTransformer.load_model(local_filename<span class="op">=</span><span class="st">'vqmodel-4e-hyptuned-32gpu.model'</span>).cuda()</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> make_model(<span class="st">'tiny'</span>, dataset<span class="op">=</span>train_ds, ttoks_codes<span class="op">=</span><span class="dv">256</span>, stoks_width<span class="op">=</span>vqmodel.codebook_dim, tunables<span class="op">=</span>Tunables(weight_decay<span class="op">=</span><span class="fl">1e-3</span>, encoder_depth_ratio<span class="op">=</span><span class="fl">.5</span>, embedding_projector_lr_scale<span class="op">=</span><span class="dv">5</span>)).cuda()</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>model.load_frozen_semantic_embeddings(vqmodel)</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>train(<span class="st">"tsar-wx"</span>, model, train_ds, val_ds, half<span class="op">=</span><span class="va">True</span>, bs<span class="op">=</span><span class="dv">64</span>, lr<span class="op">=</span>model.tunables.lr0, epochs<span class="op">=</span><span class="dv">8</span>,</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>      warmup_steps<span class="op">=</span><span class="dv">1500</span>, weight_decay<span class="op">=</span>model.tunables.weight_decay, clip_gradient_norm<span class="op">=</span>model.tunables.clip_gradient_norm,</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>      table_row_every_iters<span class="op">=</span><span class="dv">50000</span>, run_valid_every_iters<span class="op">=</span><span class="dv">10000</span>)</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a><span class="co"># model.save_model('t2s-chr-micro-base.en-2d-4096c-cosine32-padfix-premlp-learnpos-5e-large-6454.model')</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="8" class="" max="8" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [8/8 20:37&lt;00:00]
    </div>
    

<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">samples</th>
<th data-quarto-table-cell-role="th">train</th>
<th data-quarto-table-cell-role="th">val</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>50048</td>
<td>2.56502</td>
<td>2.57105</td>
<td>01:55</td>
</tr>
<tr class="even">
<td>100032</td>
<td>2.09122</td>
<td>2.19948</td>
<td>03:50</td>
</tr>
<tr class="odd">
<td>150016</td>
<td>1.52316</td>
<td>1.76259</td>
<td>05:47</td>
</tr>
<tr class="even">
<td>200000</td>
<td>1.46774</td>
<td>1.54980</td>
<td>07:42</td>
</tr>
<tr class="odd">
<td>250048</td>
<td>1.32339</td>
<td>1.45032</td>
<td>09:37</td>
</tr>
<tr class="even">
<td>300032</td>
<td>1.33820</td>
<td>1.40221</td>
<td>11:33</td>
</tr>
<tr class="odd">
<td>350016</td>
<td>1.24444</td>
<td>1.37554</td>
<td>13:28</td>
</tr>
<tr class="even">
<td>400000</td>
<td>1.20127</td>
<td>1.35640</td>
<td>15:23</td>
</tr>
<tr class="odd">
<td>450048</td>
<td>1.17260</td>
<td>1.36000</td>
<td>17:19</td>
</tr>
<tr class="even">
<td>500032</td>
<td>1.12745</td>
<td>1.35252</td>
<td>19:14</td>
</tr>
<tr class="odd">
<td>535552</td>
<td>1.20389</td>
<td>1.35048</td>
<td>20:37</td>
</tr>
</tbody>
</table>
<p>

    </p><div>
      <progress value="1046" class="" max="1046" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [1046/1046 02:35&lt;00:00 #66944/67000 loss: 1.204 / 1.350]
    </div>
    
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-21-output-4.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># make sure it works at all</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>train_ds, val_ds <span class="op">=</span> load_datasets(<span class="st">'t2s-6454/*.tar.gz'</span>, <span class="dv">67000</span>)</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>vqmodel <span class="op">=</span> vq_stoks.RQBottleneckTransformer.load_model(local_filename<span class="op">=</span><span class="st">'vqmodel-4e-hyptuned-32gpu.model'</span>).cuda()</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> make_model(<span class="st">'tiny'</span>, dataset<span class="op">=</span>train_ds, ttoks_codes<span class="op">=</span><span class="dv">256</span>, stoks_width<span class="op">=</span>vqmodel.codebook_dim, tunables<span class="op">=</span>Tunables(weight_decay<span class="op">=</span><span class="fl">1e-3</span>, encoder_depth_ratio<span class="op">=</span><span class="fl">.5</span>, embedding_projector_lr_scale<span class="op">=</span><span class="dv">1</span>)).cuda()</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>model.load_frozen_semantic_embeddings(vqmodel)</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>train(<span class="st">"tsar-wx"</span>, model, train_ds, val_ds, half<span class="op">=</span><span class="va">True</span>, bs<span class="op">=</span><span class="dv">64</span>, lr<span class="op">=</span>model.tunables.lr0, epochs<span class="op">=</span><span class="dv">8</span>,</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>      warmup_steps<span class="op">=</span><span class="dv">1500</span>, weight_decay<span class="op">=</span>model.tunables.weight_decay, clip_gradient_norm<span class="op">=</span>model.tunables.clip_gradient_norm,</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>      table_row_every_iters<span class="op">=</span><span class="dv">50000</span>, run_valid_every_iters<span class="op">=</span><span class="dv">10000</span>)</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a><span class="co"># model.save_model('t2s-chr-micro-base.en-2d-4096c-cosine32-padfix-premlp-learnpos-5e-large-6454.model')</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="8" class="" max="8" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [8/8 20:38&lt;00:00]
    </div>
    

<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">samples</th>
<th data-quarto-table-cell-role="th">train</th>
<th data-quarto-table-cell-role="th">val</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>50048</td>
<td>2.55643</td>
<td>2.57862</td>
<td>01:56</td>
</tr>
<tr class="even">
<td>100032</td>
<td>2.07709</td>
<td>2.21662</td>
<td>03:51</td>
</tr>
<tr class="odd">
<td>150016</td>
<td>1.73660</td>
<td>1.76801</td>
<td>05:48</td>
</tr>
<tr class="even">
<td>200000</td>
<td>1.47864</td>
<td>1.51147</td>
<td>07:43</td>
</tr>
<tr class="odd">
<td>250048</td>
<td>1.33383</td>
<td>1.42171</td>
<td>09:38</td>
</tr>
<tr class="even">
<td>300032</td>
<td>1.30044</td>
<td>1.38115</td>
<td>11:34</td>
</tr>
<tr class="odd">
<td>350016</td>
<td>1.23273</td>
<td>1.36965</td>
<td>13:29</td>
</tr>
<tr class="even">
<td>400000</td>
<td>1.23627</td>
<td>1.35942</td>
<td>15:24</td>
</tr>
<tr class="odd">
<td>450048</td>
<td>1.18555</td>
<td>1.33863</td>
<td>17:20</td>
</tr>
<tr class="even">
<td>500032</td>
<td>1.12210</td>
<td>1.35270</td>
<td>19:15</td>
</tr>
<tr class="odd">
<td>535552</td>
<td>1.14051</td>
<td>1.34882</td>
<td>20:38</td>
</tr>
</tbody>
</table>
<p>

    </p><div>
      <progress value="1046" class="" max="1046" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [1046/1046 02:35&lt;00:00 #66944/67000 loss: 1.141 / 1.349]
    </div>
    
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-22-output-4.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># make sure it works at all</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>train_ds, val_ds <span class="op">=</span> load_datasets(<span class="st">'t2s-6454/*.tar.gz'</span>, <span class="dv">67000</span>)</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>vqmodel <span class="op">=</span> vq_stoks.RQBottleneckTransformer.load_model(local_filename<span class="op">=</span><span class="st">'vqmodel-4e-hyptuned-32gpu.model'</span>).cuda()</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> make_model(<span class="st">'tiny'</span>, dataset<span class="op">=</span>train_ds, ttoks_codes<span class="op">=</span><span class="dv">256</span>, stoks_width<span class="op">=</span>vqmodel.codebook_dim, tunables<span class="op">=</span>Tunables(weight_decay<span class="op">=</span><span class="fl">1e-3</span>, encoder_depth_ratio<span class="op">=</span><span class="fl">.5</span>, embedding_projector_lr_scale<span class="op">=</span><span class="dv">10</span>)).cuda()</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>model.load_frozen_semantic_embeddings(vqmodel)</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>train(<span class="st">"tsar-wx"</span>, model, train_ds, val_ds, half<span class="op">=</span><span class="va">True</span>, bs<span class="op">=</span><span class="dv">64</span>, lr<span class="op">=</span>model.tunables.lr0, epochs<span class="op">=</span><span class="dv">8</span>,</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>      warmup_steps<span class="op">=</span><span class="dv">1500</span>, weight_decay<span class="op">=</span>model.tunables.weight_decay, clip_gradient_norm<span class="op">=</span>model.tunables.clip_gradient_norm,</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>      table_row_every_iters<span class="op">=</span><span class="dv">50000</span>, run_valid_every_iters<span class="op">=</span><span class="dv">10000</span>)</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a><span class="co"># model.save_model('t2s-chr-micro-base.en-2d-4096c-cosine32-padfix-premlp-learnpos-5e-large-6454.model')</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="8" class="" max="8" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [8/8 22:05&lt;00:00]
    </div>
    

<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">samples</th>
<th data-quarto-table-cell-role="th">train</th>
<th data-quarto-table-cell-role="th">val</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>50048</td>
<td>2.47366</td>
<td>2.56469</td>
<td>01:56</td>
</tr>
<tr class="even">
<td>100032</td>
<td>2.07719</td>
<td>2.18855</td>
<td>03:51</td>
</tr>
<tr class="odd">
<td>150016</td>
<td>1.62540</td>
<td>1.72760</td>
<td>05:46</td>
</tr>
<tr class="even">
<td>200000</td>
<td>1.45468</td>
<td>1.51390</td>
<td>07:42</td>
</tr>
<tr class="odd">
<td>250048</td>
<td>1.39196</td>
<td>1.43748</td>
<td>09:47</td>
</tr>
<tr class="even">
<td>300032</td>
<td>1.29714</td>
<td>1.39951</td>
<td>12:06</td>
</tr>
<tr class="odd">
<td>350016</td>
<td>1.27493</td>
<td>1.36245</td>
<td>14:24</td>
</tr>
<tr class="even">
<td>400000</td>
<td>1.24066</td>
<td>1.35400</td>
<td>16:42</td>
</tr>
<tr class="odd">
<td>450048</td>
<td>1.16084</td>
<td>1.34805</td>
<td>18:47</td>
</tr>
<tr class="even">
<td>500032</td>
<td>1.17269</td>
<td>1.34920</td>
<td>20:42</td>
</tr>
<tr class="odd">
<td>535552</td>
<td>1.15527</td>
<td>1.34971</td>
<td>22:05</td>
</tr>
</tbody>
</table>
<p>

    </p><div>
      <progress value="1046" class="" max="1046" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [1046/1046 02:35&lt;00:00 #66944/67000 loss: 1.155 / 1.350]
    </div>
    
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-23-output-4.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="codebook-dim-and-vq-codes" class="level2">
<h2 class="anchored" data-anchor-id="codebook-dim-and-vq-codes">Codebook dim and VQ codes</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># make sure it works at all</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>train_ds, val_ds <span class="op">=</span> load_datasets(<span class="st">'t2s-6454/*.tar.gz'</span>, <span class="dv">67000</span>)</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>vqmodel <span class="op">=</span> vq_stoks.RQBottleneckTransformer.load_model(local_filename<span class="op">=</span><span class="st">'vqmodel-4e-hyptuned-32gpu.model'</span>).cuda()</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> make_model(<span class="st">'tiny'</span>, dataset<span class="op">=</span>train_ds, ttoks_codes<span class="op">=</span><span class="dv">256</span>, stoks_width<span class="op">=</span>vqmodel.codebook_dim, tunables<span class="op">=</span>Tunables(weight_decay<span class="op">=</span><span class="fl">1e-3</span>, encoder_depth_ratio<span class="op">=</span><span class="fl">.5</span>, embedding_projector_lr_scale<span class="op">=</span><span class="dv">5</span>)).cuda()</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>model.load_frozen_semantic_embeddings(vqmodel)</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>train(<span class="st">"tsar-wx"</span>, model, train_ds, val_ds, half<span class="op">=</span><span class="va">True</span>, bs<span class="op">=</span><span class="dv">64</span>, lr<span class="op">=</span>model.tunables.lr0, epochs<span class="op">=</span><span class="dv">8</span>,</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>      warmup_steps<span class="op">=</span><span class="dv">1500</span>, weight_decay<span class="op">=</span>model.tunables.weight_decay, clip_gradient_norm<span class="op">=</span>model.tunables.clip_gradient_norm,</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>      table_row_every_iters<span class="op">=</span><span class="dv">50000</span>, run_valid_every_iters<span class="op">=</span><span class="dv">10000</span>)</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a><span class="co"># model.save_model('t2s-chr-micro-base.en-2d-4096c-cosine32-padfix-premlp-learnpos-5e-large-6454.model')</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="8" class="" max="8" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [8/8 20:37&lt;00:00]
    </div>
    

<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">samples</th>
<th data-quarto-table-cell-role="th">train</th>
<th data-quarto-table-cell-role="th">val</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>50048</td>
<td>2.56502</td>
<td>2.57105</td>
<td>01:55</td>
</tr>
<tr class="even">
<td>100032</td>
<td>2.09122</td>
<td>2.19948</td>
<td>03:50</td>
</tr>
<tr class="odd">
<td>150016</td>
<td>1.52316</td>
<td>1.76259</td>
<td>05:47</td>
</tr>
<tr class="even">
<td>200000</td>
<td>1.46774</td>
<td>1.54980</td>
<td>07:42</td>
</tr>
<tr class="odd">
<td>250048</td>
<td>1.32339</td>
<td>1.45032</td>
<td>09:37</td>
</tr>
<tr class="even">
<td>300032</td>
<td>1.33820</td>
<td>1.40221</td>
<td>11:33</td>
</tr>
<tr class="odd">
<td>350016</td>
<td>1.24444</td>
<td>1.37554</td>
<td>13:28</td>
</tr>
<tr class="even">
<td>400000</td>
<td>1.20127</td>
<td>1.35640</td>
<td>15:23</td>
</tr>
<tr class="odd">
<td>450048</td>
<td>1.17260</td>
<td>1.36000</td>
<td>17:19</td>
</tr>
<tr class="even">
<td>500032</td>
<td>1.12745</td>
<td>1.35252</td>
<td>19:14</td>
</tr>
<tr class="odd">
<td>535552</td>
<td>1.20389</td>
<td>1.35048</td>
<td>20:37</td>
</tr>
</tbody>
</table>
<p>

    </p><div>
      <progress value="1046" class="" max="1046" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [1046/1046 02:35&lt;00:00 #66944/67000 loss: 1.204 / 1.350]
    </div>
    
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-24-output-4.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>vqmodel.vq_codes</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>512</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> x <span class="kw">in</span> val_ds: <span class="cf">break</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>x</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>[tensor([[ 84, 104, 101,  ...,   0,   0,   0],
         [116, 104, 114,  ...,   0,   0,   0],
         [ 84, 104, 101,  ...,   0,   0,   0],
         ...,
         [ 77, 121,  32,  ...,   0,   0,   0],
         [ 70, 111, 108,  ...,   0,   0,   0],
         [ 85, 110, 100,  ...,   0,   0,   0]]),
 tensor([[513, 273, 195,  ..., 513, 513, 513],
         [513, 303,  89,  ..., 513, 513, 513],
         [513,  46, 462,  ..., 513, 513, 513],
         ...,
         [513, 454, 173,  ..., 513, 513, 513],
         [513, 454, 273,  ..., 513, 513, 513],
         [513, 332, 332,  ..., 513, 513, 513]]),
 tensor([[273, 195, 100,  ..., 513, 513, 513],
         [303,  89, 351,  ..., 513, 513, 513],
         [ 46, 462, 453,  ..., 513, 513, 513],
         ...,
         [454, 173, 173,  ..., 513, 513, 513],
         [454, 273, 198,  ..., 513, 513, 513],
         [332, 332,  88,  ..., 513, 513, 513]]),
 tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])]</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># make sure it works at all</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>vqmodel <span class="op">=</span> vq_stoks.RQBottleneckTransformer.load_model(local_filename<span class="op">=</span><span class="st">'vqmodel-256c-4e-hyptuned-32gpu.model'</span>).cuda()</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>train_ds, val_ds <span class="op">=</span> load_datasets(<span class="st">'whisperspeech-t2s-512c/*.tar.gz'</span>, <span class="dv">67000</span>, vq_codes<span class="op">=</span>vqmodel.vq_codes<span class="op">+</span><span class="dv">1</span>)</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> make_model(<span class="st">'tiny'</span>, dataset<span class="op">=</span>train_ds, ttoks_codes<span class="op">=</span><span class="dv">256</span>, stoks_width<span class="op">=</span>vqmodel.codebook_dim, tunables<span class="op">=</span>Tunables(weight_decay<span class="op">=</span><span class="fl">1e-3</span>, encoder_depth_ratio<span class="op">=</span><span class="fl">.5</span>, embedding_projector_lr_scale<span class="op">=</span><span class="dv">5</span>)).cuda()</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>model.load_frozen_semantic_embeddings(vqmodel)</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>train(<span class="st">"tsar-wx"</span>, model, train_ds, val_ds, half<span class="op">=</span><span class="va">True</span>, bs<span class="op">=</span><span class="dv">64</span>, lr<span class="op">=</span>model.tunables.lr0, epochs<span class="op">=</span><span class="dv">8</span>,</span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>      warmup_steps<span class="op">=</span><span class="dv">1500</span>, weight_decay<span class="op">=</span>model.tunables.weight_decay, clip_gradient_norm<span class="op">=</span>model.tunables.clip_gradient_norm,</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>      table_row_every_iters<span class="op">=</span><span class="dv">50000</span>, run_valid_every_iters<span class="op">=</span><span class="dv">10000</span>)</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a><span class="co"># model.save_model('t2s-chr-micro-base.en-2d-4096c-cosine32-padfix-premlp-learnpos-5e-large-6454.model')</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="8" class="" max="8" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [8/8 16:32&lt;00:00]
    </div>
    

<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">samples</th>
<th data-quarto-table-cell-role="th">train</th>
<th data-quarto-table-cell-role="th">val</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>50048</td>
<td>1.82633</td>
<td>2.22741</td>
<td>01:32</td>
</tr>
<tr class="even">
<td>100032</td>
<td>1.60664</td>
<td>1.93017</td>
<td>03:05</td>
</tr>
<tr class="odd">
<td>150016</td>
<td>1.31743</td>
<td>1.83070</td>
<td>04:37</td>
</tr>
<tr class="even">
<td>200000</td>
<td>1.47108</td>
<td>1.79051</td>
<td>06:10</td>
</tr>
<tr class="odd">
<td>250048</td>
<td>1.34203</td>
<td>1.68920</td>
<td>07:42</td>
</tr>
<tr class="even">
<td>300032</td>
<td>1.35330</td>
<td>1.65576</td>
<td>09:15</td>
</tr>
<tr class="odd">
<td>350016</td>
<td>1.36777</td>
<td>1.62137</td>
<td>10:48</td>
</tr>
<tr class="even">
<td>400000</td>
<td>1.28777</td>
<td>1.59741</td>
<td>12:20</td>
</tr>
<tr class="odd">
<td>450048</td>
<td>1.21631</td>
<td>1.57967</td>
<td>13:53</td>
</tr>
<tr class="even">
<td>500032</td>
<td>1.20893</td>
<td>1.57008</td>
<td>15:26</td>
</tr>
<tr class="odd">
<td>535552</td>
<td>1.34431</td>
<td>1.56491</td>
<td>16:32</td>
</tr>
</tbody>
</table>
<p>

    </p><div>
      <progress value="1046" class="" max="1046" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [1046/1046 02:04&lt;00:00 #66944/67000 loss: 1.344 / 1.565]
    </div>
    
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-27-output-4.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>vqmodel.vq_codes</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>512</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># make sure it works at all</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>vqmodel <span class="op">=</span> vq_stoks.RQBottleneckTransformer.load_model(local_filename<span class="op">=</span><span class="st">'vqmodel-256c-dim64-4e-hyptuned-32gpu.model'</span>).cuda()</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>train_ds, val_ds <span class="op">=</span> load_datasets(<span class="st">'whisperspeech-t2s-512c-dim64/*.tar.gz'</span>, <span class="dv">67000</span>, vq_codes<span class="op">=</span>vqmodel.vq_codes<span class="op">+</span><span class="dv">1</span>)</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> make_model(<span class="st">'tiny'</span>, dataset<span class="op">=</span>train_ds, ttoks_codes<span class="op">=</span><span class="dv">256</span>, stoks_width<span class="op">=</span>vqmodel.codebook_dim, tunables<span class="op">=</span>Tunables(weight_decay<span class="op">=</span><span class="fl">1e-3</span>, encoder_depth_ratio<span class="op">=</span><span class="fl">.5</span>, embedding_projector_lr_scale<span class="op">=</span><span class="dv">5</span>)).cuda()</span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>model.load_frozen_semantic_embeddings(vqmodel)</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>train(<span class="st">"tsar-wx"</span>, model, train_ds, val_ds, half<span class="op">=</span><span class="va">True</span>, bs<span class="op">=</span><span class="dv">64</span>, lr<span class="op">=</span>model.tunables.lr0, epochs<span class="op">=</span><span class="dv">8</span>,</span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>      warmup_steps<span class="op">=</span><span class="dv">1500</span>, weight_decay<span class="op">=</span>model.tunables.weight_decay, clip_gradient_norm<span class="op">=</span>model.tunables.clip_gradient_norm,</span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>      table_row_every_iters<span class="op">=</span><span class="dv">50000</span>, run_valid_every_iters<span class="op">=</span><span class="dv">10000</span>)</span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a>model.save_model(<span class="st">'t2s-chr-tiny-base.en-2d-512c-dim64-6454.model'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="8" class="" max="8" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [8/8 16:39&lt;00:00]
    </div>
    

<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">samples</th>
<th data-quarto-table-cell-role="th">train</th>
<th data-quarto-table-cell-role="th">val</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>50048</td>
<td>1.47909</td>
<td>1.92589</td>
<td>01:33</td>
</tr>
<tr class="even">
<td>100032</td>
<td>1.27453</td>
<td>1.60590</td>
<td>03:06</td>
</tr>
<tr class="odd">
<td>150016</td>
<td>1.21110</td>
<td>1.39237</td>
<td>04:39</td>
</tr>
<tr class="even">
<td>200000</td>
<td>0.94160</td>
<td>1.33038</td>
<td>06:12</td>
</tr>
<tr class="odd">
<td>250048</td>
<td>1.01031</td>
<td>1.22544</td>
<td>07:46</td>
</tr>
<tr class="even">
<td>300032</td>
<td>0.94135</td>
<td>1.15930</td>
<td>09:19</td>
</tr>
<tr class="odd">
<td>350016</td>
<td>0.81337</td>
<td>1.04483</td>
<td>10:53</td>
</tr>
<tr class="even">
<td>400000</td>
<td>0.75797</td>
<td>0.99746</td>
<td>12:26</td>
</tr>
<tr class="odd">
<td>450048</td>
<td>0.74541</td>
<td>0.96900</td>
<td>13:59</td>
</tr>
<tr class="even">
<td>500032</td>
<td>0.78007</td>
<td>0.94995</td>
<td>15:32</td>
</tr>
<tr class="odd">
<td>535552</td>
<td>0.77188</td>
<td>0.94316</td>
<td>16:39</td>
</tr>
</tbody>
</table>
<p>

    </p><div>
      <progress value="1046" class="" max="1046" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [1046/1046 02:05&lt;00:00 #66944/67000 loss: 0.772 / 0.943]
    </div>
    
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-29-output-4.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># make sure it works at all</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>vqmodel <span class="op">=</span> vq_stoks.RQBottleneckTransformer.load_model(local_filename<span class="op">=</span><span class="st">'vqmodel-256c-dim64-4e-hyptuned-32gpu.model'</span>).cuda()</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>train_ds, val_ds <span class="op">=</span> load_datasets(<span class="st">'whisperspeech-t2s-512c-dim64/*.tar.gz'</span>, <span class="dv">250000</span>, vq_codes<span class="op">=</span>vqmodel.vq_codes<span class="op">+</span><span class="dv">1</span>)</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> make_model(<span class="st">'base'</span>, dataset<span class="op">=</span>train_ds, ttoks_codes<span class="op">=</span><span class="dv">256</span>, stoks_width<span class="op">=</span>vqmodel.codebook_dim, tunables<span class="op">=</span>Tunables(weight_decay<span class="op">=</span><span class="fl">1e-3</span>, encoder_depth_ratio<span class="op">=</span><span class="fl">.5</span>, embedding_projector_lr_scale<span class="op">=</span><span class="dv">5</span>)).cuda()</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>model.load_frozen_semantic_embeddings(vqmodel)</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>train(<span class="st">"tsar-wx"</span>, model, train_ds, val_ds, half<span class="op">=</span><span class="va">True</span>, bs<span class="op">=</span><span class="dv">64</span>, lr<span class="op">=</span>model.tunables.lr0, epochs<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>      warmup_steps<span class="op">=</span><span class="dv">1500</span>, weight_decay<span class="op">=</span>model.tunables.weight_decay, clip_gradient_norm<span class="op">=</span>model.tunables.clip_gradient_norm,</span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>      table_row_every_iters<span class="op">=</span><span class="dv">50000</span>, run_valid_every_iters<span class="op">=</span><span class="dv">10000</span>)</span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a>model.save_model(<span class="st">'t2s-chr-base-base.en-2d-512c-dim64-6454.model'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="4" class="" max="4" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [4/4 1:02:33&lt;00:00]
    </div>
    

<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">samples</th>
<th data-quarto-table-cell-role="th">train</th>
<th data-quarto-table-cell-role="th">val</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>50048</td>
<td>1.54400</td>
<td>1.56100</td>
<td>03:07</td>
</tr>
<tr class="even">
<td>100032</td>
<td>1.39910</td>
<td>1.37488</td>
<td>06:15</td>
</tr>
<tr class="odd">
<td>150016</td>
<td>1.39666</td>
<td>1.29138</td>
<td>09:22</td>
</tr>
<tr class="even">
<td>200000</td>
<td>1.25551</td>
<td>1.25673</td>
<td>12:30</td>
</tr>
<tr class="odd">
<td>250048</td>
<td>1.32616</td>
<td>1.23933</td>
<td>15:37</td>
</tr>
<tr class="even">
<td>300032</td>
<td>1.26494</td>
<td>1.21040</td>
<td>18:45</td>
</tr>
<tr class="odd">
<td>350016</td>
<td>1.24198</td>
<td>1.19714</td>
<td>21:52</td>
</tr>
<tr class="even">
<td>400000</td>
<td>1.20484</td>
<td>1.18515</td>
<td>25:00</td>
</tr>
<tr class="odd">
<td>450048</td>
<td>1.23590</td>
<td>1.16427</td>
<td>28:08</td>
</tr>
<tr class="even">
<td>500032</td>
<td>1.16193</td>
<td>1.13852</td>
<td>31:15</td>
</tr>
<tr class="odd">
<td>550016</td>
<td>1.11333</td>
<td>1.11318</td>
<td>34:23</td>
</tr>
<tr class="even">
<td>600000</td>
<td>1.13005</td>
<td>1.08927</td>
<td>37:31</td>
</tr>
<tr class="odd">
<td>650048</td>
<td>1.06830</td>
<td>1.07150</td>
<td>40:39</td>
</tr>
<tr class="even">
<td>700032</td>
<td>1.14128</td>
<td>1.05110</td>
<td>43:46</td>
</tr>
<tr class="odd">
<td>750016</td>
<td>1.10899</td>
<td>1.03504</td>
<td>46:54</td>
</tr>
<tr class="even">
<td>800000</td>
<td>0.99225</td>
<td>1.01920</td>
<td>50:02</td>
</tr>
<tr class="odd">
<td>850048</td>
<td>1.02860</td>
<td>1.00818</td>
<td>53:10</td>
</tr>
<tr class="even">
<td>900032</td>
<td>0.98420</td>
<td>1.00081</td>
<td>56:18</td>
</tr>
<tr class="odd">
<td>950016</td>
<td>0.97809</td>
<td>0.99681</td>
<td>59:26</td>
</tr>
<tr class="even">
<td>999936</td>
<td>0.97344</td>
<td>0.99474</td>
<td>1:02:33</td>
</tr>
</tbody>
</table>
<p>

    </p><div>
      <progress value="3906" class="" max="3906" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [3906/3906 15:38&lt;00:00 #249984/250000 loss: 0.973 / 0.995]
    </div>
    
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-30-output-4.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># make sure it works at all</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>vqmodel <span class="op">=</span> vq_stoks.RQBottleneckTransformer.load_model(local_filename<span class="op">=</span><span class="st">'vqmodel-256c-dim64-4e-hyptuned-32gpu.model'</span>).cuda()</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>train_ds, val_ds <span class="op">=</span> load_datasets(<span class="st">'whisperspeech-t2s-512c-dim64/*-6454-*.tar.gz'</span>, <span class="dv">250000</span>, vq_codes<span class="op">=</span>vqmodel.vq_codes<span class="op">+</span><span class="dv">1</span>)</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> make_model(<span class="st">'micro'</span>, dataset<span class="op">=</span>train_ds, ttoks_codes<span class="op">=</span><span class="dv">256</span>, stoks_width<span class="op">=</span>vqmodel.codebook_dim, tunables<span class="op">=</span>Tunables(weight_decay<span class="op">=</span><span class="fl">1e-3</span>, encoder_depth_ratio<span class="op">=</span><span class="fl">.5</span>, embedding_projector_lr_scale<span class="op">=</span><span class="dv">5</span>, cps_input<span class="op">=</span><span class="va">False</span>)).cuda()</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>model.load_frozen_semantic_embeddings(vqmodel)</span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>train(<span class="st">"tsar-wx"</span>, model, train_ds, val_ds, half<span class="op">=</span><span class="va">True</span>, bs<span class="op">=</span><span class="dv">64</span>, lr<span class="op">=</span>model.tunables.lr0, epochs<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>      warmup_steps<span class="op">=</span><span class="dv">1500</span>, weight_decay<span class="op">=</span>model.tunables.weight_decay, clip_gradient_norm<span class="op">=</span>model.tunables.clip_gradient_norm,</span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>      table_row_every_iters<span class="op">=</span><span class="dv">50000</span>, run_valid_every_iters<span class="op">=</span><span class="dv">10000</span>)</span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a><span class="co"># model.save_model('t2s-chr-base-base.en-2d-512c-dim64-6454.model')</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="4" class="" max="4" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [4/4 08:38&lt;00:00]
    </div>
    

<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">samples</th>
<th data-quarto-table-cell-role="th">train</th>
<th data-quarto-table-cell-role="th">val</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>50048</td>
<td>1.75974</td>
<td>2.00099</td>
<td>00:25</td>
</tr>
<tr class="even">
<td>100032</td>
<td>1.28389</td>
<td>1.75231</td>
<td>00:51</td>
</tr>
<tr class="odd">
<td>150016</td>
<td>1.26908</td>
<td>1.60221</td>
<td>01:17</td>
</tr>
<tr class="even">
<td>200000</td>
<td>0.95525</td>
<td>1.16684</td>
<td>01:43</td>
</tr>
<tr class="odd">
<td>250048</td>
<td>0.96412</td>
<td>1.08697</td>
<td>02:10</td>
</tr>
<tr class="even">
<td>300032</td>
<td>0.83162</td>
<td>1.04516</td>
<td>02:35</td>
</tr>
<tr class="odd">
<td>350016</td>
<td>0.79592</td>
<td>1.03185</td>
<td>03:01</td>
</tr>
<tr class="even">
<td>400000</td>
<td>0.84238</td>
<td>0.99971</td>
<td>03:27</td>
</tr>
<tr class="odd">
<td>450048</td>
<td>0.87118</td>
<td>0.98406</td>
<td>03:53</td>
</tr>
<tr class="even">
<td>500032</td>
<td>0.86152</td>
<td>0.96493</td>
<td>04:19</td>
</tr>
<tr class="odd">
<td>550016</td>
<td>0.78976</td>
<td>0.95754</td>
<td>04:45</td>
</tr>
<tr class="even">
<td>600000</td>
<td>0.74924</td>
<td>0.95597</td>
<td>05:10</td>
</tr>
<tr class="odd">
<td>650048</td>
<td>0.77826</td>
<td>0.93904</td>
<td>05:36</td>
</tr>
<tr class="even">
<td>700032</td>
<td>0.81133</td>
<td>0.93131</td>
<td>06:02</td>
</tr>
<tr class="odd">
<td>750016</td>
<td>0.84455</td>
<td>0.92535</td>
<td>06:28</td>
</tr>
<tr class="even">
<td>800000</td>
<td>0.73336</td>
<td>0.92830</td>
<td>06:53</td>
</tr>
<tr class="odd">
<td>850048</td>
<td>0.70844</td>
<td>0.92848</td>
<td>07:20</td>
</tr>
<tr class="even">
<td>900032</td>
<td>0.72498</td>
<td>0.91084</td>
<td>07:46</td>
</tr>
<tr class="odd">
<td>950016</td>
<td>0.74317</td>
<td>0.91438</td>
<td>08:12</td>
</tr>
<tr class="even">
<td>999936</td>
<td>0.73405</td>
<td>0.90956</td>
<td>08:38</td>
</tr>
</tbody>
</table>
<p>

    </p><div>
      <progress value="3906" class="" max="3906" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [3906/3906 02:10&lt;00:00 #249984/250000 loss: 0.734 / 0.910]
    </div>
    
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-31-output-4.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># make sure it works at all</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>vqmodel <span class="op">=</span> vq_stoks.RQBottleneckTransformer.load_model(local_filename<span class="op">=</span><span class="st">'vqmodel-256c-dim64-4e-hyptuned-32gpu.model'</span>).cuda()</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>train_ds, val_ds <span class="op">=</span> load_datasets(<span class="st">'whisperspeech-t2s-512c-dim64/*-6454-*.tar.gz'</span>, <span class="dv">250000</span>, vq_codes<span class="op">=</span>vqmodel.vq_codes<span class="op">+</span><span class="dv">1</span>)</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> make_model(<span class="st">'micro'</span>, dataset<span class="op">=</span>train_ds, ttoks_codes<span class="op">=</span><span class="dv">256</span>, stoks_width<span class="op">=</span>vqmodel.codebook_dim, tunables<span class="op">=</span>Tunables(weight_decay<span class="op">=</span><span class="fl">1e-3</span>, encoder_depth_ratio<span class="op">=</span><span class="fl">.5</span>, embedding_projector_lr_scale<span class="op">=</span><span class="dv">5</span>, cps_input<span class="op">=</span><span class="va">True</span>)).cuda()</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>model.load_frozen_semantic_embeddings(vqmodel)</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>train(<span class="st">"tsar-wx"</span>, model, train_ds, val_ds, half<span class="op">=</span><span class="va">True</span>, bs<span class="op">=</span><span class="dv">64</span>, lr<span class="op">=</span>model.tunables.lr0, epochs<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>      warmup_steps<span class="op">=</span><span class="dv">1500</span>, weight_decay<span class="op">=</span>model.tunables.weight_decay, clip_gradient_norm<span class="op">=</span>model.tunables.clip_gradient_norm,</span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>      table_row_every_iters<span class="op">=</span><span class="dv">50000</span>, run_valid_every_iters<span class="op">=</span><span class="dv">10000</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="4" class="" max="4" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [4/4 08:41&lt;00:00]
    </div>
    

<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">samples</th>
<th data-quarto-table-cell-role="th">train</th>
<th data-quarto-table-cell-role="th">val</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>50048</td>
<td>1.66787</td>
<td>2.02706</td>
<td>00:26</td>
</tr>
<tr class="even">
<td>100032</td>
<td>1.40207</td>
<td>1.76437</td>
<td>00:51</td>
</tr>
<tr class="odd">
<td>150016</td>
<td>1.27476</td>
<td>1.62537</td>
<td>01:17</td>
</tr>
<tr class="even">
<td>200000</td>
<td>1.04374</td>
<td>1.26855</td>
<td>01:43</td>
</tr>
<tr class="odd">
<td>250048</td>
<td>0.98632</td>
<td>1.15448</td>
<td>02:10</td>
</tr>
<tr class="even">
<td>300032</td>
<td>0.86521</td>
<td>1.10903</td>
<td>02:35</td>
</tr>
<tr class="odd">
<td>350016</td>
<td>0.85357</td>
<td>1.09162</td>
<td>03:02</td>
</tr>
<tr class="even">
<td>400000</td>
<td>0.87830</td>
<td>1.06209</td>
<td>03:28</td>
</tr>
<tr class="odd">
<td>450048</td>
<td>0.85805</td>
<td>1.04703</td>
<td>03:54</td>
</tr>
<tr class="even">
<td>500032</td>
<td>0.89811</td>
<td>1.02455</td>
<td>04:21</td>
</tr>
<tr class="odd">
<td>550016</td>
<td>0.79925</td>
<td>1.01411</td>
<td>04:47</td>
</tr>
<tr class="even">
<td>600000</td>
<td>0.73336</td>
<td>1.01863</td>
<td>05:13</td>
</tr>
<tr class="odd">
<td>650048</td>
<td>0.82640</td>
<td>0.98806</td>
<td>05:39</td>
</tr>
<tr class="even">
<td>700032</td>
<td>0.77968</td>
<td>0.98760</td>
<td>06:04</td>
</tr>
<tr class="odd">
<td>750016</td>
<td>0.89192</td>
<td>0.97200</td>
<td>06:31</td>
</tr>
<tr class="even">
<td>800000</td>
<td>0.82949</td>
<td>0.95988</td>
<td>06:57</td>
</tr>
<tr class="odd">
<td>850048</td>
<td>0.79494</td>
<td>0.95736</td>
<td>07:23</td>
</tr>
<tr class="even">
<td>900032</td>
<td>0.77900</td>
<td>0.95254</td>
<td>07:49</td>
</tr>
<tr class="odd">
<td>950016</td>
<td>0.86420</td>
<td>0.94808</td>
<td>08:15</td>
</tr>
<tr class="even">
<td>999936</td>
<td>0.78041</td>
<td>0.94627</td>
<td>08:41</td>
</tr>
</tbody>
</table>
<p>

    </p><div>
      <progress value="3906" class="" max="3906" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [3906/3906 02:10&lt;00:00 #249984/250000 loss: 0.780 / 0.946]
    </div>
    
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-32-output-4.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co"># cps += in decoder</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>vqmodel <span class="op">=</span> vq_stoks.RQBottleneckTransformer.load_model(local_filename<span class="op">=</span><span class="st">'vqmodel-256c-dim64-4e-hyptuned-32gpu.model'</span>).cuda()</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>train_ds, val_ds <span class="op">=</span> load_datasets(<span class="st">'whisperspeech-t2s-512c-dim64/*-6454-*.tar.gz'</span>, <span class="dv">250000</span>, vq_codes<span class="op">=</span>vqmodel.vq_codes<span class="op">+</span><span class="dv">1</span>)</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> make_model(<span class="st">'micro'</span>, dataset<span class="op">=</span>train_ds, ttoks_codes<span class="op">=</span><span class="dv">256</span>, stoks_width<span class="op">=</span>vqmodel.codebook_dim, tunables<span class="op">=</span>Tunables(weight_decay<span class="op">=</span><span class="fl">1e-3</span>, encoder_depth_ratio<span class="op">=</span><span class="fl">.5</span>, embedding_projector_lr_scale<span class="op">=</span><span class="dv">5</span>, cps_input<span class="op">=</span><span class="va">True</span>)).cuda()</span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>model.load_frozen_semantic_embeddings(vqmodel)</span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>train(<span class="st">"tsar-wx"</span>, model, train_ds, val_ds, half<span class="op">=</span><span class="va">True</span>, bs<span class="op">=</span><span class="dv">64</span>, lr<span class="op">=</span>model.tunables.lr0, epochs<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>      warmup_steps<span class="op">=</span><span class="dv">1500</span>, weight_decay<span class="op">=</span>model.tunables.weight_decay, clip_gradient_norm<span class="op">=</span>model.tunables.clip_gradient_norm,</span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a>      table_row_every_iters<span class="op">=</span><span class="dv">50000</span>, run_valid_every_iters<span class="op">=</span><span class="dv">10000</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="4" class="" max="4" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [4/4 08:43&lt;00:00]
    </div>
    

<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">samples</th>
<th data-quarto-table-cell-role="th">train</th>
<th data-quarto-table-cell-role="th">val</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>50048</td>
<td>1.66341</td>
<td>2.03399</td>
<td>00:26</td>
</tr>
<tr class="even">
<td>100032</td>
<td>1.39218</td>
<td>1.79365</td>
<td>00:52</td>
</tr>
<tr class="odd">
<td>150016</td>
<td>1.25304</td>
<td>1.62505</td>
<td>01:18</td>
</tr>
<tr class="even">
<td>200000</td>
<td>1.01684</td>
<td>1.18102</td>
<td>01:44</td>
</tr>
<tr class="odd">
<td>250048</td>
<td>0.92334</td>
<td>1.09278</td>
<td>02:11</td>
</tr>
<tr class="even">
<td>300032</td>
<td>0.87596</td>
<td>1.06255</td>
<td>02:36</td>
</tr>
<tr class="odd">
<td>350016</td>
<td>0.79978</td>
<td>1.04593</td>
<td>03:03</td>
</tr>
<tr class="even">
<td>400000</td>
<td>0.83765</td>
<td>1.01986</td>
<td>03:29</td>
</tr>
<tr class="odd">
<td>450048</td>
<td>0.86234</td>
<td>1.00090</td>
<td>03:55</td>
</tr>
<tr class="even">
<td>500032</td>
<td>0.83526</td>
<td>0.98805</td>
<td>04:21</td>
</tr>
<tr class="odd">
<td>550016</td>
<td>0.79300</td>
<td>0.99132</td>
<td>04:47</td>
</tr>
<tr class="even">
<td>600000</td>
<td>0.75818</td>
<td>0.99056</td>
<td>05:14</td>
</tr>
<tr class="odd">
<td>650048</td>
<td>0.81305</td>
<td>0.96675</td>
<td>05:40</td>
</tr>
<tr class="even">
<td>700032</td>
<td>0.81213</td>
<td>0.96176</td>
<td>06:06</td>
</tr>
<tr class="odd">
<td>750016</td>
<td>0.81502</td>
<td>0.95014</td>
<td>06:32</td>
</tr>
<tr class="even">
<td>800000</td>
<td>0.78007</td>
<td>0.93658</td>
<td>06:58</td>
</tr>
<tr class="odd">
<td>850048</td>
<td>0.70850</td>
<td>0.93692</td>
<td>07:24</td>
</tr>
<tr class="even">
<td>900032</td>
<td>0.81334</td>
<td>0.92831</td>
<td>07:50</td>
</tr>
<tr class="odd">
<td>950016</td>
<td>0.80085</td>
<td>0.92518</td>
<td>08:17</td>
</tr>
<tr class="even">
<td>999936</td>
<td>0.79627</td>
<td>0.92422</td>
<td>08:43</td>
</tr>
</tbody>
</table>
<p>

    </p><div>
      <progress value="3906" class="" max="3906" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [3906/3906 02:10&lt;00:00 #249984/250000 loss: 0.796 / 0.924]
    </div>
    
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-33-output-4.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># make sure it works at all</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>vqmodel <span class="op">=</span> vq_stoks.RQBottleneckTransformer.load_model(local_filename<span class="op">=</span><span class="st">'vqmodel-256c-dim64-4e-hyptuned-32gpu.model'</span>).cuda()</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>train_ds, val_ds <span class="op">=</span> load_datasets(<span class="st">'whisperspeech-t2s-512c-dim64/*-6454-*.tar.gz'</span>, <span class="dv">250000</span>, vq_codes<span class="op">=</span>vqmodel.vq_codes<span class="op">+</span><span class="dv">1</span>)</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> make_model(<span class="st">'base'</span>, dataset<span class="op">=</span>train_ds, ttoks_codes<span class="op">=</span><span class="dv">256</span>, stoks_width<span class="op">=</span>vqmodel.codebook_dim, tunables<span class="op">=</span>Tunables(weight_decay<span class="op">=</span><span class="fl">1e-3</span>, encoder_depth_ratio<span class="op">=</span><span class="fl">.5</span>, embedding_projector_lr_scale<span class="op">=</span><span class="dv">5</span>, cps_input<span class="op">=</span><span class="va">True</span>)).cuda()</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>model.load_frozen_semantic_embeddings(vqmodel)</span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>train(<span class="st">"tsar-wx"</span>, model, train_ds, val_ds, half<span class="op">=</span><span class="va">True</span>, bs<span class="op">=</span><span class="dv">64</span>, lr<span class="op">=</span>model.tunables.lr0<span class="op">/</span><span class="dv">2</span>, epochs<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a>      warmup_steps<span class="op">=</span><span class="dv">1500</span>, weight_decay<span class="op">=</span>model.tunables.weight_decay, clip_gradient_norm<span class="op">=</span>model.tunables.clip_gradient_norm,</span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>      table_row_every_iters<span class="op">=</span><span class="dv">50000</span>, run_valid_every_iters<span class="op">=</span><span class="dv">10000</span>)</span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>model.save_model(<span class="st">'t2s-chr-base-base.en-2d-512c-dim64-cps-6454.model'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="4" class="" max="4" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [4/4 1:02:41&lt;00:00]
    </div>
    

<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">samples</th>
<th data-quarto-table-cell-role="th">train</th>
<th data-quarto-table-cell-role="th">val</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>50048</td>
<td>1.53023</td>
<td>1.95611</td>
<td>03:08</td>
</tr>
<tr class="even">
<td>100032</td>
<td>1.29101</td>
<td>1.72470</td>
<td>06:16</td>
</tr>
<tr class="odd">
<td>150016</td>
<td>1.27883</td>
<td>1.58126</td>
<td>09:24</td>
</tr>
<tr class="even">
<td>200000</td>
<td>1.04288</td>
<td>1.43338</td>
<td>12:32</td>
</tr>
<tr class="odd">
<td>250048</td>
<td>0.85578</td>
<td>1.04747</td>
<td>15:40</td>
</tr>
<tr class="even">
<td>300032</td>
<td>0.78075</td>
<td>0.93366</td>
<td>18:49</td>
</tr>
<tr class="odd">
<td>350016</td>
<td>0.70612</td>
<td>0.89653</td>
<td>21:57</td>
</tr>
<tr class="even">
<td>400000</td>
<td>0.67291</td>
<td>0.86028</td>
<td>25:04</td>
</tr>
<tr class="odd">
<td>450048</td>
<td>0.74054</td>
<td>0.83844</td>
<td>28:12</td>
</tr>
<tr class="even">
<td>500032</td>
<td>0.72978</td>
<td>0.82141</td>
<td>31:21</td>
</tr>
<tr class="odd">
<td>550016</td>
<td>0.69412</td>
<td>0.81737</td>
<td>34:29</td>
</tr>
<tr class="even">
<td>600000</td>
<td>0.65242</td>
<td>0.81077</td>
<td>37:36</td>
</tr>
<tr class="odd">
<td>650048</td>
<td>0.64136</td>
<td>0.79844</td>
<td>40:45</td>
</tr>
<tr class="even">
<td>700032</td>
<td>0.70199</td>
<td>0.78766</td>
<td>43:53</td>
</tr>
<tr class="odd">
<td>750016</td>
<td>0.65563</td>
<td>0.78030</td>
<td>47:01</td>
</tr>
<tr class="even">
<td>800000</td>
<td>0.61551</td>
<td>0.77682</td>
<td>50:09</td>
</tr>
<tr class="odd">
<td>850048</td>
<td>0.61524</td>
<td>0.77560</td>
<td>53:18</td>
</tr>
<tr class="even">
<td>900032</td>
<td>0.64484</td>
<td>0.76186</td>
<td>56:25</td>
</tr>
<tr class="odd">
<td>950016</td>
<td>0.60820</td>
<td>0.76180</td>
<td>59:34</td>
</tr>
<tr class="even">
<td>999936</td>
<td>0.67128</td>
<td>0.75855</td>
<td>1:02:41</td>
</tr>
</tbody>
</table>
<p>

    </p><div>
      <progress value="3906" class="" max="3906" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [3906/3906 15:40&lt;00:00 #249984/250000 loss: 0.671 / 0.759]
    </div>
    
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-34-output-4.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># make sure it works at all, deocder cps</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>vqmodel <span class="op">=</span> vq_stoks.RQBottleneckTransformer.load_model(local_filename<span class="op">=</span><span class="st">'vqmodel-256c-dim64-4e-hyptuned-32gpu.model'</span>).cuda()</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>train_ds, val_ds <span class="op">=</span> load_datasets(<span class="st">'whisperspeech-t2s-512c-dim64/*-6454-*.tar.gz'</span>, <span class="dv">250000</span>, vq_codes<span class="op">=</span>vqmodel.vq_codes<span class="op">+</span><span class="dv">1</span>)</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> make_model(<span class="st">'base'</span>, dataset<span class="op">=</span>train_ds, ttoks_codes<span class="op">=</span><span class="dv">256</span>, stoks_width<span class="op">=</span>vqmodel.codebook_dim, tunables<span class="op">=</span>Tunables(weight_decay<span class="op">=</span><span class="fl">1e-3</span>, encoder_depth_ratio<span class="op">=</span><span class="fl">.5</span>, embedding_projector_lr_scale<span class="op">=</span><span class="dv">5</span>, cps_input<span class="op">=</span><span class="va">True</span>)).cuda()</span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a>model.load_frozen_semantic_embeddings(vqmodel)</span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a>train(<span class="st">"tsar-wx"</span>, model, train_ds, val_ds, half<span class="op">=</span><span class="va">True</span>, bs<span class="op">=</span><span class="dv">64</span>, lr<span class="op">=</span>model.tunables.lr0<span class="op">/</span><span class="dv">2</span>, epochs<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a>      warmup_steps<span class="op">=</span><span class="dv">1500</span>, weight_decay<span class="op">=</span>model.tunables.weight_decay, clip_gradient_norm<span class="op">=</span>model.tunables.clip_gradient_norm,</span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a>      table_row_every_iters<span class="op">=</span><span class="dv">50000</span>, run_valid_every_iters<span class="op">=</span><span class="dv">10000</span>)</span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a>model.save_model(<span class="st">'t2s-chr-base-base.en-2d-512c-dim64-deccps-6454.model'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="4" class="" max="4" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [4/4 1:02:42&lt;00:00]
    </div>
    

<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">samples</th>
<th data-quarto-table-cell-role="th">train</th>
<th data-quarto-table-cell-role="th">val</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>50048</td>
<td>1.64473</td>
<td>2.00029</td>
<td>03:08</td>
</tr>
<tr class="even">
<td>100032</td>
<td>1.39717</td>
<td>1.78492</td>
<td>06:16</td>
</tr>
<tr class="odd">
<td>150016</td>
<td>1.34219</td>
<td>1.63625</td>
<td>09:24</td>
</tr>
<tr class="even">
<td>200000</td>
<td>1.24191</td>
<td>1.48726</td>
<td>12:32</td>
</tr>
<tr class="odd">
<td>250048</td>
<td>1.14523</td>
<td>1.36233</td>
<td>15:40</td>
</tr>
<tr class="even">
<td>300032</td>
<td>1.04355</td>
<td>1.24797</td>
<td>18:48</td>
</tr>
<tr class="odd">
<td>350016</td>
<td>0.86282</td>
<td>1.20460</td>
<td>21:56</td>
</tr>
<tr class="even">
<td>400000</td>
<td>0.92359</td>
<td>1.12239</td>
<td>25:04</td>
</tr>
<tr class="odd">
<td>450048</td>
<td>0.89628</td>
<td>1.07208</td>
<td>28:13</td>
</tr>
<tr class="even">
<td>500032</td>
<td>0.86888</td>
<td>1.01718</td>
<td>31:21</td>
</tr>
<tr class="odd">
<td>550016</td>
<td>0.76435</td>
<td>1.00148</td>
<td>34:29</td>
</tr>
<tr class="even">
<td>600000</td>
<td>0.67413</td>
<td>0.99886</td>
<td>37:37</td>
</tr>
<tr class="odd">
<td>650048</td>
<td>0.74025</td>
<td>0.95487</td>
<td>40:46</td>
</tr>
<tr class="even">
<td>700032</td>
<td>0.74133</td>
<td>0.94135</td>
<td>43:54</td>
</tr>
<tr class="odd">
<td>750016</td>
<td>0.77500</td>
<td>0.92194</td>
<td>47:02</td>
</tr>
<tr class="even">
<td>800000</td>
<td>0.77986</td>
<td>0.90922</td>
<td>50:10</td>
</tr>
<tr class="odd">
<td>850048</td>
<td>0.65531</td>
<td>0.90641</td>
<td>53:18</td>
</tr>
<tr class="even">
<td>900032</td>
<td>0.78476</td>
<td>0.89178</td>
<td>56:26</td>
</tr>
<tr class="odd">
<td>950016</td>
<td>0.75005</td>
<td>0.88819</td>
<td>59:35</td>
</tr>
<tr class="even">
<td>999936</td>
<td>0.79055</td>
<td>0.88686</td>
<td>1:02:42</td>
</tr>
</tbody>
</table>
<p>

    </p><div>
      <progress value="3906" class="" max="3906" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [3906/3906 15:40&lt;00:00 #249984/250000 loss: 0.791 / 0.887]
    </div>
    
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-35-output-4.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>vqmodel <span class="op">=</span> vq_stoks.RQBottleneckTransformer.load_model(local_filename<span class="op">=</span><span class="st">'vqmodel-256c-dim64-4e-hyptuned-32gpu.model'</span>).cuda()</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>train_ds, val_ds <span class="op">=</span> load_datasets(<span class="st">'whisperspeech-t2s-512c-dim64/*-6454-*.tar.gz'</span>, <span class="dv">250000</span>, vq_codes<span class="op">=</span>vqmodel.vq_codes<span class="op">+</span><span class="dv">1</span>)</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> make_model(<span class="st">'base'</span>, dataset<span class="op">=</span>train_ds, frozen_embeddings_model<span class="op">=</span><span class="st">'vqmodel-256c-dim64-4e-hyptuned-32gpu.model'</span>, tunables<span class="op">=</span>Tunables(weight_decay<span class="op">=</span><span class="fl">1e-3</span>, encoder_depth_ratio<span class="op">=</span><span class="fl">.25</span>, embedding_projector_lr_scale<span class="op">=</span><span class="dv">5</span>, cps_input<span class="op">=</span><span class="va">True</span>)).cuda()</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a><span class="co"># model.load_frozen_semantic_embeddings(vqmodel)</span></span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a>model.load_checkpoint(<span class="st">'t2s_up_wds-epoch=0-step=17189-val_loss=0.68.ckpt'</span>)</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>model.save_model(<span class="st">'t2s-chr-base-base.en-2d-512c-dim64-deccps.model'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="co"># make sure it works at all, deocder cps</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>vqmodel <span class="op">=</span> vq_stoks.RQBottleneckTransformer.load_model(local_filename<span class="op">=</span><span class="st">'vqmodel-256c-dim64-4e-hyptuned-32gpu.model'</span>).cuda()</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>train_ds, val_ds <span class="op">=</span> load_datasets(<span class="st">'t2s-dim64-6454/*.tar.gz'</span>, <span class="dv">250000</span>, vq_codes<span class="op">=</span>vqmodel.vq_codes<span class="op">+</span><span class="dv">1</span>)</span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> make_model(<span class="st">'base'</span>, dataset<span class="op">=</span>train_ds, ttoks_codes<span class="op">=</span><span class="dv">256</span>, stoks_width<span class="op">=</span>vqmodel.codebook_dim, tunables<span class="op">=</span>Tunables(weight_decay<span class="op">=</span><span class="fl">1e-3</span>, encoder_depth_ratio<span class="op">=</span><span class="fl">.5</span>, embedding_projector_lr_scale<span class="op">=</span><span class="dv">5</span>, cps_input<span class="op">=</span><span class="va">True</span>)).cuda()</span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a>model.load_frozen_semantic_embeddings(vqmodel)</span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a>train(<span class="st">"tsar-wx"</span>, model, train_ds, val_ds, half<span class="op">=</span><span class="va">True</span>, bs<span class="op">=</span><span class="dv">64</span>, lr<span class="op">=</span>model.tunables.lr0<span class="op">/</span><span class="dv">2</span>, epochs<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a>      warmup_steps<span class="op">=</span><span class="dv">1500</span>, weight_decay<span class="op">=</span>model.tunables.weight_decay, clip_gradient_norm<span class="op">=</span>model.tunables.clip_gradient_norm,</span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a>      table_row_every_iters<span class="op">=</span><span class="dv">50000</span>, run_valid_every_iters<span class="op">=</span><span class="dv">10000</span>)</span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a>model.save_model(<span class="st">'t2s-chr-base-base.en-2d-512c-dim64-deccps-mixed6454.model'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="4" class="" max="4" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [4/4 1:02:41&lt;00:00]
    </div>
    

<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">samples</th>
<th data-quarto-table-cell-role="th">train</th>
<th data-quarto-table-cell-role="th">val</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>50048</td>
<td>1.60500</td>
<td>1.71495</td>
<td>03:08</td>
</tr>
<tr class="even">
<td>100032</td>
<td>1.42996</td>
<td>1.49575</td>
<td>06:15</td>
</tr>
<tr class="odd">
<td>150016</td>
<td>1.30471</td>
<td>1.35728</td>
<td>09:23</td>
</tr>
<tr class="even">
<td>200000</td>
<td>1.23745</td>
<td>1.28199</td>
<td>12:31</td>
</tr>
<tr class="odd">
<td>250048</td>
<td>1.19447</td>
<td>1.22556</td>
<td>15:39</td>
</tr>
<tr class="even">
<td>300032</td>
<td>1.17491</td>
<td>1.16905</td>
<td>18:47</td>
</tr>
<tr class="odd">
<td>350016</td>
<td>1.10648</td>
<td>1.11482</td>
<td>21:55</td>
</tr>
<tr class="even">
<td>400000</td>
<td>0.96267</td>
<td>1.04749</td>
<td>25:03</td>
</tr>
<tr class="odd">
<td>450048</td>
<td>0.91607</td>
<td>0.96573</td>
<td>28:11</td>
</tr>
<tr class="even">
<td>500032</td>
<td>0.86155</td>
<td>0.90699</td>
<td>31:19</td>
</tr>
<tr class="odd">
<td>550016</td>
<td>0.82900</td>
<td>0.86232</td>
<td>34:28</td>
</tr>
<tr class="even">
<td>600000</td>
<td>0.81113</td>
<td>0.83169</td>
<td>37:36</td>
</tr>
<tr class="odd">
<td>650048</td>
<td>0.79252</td>
<td>0.80817</td>
<td>40:44</td>
</tr>
<tr class="even">
<td>700032</td>
<td>0.76063</td>
<td>0.79134</td>
<td>43:52</td>
</tr>
<tr class="odd">
<td>750016</td>
<td>0.73414</td>
<td>0.77928</td>
<td>47:01</td>
</tr>
<tr class="even">
<td>800000</td>
<td>0.75583</td>
<td>0.76989</td>
<td>50:09</td>
</tr>
<tr class="odd">
<td>850048</td>
<td>0.70969</td>
<td>0.76218</td>
<td>53:17</td>
</tr>
<tr class="even">
<td>900032</td>
<td>0.74606</td>
<td>0.75786</td>
<td>56:25</td>
</tr>
<tr class="odd">
<td>950016</td>
<td>0.73967</td>
<td>0.75527</td>
<td>59:33</td>
</tr>
<tr class="even">
<td>999936</td>
<td>0.73023</td>
<td>0.75428</td>
<td>1:02:41</td>
</tr>
</tbody>
</table>
<p>

    </p><div>
      <progress value="3906" class="" max="3906" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [3906/3906 15:40&lt;00:00 #249984/250000 loss: 0.730 / 0.754]
    </div>
    
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-37-output-4.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co"># make sure it works at all, deocder cps</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>vqmodel <span class="op">=</span> vq_stoks.RQBottleneckTransformer.load_model(local_filename<span class="op">=</span><span class="st">'vqmodel-256c-dim64-4e-hyptuned-32gpu.model'</span>).cuda()</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>train_ds, val_ds <span class="op">=</span> load_datasets(<span class="st">'t2s-dim64-6454/*.tar.gz'</span>, <span class="dv">250000</span>, vq_codes<span class="op">=</span>vqmodel.vq_codes<span class="op">+</span><span class="dv">1</span>)</span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> make_model(<span class="st">'base'</span>, dataset<span class="op">=</span>train_ds, ttoks_codes<span class="op">=</span><span class="dv">256</span>, stoks_width<span class="op">=</span>vqmodel.codebook_dim, tunables<span class="op">=</span>Tunables(weight_decay<span class="op">=</span><span class="fl">1e-3</span>, encoder_depth_ratio<span class="op">=</span><span class="fl">.5</span>, embedding_projector_lr_scale<span class="op">=</span><span class="dv">5</span>, cps_input<span class="op">=</span><span class="va">True</span>)).cuda()</span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a>model.load_frozen_semantic_embeddings(vqmodel)</span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a>train(<span class="st">"tsar-wx"</span>, model, train_ds, val_ds, half<span class="op">=</span><span class="va">True</span>, bs<span class="op">=</span><span class="dv">64</span>, lr<span class="op">=</span>model.tunables.lr0, epochs<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a>      warmup_steps<span class="op">=</span><span class="dv">1500</span>, weight_decay<span class="op">=</span>model.tunables.weight_decay, clip_gradient_norm<span class="op">=</span>model.tunables.clip_gradient_norm,</span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a>      table_row_every_iters<span class="op">=</span><span class="dv">50000</span>, run_valid_every_iters<span class="op">=</span><span class="dv">10000</span>)</span>
<span id="cb45-9"><a href="#cb45-9" aria-hidden="true" tabindex="-1"></a>model.save_model(<span class="st">'t2s-chr-base-base.en-2d-512c-dim64-deccps-mixed6454-2.model'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="4" class="" max="4" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [4/4 1:02:38&lt;00:00]
    </div>
    

<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">samples</th>
<th data-quarto-table-cell-role="th">train</th>
<th data-quarto-table-cell-role="th">val</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>50048</td>
<td>1.57490</td>
<td>1.65323</td>
<td>03:08</td>
</tr>
<tr class="even">
<td>100032</td>
<td>1.30007</td>
<td>1.41616</td>
<td>06:16</td>
</tr>
<tr class="odd">
<td>150016</td>
<td>1.27452</td>
<td>1.29610</td>
<td>09:24</td>
</tr>
<tr class="even">
<td>200000</td>
<td>1.21859</td>
<td>1.23891</td>
<td>12:32</td>
</tr>
<tr class="odd">
<td>250048</td>
<td>1.13482</td>
<td>1.20451</td>
<td>15:40</td>
</tr>
<tr class="even">
<td>300032</td>
<td>1.12068</td>
<td>1.18082</td>
<td>18:48</td>
</tr>
<tr class="odd">
<td>350016</td>
<td>1.09567</td>
<td>1.16008</td>
<td>21:55</td>
</tr>
<tr class="even">
<td>400000</td>
<td>1.11592</td>
<td>1.11699</td>
<td>25:03</td>
</tr>
<tr class="odd">
<td>450048</td>
<td>1.02158</td>
<td>1.06097</td>
<td>28:11</td>
</tr>
<tr class="even">
<td>500032</td>
<td>0.96963</td>
<td>1.01791</td>
<td>31:20</td>
</tr>
<tr class="odd">
<td>550016</td>
<td>0.94567</td>
<td>0.97895</td>
<td>34:28</td>
</tr>
<tr class="even">
<td>600000</td>
<td>0.98367</td>
<td>0.96788</td>
<td>37:36</td>
</tr>
<tr class="odd">
<td>650048</td>
<td>0.97887</td>
<td>1.08697</td>
<td>40:44</td>
</tr>
<tr class="even">
<td>700032</td>
<td>1.01399</td>
<td>1.05165</td>
<td>43:52</td>
</tr>
<tr class="odd">
<td>750016</td>
<td>0.96321</td>
<td>1.03418</td>
<td>47:00</td>
</tr>
<tr class="even">
<td>800000</td>
<td>1.01943</td>
<td>1.03342</td>
<td>50:07</td>
</tr>
<tr class="odd">
<td>850048</td>
<td>0.94176</td>
<td>1.02338</td>
<td>53:16</td>
</tr>
<tr class="even">
<td>900032</td>
<td>0.97142</td>
<td>1.01605</td>
<td>56:24</td>
</tr>
<tr class="odd">
<td>950016</td>
<td>1.01311</td>
<td>1.01310</td>
<td>59:31</td>
</tr>
<tr class="even">
<td>999936</td>
<td>0.96521</td>
<td>1.01233</td>
<td>1:02:38</td>
</tr>
</tbody>
</table>
<p>

    </p><div>
      <progress value="3906" class="" max="3906" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [3906/3906 15:39&lt;00:00 #249984/250000 loss: 0.965 / 1.012]
    </div>
    
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-38-output-4.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="co"># make sure it works at all</span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>vqmodel <span class="op">=</span> vq_stoks.RQBottleneckTransformer.load_model(local_filename<span class="op">=</span><span class="st">'vqmodel-256c-dim64-4e-hyptuned-32gpu.model'</span>).cuda()</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>train_ds, val_ds <span class="op">=</span> load_datasets(<span class="st">'whisperspeech-t2s-512c-dim64/*.tar.gz'</span>, <span class="dv">250000</span>, vq_codes<span class="op">=</span>vqmodel.vq_codes<span class="op">+</span><span class="dv">1</span>)</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> make_model(<span class="st">'base'</span>, dataset<span class="op">=</span>train_ds, ttoks_codes<span class="op">=</span><span class="dv">256</span>, stoks_width<span class="op">=</span>vqmodel.codebook_dim, tunables<span class="op">=</span>Tunables(weight_decay<span class="op">=</span><span class="fl">1e-3</span>, encoder_depth_ratio<span class="op">=</span><span class="fl">.5</span>, embedding_projector_lr_scale<span class="op">=</span><span class="dv">5</span>)).cuda()</span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>model.load_frozen_semantic_embeddings(vqmodel)</span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a>train(<span class="st">"tsar-wx"</span>, model, train_ds, val_ds, half<span class="op">=</span><span class="va">True</span>, bs<span class="op">=</span><span class="dv">64</span>, lr<span class="op">=</span>model.tunables.lr0<span class="op">/</span><span class="dv">2</span>, epochs<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a>      warmup_steps<span class="op">=</span><span class="dv">1500</span>, weight_decay<span class="op">=</span>model.tunables.weight_decay, clip_gradient_norm<span class="op">=</span>model.tunables.clip_gradient_norm,</span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a>      table_row_every_iters<span class="op">=</span><span class="dv">50000</span>, run_valid_every_iters<span class="op">=</span><span class="dv">10000</span>)</span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a>model.save_model(<span class="st">'t2s-chr-base-base.en-2d-512c-dim64-6454.model'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="4" class="" max="4" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [4/4 1:02:36&lt;00:00]
    </div>
    

<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">samples</th>
<th data-quarto-table-cell-role="th">train</th>
<th data-quarto-table-cell-role="th">val</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>50048</td>
<td>1.69897</td>
<td>1.60454</td>
<td>03:08</td>
</tr>
<tr class="even">
<td>100032</td>
<td>1.48860</td>
<td>1.41279</td>
<td>06:15</td>
</tr>
<tr class="odd">
<td>150016</td>
<td>1.29894</td>
<td>1.29969</td>
<td>09:23</td>
</tr>
<tr class="even">
<td>200000</td>
<td>1.18683</td>
<td>1.20707</td>
<td>12:31</td>
</tr>
<tr class="odd">
<td>250048</td>
<td>1.00874</td>
<td>1.06997</td>
<td>15:39</td>
</tr>
<tr class="even">
<td>300032</td>
<td>0.96573</td>
<td>0.97376</td>
<td>18:47</td>
</tr>
<tr class="odd">
<td>350016</td>
<td>0.93865</td>
<td>0.93088</td>
<td>21:55</td>
</tr>
<tr class="even">
<td>400000</td>
<td>0.84999</td>
<td>0.90498</td>
<td>25:02</td>
</tr>
<tr class="odd">
<td>450048</td>
<td>0.87169</td>
<td>0.89323</td>
<td>28:10</td>
</tr>
<tr class="even">
<td>500032</td>
<td>0.88411</td>
<td>0.87570</td>
<td>31:19</td>
</tr>
<tr class="odd">
<td>550016</td>
<td>0.84026</td>
<td>0.85508</td>
<td>34:26</td>
</tr>
<tr class="even">
<td>600000</td>
<td>0.88852</td>
<td>0.84814</td>
<td>37:34</td>
</tr>
<tr class="odd">
<td>650048</td>
<td>0.80170</td>
<td>0.83732</td>
<td>40:42</td>
</tr>
<tr class="even">
<td>700032</td>
<td>0.80375</td>
<td>0.83114</td>
<td>43:50</td>
</tr>
<tr class="odd">
<td>750016</td>
<td>0.81585</td>
<td>0.83003</td>
<td>46:58</td>
</tr>
<tr class="even">
<td>800000</td>
<td>0.75375</td>
<td>0.81828</td>
<td>50:06</td>
</tr>
<tr class="odd">
<td>850048</td>
<td>0.84435</td>
<td>0.81684</td>
<td>53:14</td>
</tr>
<tr class="even">
<td>900032</td>
<td>0.79457</td>
<td>0.81153</td>
<td>56:21</td>
</tr>
<tr class="odd">
<td>950016</td>
<td>0.86009</td>
<td>0.81152</td>
<td>59:29</td>
</tr>
<tr class="even">
<td>999936</td>
<td>0.78353</td>
<td>0.80970</td>
<td>1:02:36</td>
</tr>
</tbody>
</table>
<p>

    </p><div>
      <progress value="3906" class="" max="3906" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [3906/3906 15:39&lt;00:00 #249984/250000 loss: 0.784 / 0.810]
    </div>
    
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-39-output-4.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="co"># make sure it works at all</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>vqmodel <span class="op">=</span> vq_stoks.RQBottleneckTransformer.load_model(local_filename<span class="op">=</span><span class="st">'vqmodel-256c-dim64-4e-hyptuned-32gpu.model'</span>).cuda()</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>train_ds, val_ds <span class="op">=</span> load_datasets(<span class="st">'whisperspeech-t2s-512c-dim64/*.tar.gz'</span>, <span class="dv">67000</span>, vq_codes<span class="op">=</span>vqmodel.vq_codes<span class="op">+</span><span class="dv">1</span>)</span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> make_model(<span class="st">'tiny'</span>, dataset<span class="op">=</span>train_ds, ttoks_codes<span class="op">=</span><span class="dv">256</span>, stoks_width<span class="op">=</span>vqmodel.codebook_dim, tunables<span class="op">=</span>Tunables(weight_decay<span class="op">=</span><span class="fl">1e-3</span>, encoder_depth_ratio<span class="op">=</span><span class="fl">.5</span>, embedding_projector_lr_scale<span class="op">=</span><span class="dv">5</span>)).cuda()</span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a><span class="co"># model.load_frozen_semantic_embeddings(vqmodel)</span></span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a>train(<span class="st">"tsar-wx"</span>, model, train_ds, val_ds, half<span class="op">=</span><span class="va">True</span>, bs<span class="op">=</span><span class="dv">64</span>, lr<span class="op">=</span>model.tunables.lr0, epochs<span class="op">=</span><span class="dv">8</span>,</span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a>      warmup_steps<span class="op">=</span><span class="dv">1500</span>, weight_decay<span class="op">=</span>model.tunables.weight_decay, clip_gradient_norm<span class="op">=</span>model.tunables.clip_gradient_norm,</span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a>      table_row_every_iters<span class="op">=</span><span class="dv">50000</span>, run_valid_every_iters<span class="op">=</span><span class="dv">10000</span>)</span>
<span id="cb47-9"><a href="#cb47-9" aria-hidden="true" tabindex="-1"></a><span class="co"># model.save_model('t2s-chr-micro-base.en-2d-4096c-cosine32-padfix-premlp-learnpos-5e-large-6454.model')</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="8" class="" max="8" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [8/8 16:34&lt;00:00]
    </div>
    

<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">samples</th>
<th data-quarto-table-cell-role="th">train</th>
<th data-quarto-table-cell-role="th">val</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>50048</td>
<td>1.42096</td>
<td>1.76318</td>
<td>01:32</td>
</tr>
<tr class="even">
<td>100032</td>
<td>1.27539</td>
<td>1.56825</td>
<td>03:05</td>
</tr>
<tr class="odd">
<td>150016</td>
<td>1.18232</td>
<td>1.37608</td>
<td>04:38</td>
</tr>
<tr class="even">
<td>200000</td>
<td>1.02870</td>
<td>1.29385</td>
<td>06:10</td>
</tr>
<tr class="odd">
<td>250048</td>
<td>0.76373</td>
<td>1.06234</td>
<td>07:43</td>
</tr>
<tr class="even">
<td>300032</td>
<td>0.80656</td>
<td>0.96563</td>
<td>09:16</td>
</tr>
<tr class="odd">
<td>350016</td>
<td>0.81366</td>
<td>0.92360</td>
<td>10:49</td>
</tr>
<tr class="even">
<td>400000</td>
<td>0.71119</td>
<td>0.89729</td>
<td>12:22</td>
</tr>
<tr class="odd">
<td>450048</td>
<td>0.68225</td>
<td>0.86979</td>
<td>13:55</td>
</tr>
<tr class="even">
<td>500032</td>
<td>0.69954</td>
<td>0.85986</td>
<td>15:28</td>
</tr>
<tr class="odd">
<td>535552</td>
<td>0.68638</td>
<td>0.85534</td>
<td>16:34</td>
</tr>
</tbody>
</table>
<p>

    </p><div>
      <progress value="1046" class="" max="1046" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [1046/1046 02:04&lt;00:00 #66944/67000 loss: 0.686 / 0.855]
    </div>
    
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-40-output-4.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="co"># make sure it works at all</span></span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>vqmodel <span class="op">=</span> vq_stoks.RQBottleneckTransformer.load_model(local_filename<span class="op">=</span><span class="st">'vqmodel-256c-dim64-4e-hyptuned-32gpu.model'</span>).cuda()</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>train_ds, val_ds <span class="op">=</span> load_datasets(<span class="st">'whisperspeech-t2s-512c-dim64/*.tar.gz'</span>, <span class="dv">67000</span>, vq_codes<span class="op">=</span>vqmodel.vq_codes<span class="op">+</span><span class="dv">1</span>)</span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> make_model(<span class="st">'tiny'</span>, dataset<span class="op">=</span>train_ds, ttoks_codes<span class="op">=</span><span class="dv">256</span>, tunables<span class="op">=</span>Tunables(weight_decay<span class="op">=</span><span class="fl">1e-3</span>, encoder_depth_ratio<span class="op">=</span><span class="fl">.5</span>, embedding_projector_lr_scale<span class="op">=</span><span class="dv">5</span>)).cuda()</span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a><span class="co"># model.load_frozen_semantic_embeddings(vqmodel)</span></span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a>train(<span class="st">"tsar-wx"</span>, model, train_ds, val_ds, half<span class="op">=</span><span class="va">True</span>, bs<span class="op">=</span><span class="dv">64</span>, lr<span class="op">=</span>model.tunables.lr0, epochs<span class="op">=</span><span class="dv">8</span>,</span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a>      warmup_steps<span class="op">=</span><span class="dv">1500</span>, weight_decay<span class="op">=</span>model.tunables.weight_decay, clip_gradient_norm<span class="op">=</span>model.tunables.clip_gradient_norm,</span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a>      table_row_every_iters<span class="op">=</span><span class="dv">50000</span>, run_valid_every_iters<span class="op">=</span><span class="dv">10000</span>)</span>
<span id="cb48-9"><a href="#cb48-9" aria-hidden="true" tabindex="-1"></a><span class="co"># model.save_model('t2s-chr-micro-base.en-2d-4096c-cosine32-padfix-premlp-learnpos-5e-large-6454.model')</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-41-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="5" class="" max="8" style="width:300px; height:20px; vertical-align: middle;"></progress>
      62.50% [5/8 10:22&lt;06:13]
    </div>
    

<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">samples</th>
<th data-quarto-table-cell-role="th">train</th>
<th data-quarto-table-cell-role="th">val</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>50048</td>
<td>1.40568</td>
<td>1.90047</td>
<td>01:33</td>
</tr>
<tr class="even">
<td>100032</td>
<td>1.11408</td>
<td>1.45658</td>
<td>03:06</td>
</tr>
<tr class="odd">
<td>150016</td>
<td>1.02597</td>
<td>1.29036</td>
<td>04:39</td>
</tr>
<tr class="even">
<td>200000</td>
<td>0.84436</td>
<td>1.09712</td>
<td>06:11</td>
</tr>
<tr class="odd">
<td>250048</td>
<td>0.81835</td>
<td>0.99984</td>
<td>07:44</td>
</tr>
<tr class="even">
<td>300032</td>
<td>0.74737</td>
<td>0.96436</td>
<td>09:16</td>
</tr>
<tr class="odd">
<td>350016</td>
<td>0.72640</td>
<td>0.92548</td>
<td>10:50</td>
</tr>
</tbody>
</table>
<p>

    </p><div>
      <progress value="830" class="" max="1046" style="width:300px; height:20px; vertical-align: middle;"></progress>
      79.35% [830/1046 01:37&lt;00:25 #48480/67000 loss: 0.719 / 0.905]
    </div>
    
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="co"># make sure it works at all</span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>train_ds, val_ds <span class="op">=</span> load_datasets(<span class="st">'txts-large-6454.feather'</span>, <span class="st">'stoks-base.en-2d-4096c-cosine32-padfix-premlp-learnpos-5e.feather'</span>)</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> make_model(<span class="st">'micro'</span>, dataset<span class="op">=</span>train_ds, ttoks_codes<span class="op">=</span><span class="dv">256</span>, tunables<span class="op">=</span>Tunables(encoder_depth_ratio<span class="op">=</span><span class="fl">0.75</span>)).cuda()</span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a>train(<span class="st">"tsar-wx"</span>, model, train_ds, val_ds, half<span class="op">=</span><span class="va">True</span>, bs<span class="op">=</span><span class="dv">64</span>, lr<span class="op">=</span>model.tunables.lr0, epochs<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>      warmup_steps<span class="op">=</span><span class="dv">1500</span>, weight_decay<span class="op">=</span>model.tunables.weight_decay, clip_gradient_norm<span class="op">=</span>model.tunables.clip_gradient_norm,</span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a>      table_row_every_iters<span class="op">=</span><span class="dv">50000</span>, run_valid_every_iters<span class="op">=</span><span class="dv">10000</span>)</span>
<span id="cb49-7"><a href="#cb49-7" aria-hidden="true" tabindex="-1"></a><span class="co"># model.save_model('t2s-chr-micro-base.en-2d-4096c-cosine32-padfix-premlp-learnpos-5e-large-6454.model')</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="4" class="" max="4" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [4/4 09:55&lt;00:00]
    </div>
    

<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">samples</th>
<th data-quarto-table-cell-role="th">train</th>
<th data-quarto-table-cell-role="th">val</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>50048</td>
<td>2.78801</td>
<td>2.96649</td>
<td>00:38</td>
</tr>
<tr class="even">
<td>100032</td>
<td>2.17206</td>
<td>2.31484</td>
<td>01:16</td>
</tr>
<tr class="odd">
<td>150016</td>
<td>1.72292</td>
<td>1.83490</td>
<td>01:54</td>
</tr>
<tr class="even">
<td>200000</td>
<td>1.61193</td>
<td>1.71674</td>
<td>02:33</td>
</tr>
<tr class="odd">
<td>250048</td>
<td>1.56491</td>
<td>1.66836</td>
<td>03:11</td>
</tr>
<tr class="even">
<td>300032</td>
<td>1.52783</td>
<td>1.63776</td>
<td>03:49</td>
</tr>
<tr class="odd">
<td>350016</td>
<td>1.50633</td>
<td>1.61980</td>
<td>04:27</td>
</tr>
<tr class="even">
<td>400000</td>
<td>1.50440</td>
<td>1.59825</td>
<td>05:05</td>
</tr>
<tr class="odd">
<td>450048</td>
<td>1.49942</td>
<td>1.58279</td>
<td>05:43</td>
</tr>
<tr class="even">
<td>500032</td>
<td>1.46938</td>
<td>1.56660</td>
<td>06:21</td>
</tr>
<tr class="odd">
<td>550016</td>
<td>1.47412</td>
<td>1.55321</td>
<td>06:59</td>
</tr>
<tr class="even">
<td>600000</td>
<td>1.47976</td>
<td>1.54060</td>
<td>07:37</td>
</tr>
<tr class="odd">
<td>650048</td>
<td>1.45918</td>
<td>1.53168</td>
<td>08:15</td>
</tr>
<tr class="even">
<td>700032</td>
<td>1.44378</td>
<td>1.52434</td>
<td>08:53</td>
</tr>
<tr class="odd">
<td>750016</td>
<td>1.43097</td>
<td>1.52031</td>
<td>09:32</td>
</tr>
<tr class="even">
<td>780544</td>
<td>1.43909</td>
<td>1.51978</td>
<td>09:55</td>
</tr>
</tbody>
</table>
<p>

    </p><div>
      <progress value="3049" class="" max="3049" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [3049/3049 02:28&lt;00:00 #195137/195093 loss: 1.439 / 1.520]
    </div>
    
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/root/workspace/spear-tts-pytorch/whisperspeech/train.py:63: UserWarning: Attempt to set non-positive xlim on a log-scaled axis will be ignored.
  loss_p.clear()
/root/workspace/spear-tts-pytorch/whisperspeech/train.py:66: UserWarning: Attempt to set non-positive xlim on a log-scaled axis will be ignored.
  loss_p.set_xlim(500, self.total_steps)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-42-output-5.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="co"># make sure it works at all</span></span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>train_ds, val_ds <span class="op">=</span> load_datasets(<span class="st">'txts-large-6454.feather'</span>, <span class="st">'stoks-base.en-2d-4096c-cosine32-padfix-premlp-learnpos-5e.feather'</span>)</span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> make_model(<span class="st">'micro'</span>, dataset<span class="op">=</span>train_ds, ttoks_codes<span class="op">=</span><span class="dv">256</span>, tunables<span class="op">=</span>Tunables(encoder_depth_ratio<span class="op">=</span><span class="fl">0.75</span>)).cuda()</span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>train(<span class="st">"tsar-wx"</span>, model, train_ds, val_ds, half<span class="op">=</span><span class="va">True</span>, bs<span class="op">=</span><span class="dv">64</span>, lr<span class="op">=</span>model.tunables.lr0, epochs<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a>      warmup_steps<span class="op">=</span><span class="dv">1500</span>, weight_decay<span class="op">=</span>model.tunables.weight_decay, clip_gradient_norm<span class="op">=</span>model.tunables.clip_gradient_norm,</span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a>      table_row_every_iters<span class="op">=</span><span class="dv">50000</span>, run_valid_every_iters<span class="op">=</span><span class="dv">10000</span>)</span>
<span id="cb51-7"><a href="#cb51-7" aria-hidden="true" tabindex="-1"></a><span class="co"># model.save_model('t2s-chr-micro-base.en-2d-4096c-cosine32-padfix-premlp-learnpos-5e-large-6454.model')</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="4" class="" max="4" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [4/4 10:16&lt;00:00]
    </div>
    

<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">samples</th>
<th data-quarto-table-cell-role="th">train</th>
<th data-quarto-table-cell-role="th">val</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>50048</td>
<td>2.77018</td>
<td>3.21193</td>
<td>00:39</td>
</tr>
<tr class="even">
<td>100032</td>
<td>2.19978</td>
<td>2.33585</td>
<td>01:19</td>
</tr>
<tr class="odd">
<td>150016</td>
<td>1.72773</td>
<td>1.81870</td>
<td>01:58</td>
</tr>
<tr class="even">
<td>200000</td>
<td>1.61463</td>
<td>1.72023</td>
<td>02:38</td>
</tr>
<tr class="odd">
<td>250048</td>
<td>1.58084</td>
<td>1.67646</td>
<td>03:17</td>
</tr>
<tr class="even">
<td>300032</td>
<td>1.53818</td>
<td>1.64994</td>
<td>03:57</td>
</tr>
<tr class="odd">
<td>350016</td>
<td>1.52391</td>
<td>1.62680</td>
<td>04:36</td>
</tr>
<tr class="even">
<td>400000</td>
<td>1.49011</td>
<td>1.60559</td>
<td>05:16</td>
</tr>
<tr class="odd">
<td>450048</td>
<td>1.50526</td>
<td>1.58791</td>
<td>05:55</td>
</tr>
<tr class="even">
<td>500032</td>
<td>1.48537</td>
<td>1.57416</td>
<td>06:34</td>
</tr>
<tr class="odd">
<td>550016</td>
<td>1.50840</td>
<td>1.56029</td>
<td>07:14</td>
</tr>
<tr class="even">
<td>600000</td>
<td>1.44101</td>
<td>1.54977</td>
<td>07:54</td>
</tr>
<tr class="odd">
<td>650048</td>
<td>1.44604</td>
<td>1.53820</td>
<td>08:33</td>
</tr>
<tr class="even">
<td>700032</td>
<td>1.45949</td>
<td>1.53106</td>
<td>09:12</td>
</tr>
<tr class="odd">
<td>750016</td>
<td>1.43625</td>
<td>1.52777</td>
<td>09:52</td>
</tr>
<tr class="even">
<td>780544</td>
<td>1.47563</td>
<td>1.52655</td>
<td>10:16</td>
</tr>
</tbody>
</table>
<p>

    </p><div>
      <progress value="3049" class="" max="3049" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [3049/3049 02:34&lt;00:00 #195137/195093 loss: 1.476 / 1.527]
    </div>
    
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/root/workspace/spear-tts-pytorch/whisperspeech/train.py:63: UserWarning: Attempt to set non-positive xlim on a log-scaled axis will be ignored.
  loss_p.clear()
/root/workspace/spear-tts-pytorch/whisperspeech/train.py:66: UserWarning: Attempt to set non-positive xlim on a log-scaled axis will be ignored.
  loss_p.set_xlim(500, self.total_steps)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-43-output-5.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="co"># make sure it works at all</span></span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>train_ds, val_ds <span class="op">=</span> load_datasets(<span class="st">'txts-large-6454.feather'</span>, <span class="st">'stoks-2d-512c-cosine-padfix-premlp-learnpos-5e.feather'</span>)</span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> make_model(<span class="st">'tiny'</span>, dataset<span class="op">=</span>train_ds).cuda()</span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a>train(<span class="st">"tsar-wx"</span>, model, train_ds, val_ds, half<span class="op">=</span><span class="va">True</span>, bs<span class="op">=</span><span class="dv">64</span>, lr<span class="op">=</span>model.tunables.lr0, epochs<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a>      warmup_steps<span class="op">=</span>model.tunables.warmup_steps, weight_decay<span class="op">=</span>model.tunables.weight_decay, clip_gradient_norm<span class="op">=</span>model.tunables.clip_gradient_norm,</span>
<span id="cb53-6"><a href="#cb53-6" aria-hidden="true" tabindex="-1"></a>      table_row_every_iters<span class="op">=</span><span class="dv">25000</span>, run_valid_every_iters<span class="op">=</span><span class="dv">5000</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="1" class="" max="1" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [1/1 06:33&lt;00:00]
    </div>
    

<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">samples</th>
<th data-quarto-table-cell-role="th">train</th>
<th data-quarto-table-cell-role="th">val</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>25024</td>
<td>2.60773</td>
<td>3.69719</td>
<td>00:50</td>
</tr>
<tr class="even">
<td>50048</td>
<td>2.17093</td>
<td>2.28062</td>
<td>01:40</td>
</tr>
<tr class="odd">
<td>75008</td>
<td>1.84834</td>
<td>1.99388</td>
<td>02:31</td>
</tr>
<tr class="even">
<td>100032</td>
<td>1.69955</td>
<td>1.83580</td>
<td>03:21</td>
</tr>
<tr class="odd">
<td>125056</td>
<td>1.58153</td>
<td>1.71103</td>
<td>04:12</td>
</tr>
<tr class="even">
<td>150016</td>
<td>1.52247</td>
<td>1.63647</td>
<td>05:02</td>
</tr>
<tr class="odd">
<td>175040</td>
<td>1.46376</td>
<td>1.56754</td>
<td>05:52</td>
</tr>
<tr class="even">
<td>195136</td>
<td>1.42067</td>
<td>1.54652</td>
<td>06:33</td>
</tr>
</tbody>
</table>
<p>

    </p><div>
      <progress value="3049" class="" max="3049" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [3049/3049 06:33&lt;00:00 #195137/195093 loss: 1.421 / 1.547]
    </div>
    
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/root/workspace/spear-tts-pytorch/whisperspeech/train.py:63: UserWarning: Attempt to set non-positive xlim on a log-scaled axis will be ignored.
  loss_p.clear()
/root/workspace/spear-tts-pytorch/whisperspeech/train.py:66: UserWarning: Attempt to set non-positive xlim on a log-scaled axis will be ignored.
  loss_p.set_xlim(500, self.total_steps)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-44-output-5.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>vqmodel <span class="op">=</span> RQBottleneckTransformer.load_model(local_filename<span class="op">=</span><span class="st">'vq-base.en-2d-4096c-cosine32-padfix-premlp-learnpos-5e.model'</span>).cuda()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="co"># reuse the VQ stoks padding token</span></span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>train_ds, val_ds <span class="op">=</span> load_datasets(<span class="st">'txts-large-6454-cleaned.feather'</span>, <span class="st">'stoks-base.en-2d-4096c-cosine32-padfix-premlp-learnpos-5e.feather'</span>)</span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> make_model(<span class="st">'tiny'</span>, dataset<span class="op">=</span>train_ds, ttoks_codes<span class="op">=</span><span class="dv">256</span>, stoks_width<span class="op">=</span><span class="dv">32</span>).cuda()</span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad(): model.decoder.embedding.weight[:] <span class="op">=</span> vqmodel.rq.layers[<span class="dv">0</span>]._codebook.embed[<span class="dv">0</span>]</span>
<span id="cb56-5"><a href="#cb56-5" aria-hidden="true" tabindex="-1"></a>model.decoder.embedding.lr_scale <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb56-6"><a href="#cb56-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> m <span class="kw">in</span> [model.decoder.emb_to_hidden, model.decoder.hidden_to_emb]:</span>
<span id="cb56-7"><a href="#cb56-7" aria-hidden="true" tabindex="-1"></a>    m.lr_scale <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb56-8"><a href="#cb56-8" aria-hidden="true" tabindex="-1"></a>    std <span class="op">=</span> model.tunables.init_std</span>
<span id="cb56-9"><a href="#cb56-9" aria-hidden="true" tabindex="-1"></a>    torch.nn.init.trunc_normal_(m.weight, std<span class="op">=</span>std, a<span class="op">=-</span><span class="dv">3</span><span class="op">*</span>std, b<span class="op">=</span><span class="dv">3</span><span class="op">*</span>std)</span>
<span id="cb56-10"><a href="#cb56-10" aria-hidden="true" tabindex="-1"></a>train(<span class="st">"tsar-wx"</span>, model, train_ds, val_ds, half<span class="op">=</span><span class="va">True</span>, bs<span class="op">=</span><span class="dv">32</span>, lr<span class="op">=</span>model.tunables.lr0, epochs<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb56-11"><a href="#cb56-11" aria-hidden="true" tabindex="-1"></a>      warmup_steps<span class="op">=</span>model.tunables.warmup_steps, weight_decay<span class="op">=</span>model.tunables.weight_decay, clip_gradient_norm<span class="op">=</span>model.tunables.clip_gradient_norm,</span>
<span id="cb56-12"><a href="#cb56-12" aria-hidden="true" tabindex="-1"></a>      table_row_every_iters<span class="op">=</span><span class="dv">100000</span>, run_valid_every_iters<span class="op">=</span><span class="dv">25000</span>)</span>
<span id="cb56-13"><a href="#cb56-13" aria-hidden="true" tabindex="-1"></a>model.save_model(<span class="st">'t2s-tiny-eot0.1x.model'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="1" class="" max="1" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [1/1 07:24&lt;00:00]
    </div>
    

<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">samples</th>
<th data-quarto-table-cell-role="th">train</th>
<th data-quarto-table-cell-role="th">val</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>100000</td>
<td>2.00655</td>
<td>2.57978</td>
<td>03:57</td>
</tr>
<tr class="even">
<td>187296</td>
<td>1.56021</td>
<td>1.91384</td>
<td>07:24</td>
</tr>
</tbody>
</table>
<p>

    </p><div>
      <progress value="5853" class="" max="5853" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [5853/5853 07:24&lt;00:00 #187296/187286 loss: 1.560 / 1.914]
    </div>
    
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/root/workspace/spear-tts-pytorch/whisperspeech/train.py:63: UserWarning: Attempt to set non-positive xlim on a log-scaled axis will be ignored.
  loss_p.clear()
/root/workspace/spear-tts-pytorch/whisperspeech/train.py:66: UserWarning: Attempt to set non-positive xlim on a log-scaled axis will be ignored.
  loss_p.set_xlim(500, self.total_steps)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-46-output-5.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="co"># reuse the VQ stoks padding token</span></span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>train_ds, val_ds <span class="op">=</span> load_datasets(<span class="st">'txts-large-6454-cleaned.feather'</span>, <span class="st">'stoks-base.en-2d-4096c-cosine32-padfix-premlp-learnpos-5e.feather'</span>)</span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> make_model(<span class="st">'tiny'</span>, dataset<span class="op">=</span>train_ds, ttoks_codes<span class="op">=</span><span class="dv">256</span>, stoks_width<span class="op">=</span><span class="dv">32</span>).cuda()</span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad(): model.decoder.embedding.weight[:] <span class="op">=</span> vqmodel.rq.layers[<span class="dv">0</span>]._codebook.embed[<span class="dv">0</span>]</span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true" tabindex="-1"></a>model.decoder.embedding.lr_scale <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb58-6"><a href="#cb58-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> m <span class="kw">in</span> [model.decoder.emb_to_hidden, model.decoder.hidden_to_emb]:</span>
<span id="cb58-7"><a href="#cb58-7" aria-hidden="true" tabindex="-1"></a>    m.lr_scale <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb58-8"><a href="#cb58-8" aria-hidden="true" tabindex="-1"></a>    std <span class="op">=</span> model.tunables.init_std</span>
<span id="cb58-9"><a href="#cb58-9" aria-hidden="true" tabindex="-1"></a>    torch.nn.init.trunc_normal_(m.weight, std<span class="op">=</span>std, a<span class="op">=-</span><span class="dv">3</span><span class="op">*</span>std, b<span class="op">=</span><span class="dv">3</span><span class="op">*</span>std)</span>
<span id="cb58-10"><a href="#cb58-10" aria-hidden="true" tabindex="-1"></a>train(<span class="st">"tsar-wx"</span>, model, train_ds, val_ds, half<span class="op">=</span><span class="va">True</span>, bs<span class="op">=</span><span class="dv">32</span>, lr<span class="op">=</span>model.tunables.lr0, epochs<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb58-11"><a href="#cb58-11" aria-hidden="true" tabindex="-1"></a>      warmup_steps<span class="op">=</span>model.tunables.warmup_steps, weight_decay<span class="op">=</span>model.tunables.weight_decay, clip_gradient_norm<span class="op">=</span>model.tunables.clip_gradient_norm,</span>
<span id="cb58-12"><a href="#cb58-12" aria-hidden="true" tabindex="-1"></a>      table_row_every_iters<span class="op">=</span><span class="dv">100000</span>, run_valid_every_iters<span class="op">=</span><span class="dv">25000</span>)</span>
<span id="cb58-13"><a href="#cb58-13" aria-hidden="true" tabindex="-1"></a>model.save_model(<span class="st">'t2s-tiny-eot10x.model'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="1" class="" max="1" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [1/1 07:25&lt;00:00]
    </div>
    

<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">samples</th>
<th data-quarto-table-cell-role="th">train</th>
<th data-quarto-table-cell-role="th">val</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>100000</td>
<td>2.05328</td>
<td>2.59797</td>
<td>03:58</td>
</tr>
<tr class="even">
<td>187296</td>
<td>1.68969</td>
<td>2.10436</td>
<td>07:26</td>
</tr>
</tbody>
</table>
<p>

    </p><div>
      <progress value="5853" class="" max="5853" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [5853/5853 07:25&lt;00:00 #187296/187286 loss: 1.690 / 2.104]
    </div>
    
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/root/workspace/spear-tts-pytorch/whisperspeech/train.py:63: UserWarning: Attempt to set non-positive xlim on a log-scaled axis will be ignored.
  loss_p.clear()
/root/workspace/spear-tts-pytorch/whisperspeech/train.py:66: UserWarning: Attempt to set non-positive xlim on a log-scaled axis will be ignored.
  loss_p.set_xlim(500, self.total_steps)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-47-output-5.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="co"># reuse the VQ stoks padding token</span></span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a>train_ds, val_ds <span class="op">=</span> load_datasets(<span class="st">'txts-large-6454-cleaned.feather'</span>, <span class="st">'stoks-base.en-2d-4096c-cosine32-padfix-premlp-learnpos-5e.feather'</span>)</span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> make_model(<span class="st">'tiny'</span>, dataset<span class="op">=</span>train_ds, ttoks_codes<span class="op">=</span><span class="dv">256</span>, stoks_width<span class="op">=</span><span class="dv">32</span>).cuda()</span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad(): model.decoder.embedding.weight[:] <span class="op">=</span> vqmodel.rq.layers[<span class="dv">0</span>]._codebook.embed[<span class="dv">0</span>]</span>
<span id="cb60-5"><a href="#cb60-5" aria-hidden="true" tabindex="-1"></a>model.decoder.embedding.lr_scale <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb60-6"><a href="#cb60-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> m <span class="kw">in</span> [model.decoder.emb_to_hidden, model.decoder.hidden_to_emb]:</span>
<span id="cb60-7"><a href="#cb60-7" aria-hidden="true" tabindex="-1"></a>    m.lr_scale <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb60-8"><a href="#cb60-8" aria-hidden="true" tabindex="-1"></a>    std <span class="op">=</span> model.tunables.init_std</span>
<span id="cb60-9"><a href="#cb60-9" aria-hidden="true" tabindex="-1"></a>    torch.nn.init.trunc_normal_(m.weight, std<span class="op">=</span>std, a<span class="op">=-</span><span class="dv">3</span><span class="op">*</span>std, b<span class="op">=</span><span class="dv">3</span><span class="op">*</span>std)</span>
<span id="cb60-10"><a href="#cb60-10" aria-hidden="true" tabindex="-1"></a>train(<span class="st">"tsar-wx"</span>, model, train_ds, val_ds, half<span class="op">=</span><span class="va">True</span>, bs<span class="op">=</span><span class="dv">32</span>, lr<span class="op">=</span>model.tunables.lr0, epochs<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb60-11"><a href="#cb60-11" aria-hidden="true" tabindex="-1"></a>      warmup_steps<span class="op">=</span>model.tunables.warmup_steps, weight_decay<span class="op">=</span>model.tunables.weight_decay, clip_gradient_norm<span class="op">=</span>model.tunables.clip_gradient_norm,</span>
<span id="cb60-12"><a href="#cb60-12" aria-hidden="true" tabindex="-1"></a>      table_row_every_iters<span class="op">=</span><span class="dv">100000</span>, run_valid_every_iters<span class="op">=</span><span class="dv">25000</span>)</span>
<span id="cb60-13"><a href="#cb60-13" aria-hidden="true" tabindex="-1"></a>model.save_model(<span class="st">'t2s-tiny-dropeot.model'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="1" class="" max="1" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [1/1 07:26&lt;00:00]
    </div>
    

<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">samples</th>
<th data-quarto-table-cell-role="th">train</th>
<th data-quarto-table-cell-role="th">val</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>100000</td>
<td>1.98257</td>
<td>2.55949</td>
<td>03:58</td>
</tr>
<tr class="even">
<td>187296</td>
<td>1.69418</td>
<td>2.06103</td>
<td>07:26</td>
</tr>
</tbody>
</table>
<p>

    </p><div>
      <progress value="5853" class="" max="5853" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [5853/5853 07:25&lt;00:00 #187296/187286 loss: 1.694 / 2.061]
    </div>
    
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/root/workspace/spear-tts-pytorch/whisperspeech/train.py:63: UserWarning: Attempt to set non-positive xlim on a log-scaled axis will be ignored.
  loss_p.clear()
/root/workspace/spear-tts-pytorch/whisperspeech/train.py:66: UserWarning: Attempt to set non-positive xlim on a log-scaled axis will be ignored.
  loss_p.set_xlim(500, self.total_steps)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-48-output-5.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="co"># reuse the VQ stoks padding token</span></span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a>train_ds, val_ds <span class="op">=</span> load_datasets(<span class="st">'txts-large-6454-cleaned.feather'</span>, <span class="st">'stoks-base.en-2d-4096c-cosine32-padfix-premlp-learnpos-5e.feather'</span>)</span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> make_model(<span class="st">'tiny'</span>, dataset<span class="op">=</span>train_ds, ttoks_codes<span class="op">=</span><span class="dv">256</span>, stoks_width<span class="op">=</span><span class="dv">32</span>).cuda()</span>
<span id="cb62-4"><a href="#cb62-4" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad(): model.decoder.embedding.weight[:] <span class="op">=</span> vqmodel.rq.layers[<span class="dv">0</span>]._codebook.embed[<span class="dv">0</span>]</span>
<span id="cb62-5"><a href="#cb62-5" aria-hidden="true" tabindex="-1"></a>model.decoder.embedding.lr_scale <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb62-6"><a href="#cb62-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> m <span class="kw">in</span> [model.decoder.emb_to_hidden, model.decoder.hidden_to_emb]:</span>
<span id="cb62-7"><a href="#cb62-7" aria-hidden="true" tabindex="-1"></a>    m.lr_scale <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb62-8"><a href="#cb62-8" aria-hidden="true" tabindex="-1"></a>    std <span class="op">=</span> model.tunables.init_std</span>
<span id="cb62-9"><a href="#cb62-9" aria-hidden="true" tabindex="-1"></a>    torch.nn.init.trunc_normal_(m.weight, std<span class="op">=</span>std, a<span class="op">=-</span><span class="dv">3</span><span class="op">*</span>std, b<span class="op">=</span><span class="dv">3</span><span class="op">*</span>std)</span>
<span id="cb62-10"><a href="#cb62-10" aria-hidden="true" tabindex="-1"></a>train(<span class="st">"tsar-wx"</span>, model, train_ds, val_ds, half<span class="op">=</span><span class="va">True</span>, bs<span class="op">=</span><span class="dv">32</span>, lr<span class="op">=</span>model.tunables.lr0, epochs<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb62-11"><a href="#cb62-11" aria-hidden="true" tabindex="-1"></a>      warmup_steps<span class="op">=</span>model.tunables.warmup_steps, weight_decay<span class="op">=</span>model.tunables.weight_decay, clip_gradient_norm<span class="op">=</span>model.tunables.clip_gradient_norm,</span>
<span id="cb62-12"><a href="#cb62-12" aria-hidden="true" tabindex="-1"></a>      table_row_every_iters<span class="op">=</span><span class="dv">100000</span>, run_valid_every_iters<span class="op">=</span><span class="dv">25000</span>)</span>
<span id="cb62-13"><a href="#cb62-13" aria-hidden="true" tabindex="-1"></a>model.save_model(<span class="st">'t2s-tiny-dropeot1.model'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="1" class="" max="1" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [1/1 07:25&lt;00:00]
    </div>
    

<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">samples</th>
<th data-quarto-table-cell-role="th">train</th>
<th data-quarto-table-cell-role="th">val</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>100000</td>
<td>2.05267</td>
<td>3.04738</td>
<td>03:57</td>
</tr>
<tr class="even">
<td>187296</td>
<td>1.73854</td>
<td>2.19192</td>
<td>07:25</td>
</tr>
</tbody>
</table>
<p>

    </p><div>
      <progress value="5853" class="" max="5853" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [5853/5853 07:25&lt;00:00 #187296/187286 loss: 1.739 / 2.192]
    </div>
    
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/root/workspace/spear-tts-pytorch/whisperspeech/train.py:63: UserWarning: Attempt to set non-positive xlim on a log-scaled axis will be ignored.
  loss_p.clear()
/root/workspace/spear-tts-pytorch/whisperspeech/train.py:66: UserWarning: Attempt to set non-positive xlim on a log-scaled axis will be ignored.
  loss_p.set_xlim(500, self.total_steps)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-49-output-5.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="co"># reuse the VQ stoks padding token</span></span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a>train_ds, val_ds <span class="op">=</span> load_datasets(<span class="st">'txts-large-6454-cleaned.feather'</span>, <span class="st">'stoks-base.en-2d-4096c-cosine32-padfix-premlp-learnpos-5e.feather'</span>)</span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> make_model(<span class="st">'tiny'</span>, dataset<span class="op">=</span>train_ds, ttoks_codes<span class="op">=</span><span class="dv">256</span>, stoks_width<span class="op">=</span><span class="dv">32</span>).cuda()</span>
<span id="cb64-4"><a href="#cb64-4" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad(): model.decoder.embedding.weight[:] <span class="op">=</span> vqmodel.rq.layers[<span class="dv">0</span>]._codebook.embed[<span class="dv">0</span>]</span>
<span id="cb64-5"><a href="#cb64-5" aria-hidden="true" tabindex="-1"></a>model.decoder.embedding.lr_scale <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb64-6"><a href="#cb64-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> m <span class="kw">in</span> [model.decoder.emb_to_hidden, model.decoder.hidden_to_emb]:</span>
<span id="cb64-7"><a href="#cb64-7" aria-hidden="true" tabindex="-1"></a>    m.lr_scale <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb64-8"><a href="#cb64-8" aria-hidden="true" tabindex="-1"></a>    std <span class="op">=</span> model.tunables.init_std</span>
<span id="cb64-9"><a href="#cb64-9" aria-hidden="true" tabindex="-1"></a>    torch.nn.init.trunc_normal_(m.weight, std<span class="op">=</span>std, a<span class="op">=-</span><span class="dv">3</span><span class="op">*</span>std, b<span class="op">=</span><span class="dv">3</span><span class="op">*</span>std)</span>
<span id="cb64-10"><a href="#cb64-10" aria-hidden="true" tabindex="-1"></a>train(<span class="st">"tsar-wx"</span>, model, train_ds, val_ds, half<span class="op">=</span><span class="va">True</span>, bs<span class="op">=</span><span class="dv">32</span>, lr<span class="op">=</span>model.tunables.lr0, epochs<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb64-11"><a href="#cb64-11" aria-hidden="true" tabindex="-1"></a>      warmup_steps<span class="op">=</span>model.tunables.warmup_steps, weight_decay<span class="op">=</span>model.tunables.weight_decay, clip_gradient_norm<span class="op">=</span>model.tunables.clip_gradient_norm,</span>
<span id="cb64-12"><a href="#cb64-12" aria-hidden="true" tabindex="-1"></a>      table_row_every_iters<span class="op">=</span><span class="dv">100000</span>, run_valid_every_iters<span class="op">=</span><span class="dv">25000</span>)</span>
<span id="cb64-13"><a href="#cb64-13" aria-hidden="true" tabindex="-1"></a>model.save_model(<span class="st">'t2s-tiny-dropeot1-3e.model'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="3" class="" max="3" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [3/3 22:20&lt;00:00]
    </div>
    

<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">samples</th>
<th data-quarto-table-cell-role="th">train</th>
<th data-quarto-table-cell-role="th">val</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>100000</td>
<td>2.16998</td>
<td>3.32899</td>
<td>03:58</td>
</tr>
<tr class="even">
<td>200000</td>
<td>1.61419</td>
<td>2.16362</td>
<td>07:56</td>
</tr>
<tr class="odd">
<td>300000</td>
<td>1.46889</td>
<td>1.88969</td>
<td>11:55</td>
</tr>
<tr class="even">
<td>400000</td>
<td>1.43118</td>
<td>1.82983</td>
<td>15:54</td>
</tr>
<tr class="odd">
<td>500000</td>
<td>1.38416</td>
<td>1.74227</td>
<td>19:52</td>
</tr>
<tr class="even">
<td>561888</td>
<td>1.31517</td>
<td>1.72425</td>
<td>22:20</td>
</tr>
</tbody>
</table>
<p>

    </p><div>
      <progress value="5853" class="" max="5853" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [5853/5853 07:27&lt;00:00 #187296/187286 loss: 1.315 / 1.724]
    </div>
    
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/root/workspace/spear-tts-pytorch/whisperspeech/train.py:63: UserWarning: Attempt to set non-positive xlim on a log-scaled axis will be ignored.
  loss_p.clear()
/root/workspace/spear-tts-pytorch/whisperspeech/train.py:66: UserWarning: Attempt to set non-positive xlim on a log-scaled axis will be ignored.
  loss_p.set_xlim(500, self.total_steps)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-50-output-5.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="co"># reuse the VQ stoks padding token</span></span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a>train_ds, val_ds <span class="op">=</span> load_datasets(<span class="st">'txts-large-6454-cleaned.feather'</span>, <span class="st">'stoks-base.en-2d-4096c-cosine32-padfix-premlp-learnpos-5e.feather'</span>)</span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> make_model(<span class="st">'base'</span>, dataset<span class="op">=</span>train_ds, ttoks_codes<span class="op">=</span><span class="dv">256</span>, stoks_width<span class="op">=</span><span class="dv">32</span>).cuda()</span>
<span id="cb66-4"><a href="#cb66-4" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad(): model.decoder.embedding.weight[:] <span class="op">=</span> vqmodel.rq.layers[<span class="dv">0</span>]._codebook.embed[<span class="dv">0</span>]</span>
<span id="cb66-5"><a href="#cb66-5" aria-hidden="true" tabindex="-1"></a>model.decoder.embedding.lr_scale <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb66-6"><a href="#cb66-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> m <span class="kw">in</span> [model.decoder.emb_to_hidden, model.decoder.hidden_to_emb]:</span>
<span id="cb66-7"><a href="#cb66-7" aria-hidden="true" tabindex="-1"></a>    m.lr_scale <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb66-8"><a href="#cb66-8" aria-hidden="true" tabindex="-1"></a>    std <span class="op">=</span> model.tunables.init_std</span>
<span id="cb66-9"><a href="#cb66-9" aria-hidden="true" tabindex="-1"></a>    torch.nn.init.trunc_normal_(m.weight, std<span class="op">=</span>std, a<span class="op">=-</span><span class="dv">3</span><span class="op">*</span>std, b<span class="op">=</span><span class="dv">3</span><span class="op">*</span>std)</span>
<span id="cb66-10"><a href="#cb66-10" aria-hidden="true" tabindex="-1"></a>train(<span class="st">"tsar-wx"</span>, model, train_ds, val_ds, half<span class="op">=</span><span class="va">True</span>, bs<span class="op">=</span><span class="dv">32</span>, lr<span class="op">=</span>model.tunables.lr0, epochs<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb66-11"><a href="#cb66-11" aria-hidden="true" tabindex="-1"></a>      warmup_steps<span class="op">=</span>model.tunables.warmup_steps, weight_decay<span class="op">=</span>model.tunables.weight_decay, clip_gradient_norm<span class="op">=</span>model.tunables.clip_gradient_norm,</span>
<span id="cb66-12"><a href="#cb66-12" aria-hidden="true" tabindex="-1"></a>      table_row_every_iters<span class="op">=</span><span class="dv">100000</span>, run_valid_every_iters<span class="op">=</span><span class="dv">25000</span>)</span>
<span id="cb66-13"><a href="#cb66-13" aria-hidden="true" tabindex="-1"></a>model.save_model(<span class="st">'t2s-base-dropeot1-5e.model'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="5" class="" max="5" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [5/5 1:07:09&lt;00:00]
    </div>
    

<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">samples</th>
<th data-quarto-table-cell-role="th">train</th>
<th data-quarto-table-cell-role="th">val</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>100000</td>
<td>2.15739</td>
<td>3.14531</td>
<td>07:10</td>
</tr>
<tr class="even">
<td>200000</td>
<td>1.61380</td>
<td>2.14494</td>
<td>14:20</td>
</tr>
<tr class="odd">
<td>300000</td>
<td>1.44079</td>
<td>1.92889</td>
<td>21:29</td>
</tr>
<tr class="even">
<td>400000</td>
<td>1.39237</td>
<td>1.84527</td>
<td>28:40</td>
</tr>
<tr class="odd">
<td>500000</td>
<td>1.31629</td>
<td>1.86375</td>
<td>35:50</td>
</tr>
<tr class="even">
<td>600000</td>
<td>1.30173</td>
<td>1.73855</td>
<td>43:00</td>
</tr>
<tr class="odd">
<td>700000</td>
<td>1.32894</td>
<td>1.71813</td>
<td>50:10</td>
</tr>
<tr class="even">
<td>800000</td>
<td>1.21819</td>
<td>1.68263</td>
<td>57:21</td>
</tr>
<tr class="odd">
<td>900000</td>
<td>1.22189</td>
<td>1.66920</td>
<td>1:04:31</td>
</tr>
<tr class="even">
<td>936480</td>
<td>1.22943</td>
<td>1.66867</td>
<td>1:07:09</td>
</tr>
</tbody>
</table>
<p>

    </p><div>
      <progress value="5853" class="" max="5853" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [5853/5853 13:27&lt;00:00 #187296/187286 loss: 1.229 / 1.669]
    </div>
    
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/root/workspace/spear-tts-pytorch/whisperspeech/train.py:63: UserWarning: Attempt to set non-positive xlim on a log-scaled axis will be ignored.
  loss_p.clear()
/root/workspace/spear-tts-pytorch/whisperspeech/train.py:66: UserWarning: Attempt to set non-positive xlim on a log-scaled axis will be ignored.
  loss_p.set_xlim(500, self.total_steps)
IOPub message rate exceeded.
The notebook server will temporarily stop sending output
to the client in order to avoid crashing it.
To change this limit, set the config variable
`--NotebookApp.iopub_msg_rate_limit`.

Current values:
NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
NotebookApp.rate_limit_window=3.0 (secs)
</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-51-output-5.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="co"># reuse the VQ stoks padding token</span></span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a>train_ds, val_ds <span class="op">=</span> load_datasets(<span class="st">'txts-large-6454-cleaned.feather'</span>, <span class="st">'stoks-base.en-2d-4096c-cosine32-padfix-premlp-learnpos-5e.feather'</span>)</span>
<span id="cb68-3"><a href="#cb68-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> make_model(<span class="st">'base'</span>, dataset<span class="op">=</span>train_ds, ttoks_codes<span class="op">=</span><span class="dv">256</span>, stoks_width<span class="op">=</span><span class="dv">32</span>, tunables<span class="op">=</span>Tunables(eot_dropout_p<span class="op">=</span><span class="fl">.5</span>)).cuda()</span>
<span id="cb68-4"><a href="#cb68-4" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad(): model.decoder.embedding.weight[:] <span class="op">=</span> vqmodel.rq.layers[<span class="dv">0</span>]._codebook.embed[<span class="dv">0</span>]</span>
<span id="cb68-5"><a href="#cb68-5" aria-hidden="true" tabindex="-1"></a>model.decoder.embedding.lr_scale <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb68-6"><a href="#cb68-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> m <span class="kw">in</span> [model.decoder.emb_to_hidden, model.decoder.hidden_to_emb]:</span>
<span id="cb68-7"><a href="#cb68-7" aria-hidden="true" tabindex="-1"></a>    m.lr_scale <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb68-8"><a href="#cb68-8" aria-hidden="true" tabindex="-1"></a>    std <span class="op">=</span> model.tunables.init_std</span>
<span id="cb68-9"><a href="#cb68-9" aria-hidden="true" tabindex="-1"></a>    torch.nn.init.trunc_normal_(m.weight, std<span class="op">=</span>std, a<span class="op">=-</span><span class="dv">3</span><span class="op">*</span>std, b<span class="op">=</span><span class="dv">3</span><span class="op">*</span>std)</span>
<span id="cb68-10"><a href="#cb68-10" aria-hidden="true" tabindex="-1"></a>train(<span class="st">"tsar-wx"</span>, model, train_ds, val_ds, half<span class="op">=</span><span class="va">True</span>, bs<span class="op">=</span><span class="dv">32</span>, lr<span class="op">=</span>model.tunables.lr0, epochs<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb68-11"><a href="#cb68-11" aria-hidden="true" tabindex="-1"></a>      warmup_steps<span class="op">=</span>model.tunables.warmup_steps, weight_decay<span class="op">=</span>model.tunables.weight_decay, clip_gradient_norm<span class="op">=</span>model.tunables.clip_gradient_norm,</span>
<span id="cb68-12"><a href="#cb68-12" aria-hidden="true" tabindex="-1"></a>      table_row_every_iters<span class="op">=</span><span class="dv">100000</span>, run_valid_every_iters<span class="op">=</span><span class="dv">25000</span>)</span>
<span id="cb68-13"><a href="#cb68-13" aria-hidden="true" tabindex="-1"></a>model.save_model(<span class="st">'t2s-base-dropeot_p.5-5e.model'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="5" class="" max="5" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [5/5 1:07:12&lt;00:00]
    </div>
    

<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">samples</th>
<th data-quarto-table-cell-role="th">train</th>
<th data-quarto-table-cell-role="th">val</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>100000</td>
<td>2.17942</td>
<td>2.77374</td>
<td>07:09</td>
</tr>
<tr class="even">
<td>200000</td>
<td>1.79937</td>
<td>2.20654</td>
<td>14:19</td>
</tr>
<tr class="odd">
<td>300000</td>
<td>1.55872</td>
<td>1.98851</td>
<td>21:29</td>
</tr>
<tr class="even">
<td>400000</td>
<td>1.48880</td>
<td>1.85471</td>
<td>28:39</td>
</tr>
<tr class="odd">
<td>500000</td>
<td>1.35137</td>
<td>1.78626</td>
<td>35:49</td>
</tr>
<tr class="even">
<td>600000</td>
<td>1.35452</td>
<td>1.73572</td>
<td>43:00</td>
</tr>
<tr class="odd">
<td>700000</td>
<td>1.28091</td>
<td>1.70269</td>
<td>50:11</td>
</tr>
<tr class="even">
<td>800000</td>
<td>1.21449</td>
<td>1.68077</td>
<td>57:23</td>
</tr>
<tr class="odd">
<td>900000</td>
<td>1.27294</td>
<td>1.66469</td>
<td>1:04:33</td>
</tr>
<tr class="even">
<td>936480</td>
<td>1.23449</td>
<td>1.66274</td>
<td>1:07:12</td>
</tr>
</tbody>
</table>
<p>

    </p><div>
      <progress value="5853" class="" max="5853" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [5853/5853 13:29&lt;00:00 #187296/187286 loss: 1.234 / 1.663]
    </div>
    
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/root/workspace/spear-tts-pytorch/whisperspeech/train.py:63: UserWarning: Attempt to set non-positive xlim on a log-scaled axis will be ignored.
  loss_p.clear()
/root/workspace/spear-tts-pytorch/whisperspeech/train.py:66: UserWarning: Attempt to set non-positive xlim on a log-scaled axis will be ignored.
  loss_p.set_xlim(500, self.total_steps)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-52-output-5.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="co"># reuse the VQ stoks padding token</span></span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a>train_ds, val_ds <span class="op">=</span> load_datasets(<span class="st">'txts-large-6454-cleaned.feather'</span>, <span class="st">'stoks-base.en-2d-4096c-cosine32-padfix-premlp-learnpos-5e.feather'</span>)</span>
<span id="cb70-3"><a href="#cb70-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> make_model(<span class="st">'base'</span>, dataset<span class="op">=</span>train_ds, ttoks_codes<span class="op">=</span><span class="dv">256</span>, stoks_width<span class="op">=</span><span class="dv">32</span>).cuda()</span>
<span id="cb70-4"><a href="#cb70-4" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad(): model.decoder.embedding.weight[:] <span class="op">=</span> vqmodel.rq.layers[<span class="dv">0</span>]._codebook.embed[<span class="dv">0</span>]</span>
<span id="cb70-5"><a href="#cb70-5" aria-hidden="true" tabindex="-1"></a>model.decoder.embedding.lr_scale <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb70-6"><a href="#cb70-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> m <span class="kw">in</span> [model.decoder.emb_to_hidden, model.decoder.hidden_to_emb]:</span>
<span id="cb70-7"><a href="#cb70-7" aria-hidden="true" tabindex="-1"></a>    m.lr_scale <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb70-8"><a href="#cb70-8" aria-hidden="true" tabindex="-1"></a>    std <span class="op">=</span> model.tunables.init_std</span>
<span id="cb70-9"><a href="#cb70-9" aria-hidden="true" tabindex="-1"></a>    torch.nn.init.trunc_normal_(m.weight, std<span class="op">=</span>std, a<span class="op">=-</span><span class="dv">3</span><span class="op">*</span>std, b<span class="op">=</span><span class="dv">3</span><span class="op">*</span>std)</span>
<span id="cb70-10"><a href="#cb70-10" aria-hidden="true" tabindex="-1"></a>train(<span class="st">"tsar-wx"</span>, model, train_ds, val_ds, half<span class="op">=</span><span class="va">True</span>, bs<span class="op">=</span><span class="dv">32</span>, lr<span class="op">=</span>model.tunables.lr0, epochs<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb70-11"><a href="#cb70-11" aria-hidden="true" tabindex="-1"></a>      warmup_steps<span class="op">=</span>model.tunables.warmup_steps, weight_decay<span class="op">=</span>model.tunables.weight_decay, clip_gradient_norm<span class="op">=</span>model.tunables.clip_gradient_norm,</span>
<span id="cb70-12"><a href="#cb70-12" aria-hidden="true" tabindex="-1"></a>      table_row_every_iters<span class="op">=</span><span class="dv">100000</span>, run_valid_every_iters<span class="op">=</span><span class="dv">25000</span>)</span>
<span id="cb70-13"><a href="#cb70-13" aria-hidden="true" tabindex="-1"></a>model.save_model(<span class="st">'t2s-base-dropeot1-10e.model'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="10" class="" max="10" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [10/10 2:14:15&lt;00:00]
    </div>
    

<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">samples</th>
<th data-quarto-table-cell-role="th">train</th>
<th data-quarto-table-cell-role="th">val</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>100000</td>
<td>2.17033</td>
<td>2.89845</td>
<td>07:10</td>
</tr>
<tr class="even">
<td>200000</td>
<td>1.50829</td>
<td>2.02612</td>
<td>14:20</td>
</tr>
<tr class="odd">
<td>300000</td>
<td>1.43682</td>
<td>1.84901</td>
<td>21:30</td>
</tr>
<tr class="even">
<td>400000</td>
<td>1.35099</td>
<td>1.87154</td>
<td>28:40</td>
</tr>
<tr class="odd">
<td>500000</td>
<td>1.39165</td>
<td>1.76240</td>
<td>35:50</td>
</tr>
<tr class="even">
<td>600000</td>
<td>1.31132</td>
<td>1.79887</td>
<td>43:00</td>
</tr>
<tr class="odd">
<td>700000</td>
<td>1.33037</td>
<td>1.74390</td>
<td>50:11</td>
</tr>
<tr class="even">
<td>800000</td>
<td>1.27363</td>
<td>1.81697</td>
<td>57:22</td>
</tr>
<tr class="odd">
<td>900000</td>
<td>1.29424</td>
<td>1.71701</td>
<td>1:04:32</td>
</tr>
<tr class="even">
<td>1000000</td>
<td>1.22769</td>
<td>1.72730</td>
<td>1:11:41</td>
</tr>
<tr class="odd">
<td>1100000</td>
<td>1.29504</td>
<td>1.70143</td>
<td>1:18:50</td>
</tr>
<tr class="even">
<td>1200000</td>
<td>1.19364</td>
<td>1.68924</td>
<td>1:26:01</td>
</tr>
<tr class="odd">
<td>1300000</td>
<td>1.23772</td>
<td>1.68347</td>
<td>1:33:11</td>
</tr>
<tr class="even">
<td>1400000</td>
<td>1.21491</td>
<td>1.65472</td>
<td>1:40:22</td>
</tr>
<tr class="odd">
<td>1500000</td>
<td>1.12864</td>
<td>1.63846</td>
<td>1:47:32</td>
</tr>
<tr class="even">
<td>1600000</td>
<td>1.14099</td>
<td>1.63741</td>
<td>1:54:41</td>
</tr>
<tr class="odd">
<td>1700000</td>
<td>1.11053</td>
<td>1.62853</td>
<td>2:01:51</td>
</tr>
<tr class="even">
<td>1800000</td>
<td>1.10278</td>
<td>1.63842</td>
<td>2:09:02</td>
</tr>
<tr class="odd">
<td>1872960</td>
<td>1.07250</td>
<td>1.63690</td>
<td>2:14:15</td>
</tr>
</tbody>
</table>
<p>

    </p><div>
      <progress value="5853" class="" max="5853" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [5853/5853 13:25&lt;00:00 #187296/187286 loss: 1.073 / 1.637]
    </div>
    
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/root/workspace/spear-tts-pytorch/whisperspeech/train.py:63: UserWarning: Attempt to set non-positive xlim on a log-scaled axis will be ignored.
  loss_p.clear()
/root/workspace/spear-tts-pytorch/whisperspeech/train.py:66: UserWarning: Attempt to set non-positive xlim on a log-scaled axis will be ignored.
  loss_p.set_xlim(500, self.total_steps)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-53-output-5.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="co"># reuse the VQ stoks padding token</span></span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a>train_ds, val_ds <span class="op">=</span> load_datasets(<span class="st">'txts-large-6454-cleaned.feather'</span>, <span class="st">'stoks-base.en-2d-4096c-cosine32-padfix-premlp-learnpos-5e.feather'</span>)</span>
<span id="cb72-3"><a href="#cb72-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> make_model(<span class="st">'base'</span>, dataset<span class="op">=</span>train_ds, ttoks_codes<span class="op">=</span><span class="dv">256</span>, stoks_width<span class="op">=</span><span class="dv">32</span>).cuda()</span>
<span id="cb72-4"><a href="#cb72-4" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad(): model.decoder.embedding.weight[:] <span class="op">=</span> vqmodel.rq.layers[<span class="dv">0</span>]._codebook.embed[<span class="dv">0</span>]</span>
<span id="cb72-5"><a href="#cb72-5" aria-hidden="true" tabindex="-1"></a>model.decoder.embedding.lr_scale <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb72-6"><a href="#cb72-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> m <span class="kw">in</span> [model.decoder.emb_to_hidden, model.decoder.hidden_to_emb]:</span>
<span id="cb72-7"><a href="#cb72-7" aria-hidden="true" tabindex="-1"></a>    m.lr_scale <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb72-8"><a href="#cb72-8" aria-hidden="true" tabindex="-1"></a>    std <span class="op">=</span> model.tunables.init_std</span>
<span id="cb72-9"><a href="#cb72-9" aria-hidden="true" tabindex="-1"></a>    torch.nn.init.trunc_normal_(m.weight, std<span class="op">=</span>std, a<span class="op">=-</span><span class="dv">3</span><span class="op">*</span>std, b<span class="op">=</span><span class="dv">3</span><span class="op">*</span>std)</span>
<span id="cb72-10"><a href="#cb72-10" aria-hidden="true" tabindex="-1"></a>train(<span class="st">"tsar-wx"</span>, model, train_ds, val_ds, half<span class="op">=</span><span class="va">True</span>, bs<span class="op">=</span><span class="dv">32</span>, lr<span class="op">=</span>model.tunables.lr0, epochs<span class="op">=</span><span class="dv">20</span>,</span>
<span id="cb72-11"><a href="#cb72-11" aria-hidden="true" tabindex="-1"></a>      warmup_steps<span class="op">=</span>model.tunables.warmup_steps, weight_decay<span class="op">=</span>model.tunables.weight_decay, clip_gradient_norm<span class="op">=</span>model.tunables.clip_gradient_norm,</span>
<span id="cb72-12"><a href="#cb72-12" aria-hidden="true" tabindex="-1"></a>      table_row_every_iters<span class="op">=</span><span class="dv">100000</span>, run_valid_every_iters<span class="op">=</span><span class="dv">25000</span>)</span>
<span id="cb72-13"><a href="#cb72-13" aria-hidden="true" tabindex="-1"></a>model.save_model(<span class="st">'t2s-base-dropeot1-20e.model'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="20" class="" max="20" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [20/20 4:28:43&lt;00:00]
    </div>
    

<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">samples</th>
<th data-quarto-table-cell-role="th">train</th>
<th data-quarto-table-cell-role="th">val</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>100000</td>
<td>2.12544</td>
<td>2.91373</td>
<td>07:10</td>
</tr>
<tr class="even">
<td>200000</td>
<td>1.66652</td>
<td>2.18800</td>
<td>14:20</td>
</tr>
<tr class="odd">
<td>300000</td>
<td>1.49255</td>
<td>1.94797</td>
<td>21:30</td>
</tr>
<tr class="even">
<td>400000</td>
<td>1.49216</td>
<td>2.17191</td>
<td>28:40</td>
</tr>
<tr class="odd">
<td>500000</td>
<td>1.42051</td>
<td>2.13272</td>
<td>35:51</td>
</tr>
<tr class="even">
<td>600000</td>
<td>1.43777</td>
<td>2.19251</td>
<td>43:01</td>
</tr>
<tr class="odd">
<td>700000</td>
<td>1.39764</td>
<td>1.91985</td>
<td>50:12</td>
</tr>
<tr class="even">
<td>800000</td>
<td>1.38636</td>
<td>1.88027</td>
<td>57:24</td>
</tr>
<tr class="odd">
<td>900000</td>
<td>1.36741</td>
<td>1.77583</td>
<td>1:04:34</td>
</tr>
<tr class="even">
<td>1000000</td>
<td>1.34063</td>
<td>1.78621</td>
<td>1:11:44</td>
</tr>
<tr class="odd">
<td>1100000</td>
<td>1.36154</td>
<td>2.18804</td>
<td>1:18:54</td>
</tr>
<tr class="even">
<td>1200000</td>
<td>1.31143</td>
<td>2.22532</td>
<td>1:26:04</td>
</tr>
<tr class="odd">
<td>1300000</td>
<td>1.35298</td>
<td>2.09253</td>
<td>1:33:14</td>
</tr>
<tr class="even">
<td>1400000</td>
<td>1.30664</td>
<td>1.89705</td>
<td>1:40:24</td>
</tr>
<tr class="odd">
<td>1500000</td>
<td>1.24203</td>
<td>1.74635</td>
<td>1:47:34</td>
</tr>
<tr class="even">
<td>1600000</td>
<td>1.31825</td>
<td>2.27607</td>
<td>1:54:44</td>
</tr>
<tr class="odd">
<td>1700000</td>
<td>1.31140</td>
<td>1.72148</td>
<td>2:01:54</td>
</tr>
<tr class="even">
<td>1800000</td>
<td>1.33538</td>
<td>1.92881</td>
<td>2:09:04</td>
</tr>
<tr class="odd">
<td>1900000</td>
<td>1.27322</td>
<td>1.70205</td>
<td>2:16:15</td>
</tr>
<tr class="even">
<td>2000000</td>
<td>1.28421</td>
<td>1.80239</td>
<td>2:23:24</td>
</tr>
<tr class="odd">
<td>2100000</td>
<td>1.25328</td>
<td>1.70730</td>
<td>2:30:35</td>
</tr>
<tr class="even">
<td>2200000</td>
<td>1.32125</td>
<td>1.69055</td>
<td>2:37:46</td>
</tr>
<tr class="odd">
<td>2300000</td>
<td>1.26999</td>
<td>1.70065</td>
<td>2:44:56</td>
</tr>
<tr class="even">
<td>2400000</td>
<td>1.25610</td>
<td>1.67959</td>
<td>2:52:07</td>
</tr>
<tr class="odd">
<td>2500000</td>
<td>1.23619</td>
<td>1.68657</td>
<td>2:59:18</td>
</tr>
<tr class="even">
<td>2600000</td>
<td>1.27713</td>
<td>1.65734</td>
<td>3:06:29</td>
</tr>
<tr class="odd">
<td>2700000</td>
<td>1.22025</td>
<td>1.66189</td>
<td>3:13:40</td>
</tr>
<tr class="even">
<td>2800000</td>
<td>1.19720</td>
<td>1.64429</td>
<td>3:20:50</td>
</tr>
<tr class="odd">
<td>2900000</td>
<td>1.18185</td>
<td>1.66007</td>
<td>3:28:01</td>
</tr>
<tr class="even">
<td>3000000</td>
<td>1.14963</td>
<td>1.64336</td>
<td>3:35:12</td>
</tr>
<tr class="odd">
<td>3100000</td>
<td>1.15113</td>
<td>1.65405</td>
<td>3:42:22</td>
</tr>
<tr class="even">
<td>3200000</td>
<td>1.14006</td>
<td>1.64569</td>
<td>3:49:33</td>
</tr>
<tr class="odd">
<td>3300000</td>
<td>1.11431</td>
<td>1.65047</td>
<td>3:56:43</td>
</tr>
<tr class="even">
<td>3400000</td>
<td>1.17996</td>
<td>1.65538</td>
<td>4:03:54</td>
</tr>
<tr class="odd">
<td>3500000</td>
<td>1.09533</td>
<td>1.65644</td>
<td>4:11:05</td>
</tr>
<tr class="even">
<td>3600000</td>
<td>1.14862</td>
<td>1.66063</td>
<td>4:18:16</td>
</tr>
<tr class="odd">
<td>3700000</td>
<td>1.08553</td>
<td>1.65924</td>
<td>4:25:25</td>
</tr>
<tr class="even">
<td>3745920</td>
<td>1.11090</td>
<td>1.65944</td>
<td>4:28:43</td>
</tr>
</tbody>
</table>
<p>

    </p><div>
      <progress value="5853" class="" max="5853" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [5853/5853 13:25&lt;00:00 #187296/187286 loss: 1.111 / 1.659]
    </div>
    
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/root/workspace/spear-tts-pytorch/whisperspeech/train.py:63: UserWarning: Attempt to set non-positive xlim on a log-scaled axis will be ignored.
  loss_p.clear()
/root/workspace/spear-tts-pytorch/whisperspeech/train.py:66: UserWarning: Attempt to set non-positive xlim on a log-scaled axis will be ignored.
  loss_p.set_xlim(500, self.total_steps)
IOPub message rate exceeded.
The notebook server will temporarily stop sending output
to the client in order to avoid crashing it.
To change this limit, set the config variable
`--NotebookApp.iopub_msg_rate_limit`.

Current values:
NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
NotebookApp.rate_limit_window=3.0 (secs)

IOPub message rate exceeded.
The notebook server will temporarily stop sending output
to the client in order to avoid crashing it.
To change this limit, set the config variable
`--NotebookApp.iopub_msg_rate_limit`.

Current values:
NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
NotebookApp.rate_limit_window=3.0 (secs)

IOPub message rate exceeded.
The notebook server will temporarily stop sending output
to the client in order to avoid crashing it.
To change this limit, set the config variable
`--NotebookApp.iopub_msg_rate_limit`.

Current values:
NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
NotebookApp.rate_limit_window=3.0 (secs)
</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-54-output-5.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="co"># reuse the VQ stoks padding token</span></span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a>train_ds, val_ds <span class="op">=</span> load_datasets(<span class="st">'txts-large-6454-cleaned.feather'</span>, <span class="st">'stoks-base.en-2d-4096c-cosine32-padfix-premlp-learnpos-5e.feather'</span>)</span>
<span id="cb74-3"><a href="#cb74-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> make_model(<span class="st">'tiny'</span>, dataset<span class="op">=</span>train_ds, ttoks_codes<span class="op">=</span><span class="dv">256</span>, stoks_width<span class="op">=</span><span class="dv">32</span>).cuda()</span>
<span id="cb74-4"><a href="#cb74-4" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad(): model.decoder.embedding.weight[:] <span class="op">=</span> vqmodel.rq.layers[<span class="dv">0</span>]._codebook.embed[<span class="dv">0</span>]</span>
<span id="cb74-5"><a href="#cb74-5" aria-hidden="true" tabindex="-1"></a>model.decoder.embedding.lr_scale <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb74-6"><a href="#cb74-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> m <span class="kw">in</span> [model.decoder.emb_to_hidden, model.decoder.hidden_to_emb]:</span>
<span id="cb74-7"><a href="#cb74-7" aria-hidden="true" tabindex="-1"></a>    m.lr_scale <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb74-8"><a href="#cb74-8" aria-hidden="true" tabindex="-1"></a>    std <span class="op">=</span> model.tunables.init_std</span>
<span id="cb74-9"><a href="#cb74-9" aria-hidden="true" tabindex="-1"></a>    torch.nn.init.trunc_normal_(m.weight, std<span class="op">=</span>std, a<span class="op">=-</span><span class="dv">3</span><span class="op">*</span>std, b<span class="op">=</span><span class="dv">3</span><span class="op">*</span>std)</span>
<span id="cb74-10"><a href="#cb74-10" aria-hidden="true" tabindex="-1"></a>train(<span class="st">"tsar-wx"</span>, model, train_ds, val_ds, half<span class="op">=</span><span class="va">True</span>, bs<span class="op">=</span><span class="dv">32</span>, lr<span class="op">=</span>model.tunables.lr0, epochs<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb74-11"><a href="#cb74-11" aria-hidden="true" tabindex="-1"></a>      warmup_steps<span class="op">=</span>model.tunables.warmup_steps, weight_decay<span class="op">=</span>model.tunables.weight_decay, clip_gradient_norm<span class="op">=</span>model.tunables.clip_gradient_norm,</span>
<span id="cb74-12"><a href="#cb74-12" aria-hidden="true" tabindex="-1"></a>      table_row_every_iters<span class="op">=</span><span class="dv">100000</span>, run_valid_every_iters<span class="op">=</span><span class="dv">25000</span>)</span>
<span id="cb74-13"><a href="#cb74-13" aria-hidden="true" tabindex="-1"></a>model.save_model(<span class="st">'t2s-tiny-nodropeot.model'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="1" class="" max="1" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [1/1 07:25&lt;00:00]
    </div>
    

<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">samples</th>
<th data-quarto-table-cell-role="th">train</th>
<th data-quarto-table-cell-role="th">val</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>100000</td>
<td>1.79375</td>
<td>2.43253</td>
<td>03:57</td>
</tr>
<tr class="even">
<td>187296</td>
<td>1.50454</td>
<td>1.88259</td>
<td>07:25</td>
</tr>
</tbody>
</table>
<p>

    </p><div>
      <progress value="5853" class="" max="5853" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [5853/5853 07:25&lt;00:00 #187296/187286 loss: 1.505 / 1.883]
    </div>
    
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/root/workspace/spear-tts-pytorch/whisperspeech/train.py:63: UserWarning: Attempt to set non-positive xlim on a log-scaled axis will be ignored.
  loss_p.clear()
/root/workspace/spear-tts-pytorch/whisperspeech/train.py:66: UserWarning: Attempt to set non-positive xlim on a log-scaled axis will be ignored.
  loss_p.set_xlim(500, self.total_steps)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-55-output-5.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a>vqmodel <span class="op">=</span> RQBottleneckTransformer.load_model(local_filename<span class="op">=</span><span class="st">'vq-base.en-2d-4096c-cosine32-padfix-premlp-preconv-learnpos-5e-cleaned.model'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a>vqmodel.rq.layers[<span class="dv">0</span>]._codebook.embed.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>torch.Size([1, 4097, 32])</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="co"># cleaned data</span></span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a>vqmodel <span class="op">=</span> RQBottleneckTransformer.load_model(local_filename<span class="op">=</span><span class="st">'vq-base.en-2d-4096c-cosine32-padfix-premlp-preconv-learnpos-5e-cleaned.model'</span>)</span>
<span id="cb79-3"><a href="#cb79-3" aria-hidden="true" tabindex="-1"></a>train_ds, val_ds <span class="op">=</span> load_datasets(<span class="st">'txts-large-6454.feather'</span>, <span class="st">'stoks-base.en-2d-4096c-cosine32-padfix-premlp-preconv-learnpos-5e-cleaned.feather'</span>)</span>
<span id="cb79-4"><a href="#cb79-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> make_model(<span class="st">'tiny'</span>, dataset<span class="op">=</span>train_ds, ttoks_codes<span class="op">=</span><span class="dv">256</span>, stoks_width<span class="op">=</span><span class="dv">32</span>, tunables<span class="op">=</span>Tunables(eot_dropout_p<span class="op">=</span><span class="dv">0</span>)).cuda()</span>
<span id="cb79-5"><a href="#cb79-5" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad(): model.decoder.embedding.weight[:] <span class="op">=</span> vqmodel.rq.layers[<span class="dv">0</span>]._codebook.embed[<span class="dv">0</span>]</span>
<span id="cb79-6"><a href="#cb79-6" aria-hidden="true" tabindex="-1"></a>model.decoder.embedding.lr_scale <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb79-7"><a href="#cb79-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> m <span class="kw">in</span> [model.decoder.emb_to_hidden, model.decoder.hidden_to_emb]:</span>
<span id="cb79-8"><a href="#cb79-8" aria-hidden="true" tabindex="-1"></a>    m.lr_scale <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb79-9"><a href="#cb79-9" aria-hidden="true" tabindex="-1"></a>    std <span class="op">=</span> model.tunables.init_std</span>
<span id="cb79-10"><a href="#cb79-10" aria-hidden="true" tabindex="-1"></a>    torch.nn.init.trunc_normal_(m.weight, std<span class="op">=</span>std, a<span class="op">=-</span><span class="dv">3</span><span class="op">*</span>std, b<span class="op">=</span><span class="dv">3</span><span class="op">*</span>std)</span>
<span id="cb79-11"><a href="#cb79-11" aria-hidden="true" tabindex="-1"></a>train(<span class="st">"tsar-wx"</span>, model, train_ds, val_ds, half<span class="op">=</span><span class="va">True</span>, bs<span class="op">=</span><span class="dv">32</span>, lr<span class="op">=</span>model.tunables.lr0, epochs<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb79-12"><a href="#cb79-12" aria-hidden="true" tabindex="-1"></a>      warmup_steps<span class="op">=</span>model.tunables.warmup_steps, weight_decay<span class="op">=</span>model.tunables.weight_decay, clip_gradient_norm<span class="op">=</span>model.tunables.clip_gradient_norm,</span>
<span id="cb79-13"><a href="#cb79-13" aria-hidden="true" tabindex="-1"></a>      table_row_every_iters<span class="op">=</span><span class="dv">100000</span>, run_valid_every_iters<span class="op">=</span><span class="dv">25000</span>)</span>
<span id="cb79-14"><a href="#cb79-14" aria-hidden="true" tabindex="-1"></a>model.save_model(<span class="st">'t2s-tiny-cleaned.model'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="1" class="" max="1" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [1/1 07:39&lt;00:00]
    </div>
    

<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">samples</th>
<th data-quarto-table-cell-role="th">train</th>
<th data-quarto-table-cell-role="th">val</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>100000</td>
<td>3.74254</td>
<td>3.83815</td>
<td>03:57</td>
</tr>
<tr class="even">
<td>194048</td>
<td>3.29812</td>
<td>3.46448</td>
<td>07:39</td>
</tr>
</tbody>
</table>
<p>

    </p><div>
      <progress value="6064" class="" max="6064" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [6064/6064 07:39&lt;00:00 #194048/194040 loss: 3.298 / 3.464]
    </div>
    
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/root/workspace/spear-tts-pytorch/whisperspeech/train.py:63: UserWarning: Attempt to set non-positive xlim on a log-scaled axis will be ignored.
  loss_p.clear()
/root/workspace/spear-tts-pytorch/whisperspeech/train.py:66: UserWarning: Attempt to set non-positive xlim on a log-scaled axis will be ignored.
  loss_p.set_xlim(500, self.total_steps)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-58-output-5.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb81"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="co"># cleaned data</span></span>
<span id="cb81-2"><a href="#cb81-2" aria-hidden="true" tabindex="-1"></a>vqmodel <span class="op">=</span> RQBottleneckTransformer.load_model(local_filename<span class="op">=</span><span class="st">'vq-base.en-2d-4096c-cosine32-padfix-premlp-preconv-learnpos-5e-cleaned.model'</span>)</span>
<span id="cb81-3"><a href="#cb81-3" aria-hidden="true" tabindex="-1"></a>train_ds, val_ds <span class="op">=</span> load_datasets(<span class="st">'txts-large-6454.feather'</span>, <span class="st">'stoks-base.en-2d-4096c-cosine32-padfix-premlp-preconv-learnpos-5e-cleaned.feather'</span>)</span>
<span id="cb81-4"><a href="#cb81-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> make_model(<span class="st">'base'</span>, dataset<span class="op">=</span>train_ds, ttoks_codes<span class="op">=</span><span class="dv">256</span>, stoks_width<span class="op">=</span><span class="dv">32</span>, tunables<span class="op">=</span>Tunables(eot_dropout_p<span class="op">=</span><span class="dv">0</span>)).cuda()</span>
<span id="cb81-5"><a href="#cb81-5" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad(): model.decoder.embedding.weight[:] <span class="op">=</span> vqmodel.rq.layers[<span class="dv">0</span>]._codebook.embed[<span class="dv">0</span>]</span>
<span id="cb81-6"><a href="#cb81-6" aria-hidden="true" tabindex="-1"></a>model.decoder.embedding.lr_scale <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb81-7"><a href="#cb81-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> m <span class="kw">in</span> [model.decoder.emb_to_hidden, model.decoder.hidden_to_emb]:</span>
<span id="cb81-8"><a href="#cb81-8" aria-hidden="true" tabindex="-1"></a>    m.lr_scale <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb81-9"><a href="#cb81-9" aria-hidden="true" tabindex="-1"></a>    std <span class="op">=</span> model.tunables.init_std</span>
<span id="cb81-10"><a href="#cb81-10" aria-hidden="true" tabindex="-1"></a>    torch.nn.init.trunc_normal_(m.weight, std<span class="op">=</span>std, a<span class="op">=-</span><span class="dv">3</span><span class="op">*</span>std, b<span class="op">=</span><span class="dv">3</span><span class="op">*</span>std)</span>
<span id="cb81-11"><a href="#cb81-11" aria-hidden="true" tabindex="-1"></a>train(<span class="st">"tsar-wx"</span>, model, train_ds, val_ds, half<span class="op">=</span><span class="va">True</span>, bs<span class="op">=</span><span class="dv">32</span>, lr<span class="op">=</span>model.tunables.lr0, epochs<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb81-12"><a href="#cb81-12" aria-hidden="true" tabindex="-1"></a>      warmup_steps<span class="op">=</span>model.tunables.warmup_steps, weight_decay<span class="op">=</span>model.tunables.weight_decay, clip_gradient_norm<span class="op">=</span>model.tunables.clip_gradient_norm,</span>
<span id="cb81-13"><a href="#cb81-13" aria-hidden="true" tabindex="-1"></a>      table_row_every_iters<span class="op">=</span><span class="dv">100000</span>, run_valid_every_iters<span class="op">=</span><span class="dv">25000</span>)</span>
<span id="cb81-14"><a href="#cb81-14" aria-hidden="true" tabindex="-1"></a>model.save_model(<span class="st">'t2s-base-cleaned.model'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="5" class="" max="5" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [5/5 1:09:42&lt;00:00]
    </div>
    

<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">samples</th>
<th data-quarto-table-cell-role="th">train</th>
<th data-quarto-table-cell-role="th">val</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>100000</td>
<td>3.68559</td>
<td>4.04428</td>
<td>07:10</td>
</tr>
<tr class="even">
<td>200000</td>
<td>3.01551</td>
<td>3.21883</td>
<td>14:22</td>
</tr>
<tr class="odd">
<td>300000</td>
<td>3.24499</td>
<td>3.11739</td>
<td>21:33</td>
</tr>
<tr class="even">
<td>400000</td>
<td>2.96113</td>
<td>3.07379</td>
<td>28:43</td>
</tr>
<tr class="odd">
<td>500000</td>
<td>2.97186</td>
<td>3.04313</td>
<td>35:54</td>
</tr>
<tr class="even">
<td>600000</td>
<td>2.97368</td>
<td>3.01292</td>
<td>43:06</td>
</tr>
<tr class="odd">
<td>700000</td>
<td>2.78741</td>
<td>2.99100</td>
<td>50:17</td>
</tr>
<tr class="even">
<td>800000</td>
<td>2.62833</td>
<td>2.96299</td>
<td>57:29</td>
</tr>
<tr class="odd">
<td>900000</td>
<td>2.91650</td>
<td>2.94995</td>
<td>1:04:40</td>
</tr>
<tr class="even">
<td>970240</td>
<td>2.87281</td>
<td>2.94701</td>
<td>1:09:42</td>
</tr>
</tbody>
</table>
<p>

    </p><div>
      <progress value="6064" class="" max="6064" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [6064/6064 13:55&lt;00:00 #194048/194040 loss: 2.873 / 2.947]
    </div>
    
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/root/workspace/spear-tts-pytorch/whisperspeech/train.py:63: UserWarning: Attempt to set non-positive xlim on a log-scaled axis will be ignored.
  loss_p.clear()
/root/workspace/spear-tts-pytorch/whisperspeech/train.py:66: UserWarning: Attempt to set non-positive xlim on a log-scaled axis will be ignored.
  loss_p.set_xlim(500, self.total_steps)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-59-output-5.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb83"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a><span class="co"># cleaned data</span></span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true" tabindex="-1"></a>vqmodel <span class="op">=</span> RQBottleneckTransformer.load_model(local_filename<span class="op">=</span><span class="st">'vq-base.en-2d-4096c-cosine32-padfix-premlp-learnpos-5e-cleaned.model'</span>)</span>
<span id="cb83-3"><a href="#cb83-3" aria-hidden="true" tabindex="-1"></a>train_ds, val_ds <span class="op">=</span> load_datasets(<span class="st">'txts-large-6454.feather'</span>, <span class="st">'stoks-base.en-2d-4096c-cosine32-padfix-premlp-learnpos-5e-cleaned.feather'</span>)</span>
<span id="cb83-4"><a href="#cb83-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> make_model(<span class="st">'tiny'</span>, dataset<span class="op">=</span>train_ds, ttoks_codes<span class="op">=</span><span class="dv">256</span>, stoks_width<span class="op">=</span><span class="dv">32</span>, tunables<span class="op">=</span>Tunables(eot_dropout_p<span class="op">=</span><span class="dv">0</span>)).cuda()</span>
<span id="cb83-5"><a href="#cb83-5" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad(): model.decoder.embedding.weight[:] <span class="op">=</span> vqmodel.rq.layers[<span class="dv">0</span>]._codebook.embed[<span class="dv">0</span>]</span>
<span id="cb83-6"><a href="#cb83-6" aria-hidden="true" tabindex="-1"></a>model.decoder.embedding.lr_scale <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb83-7"><a href="#cb83-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> m <span class="kw">in</span> [model.decoder.emb_to_hidden, model.decoder.hidden_to_emb]:</span>
<span id="cb83-8"><a href="#cb83-8" aria-hidden="true" tabindex="-1"></a>    m.lr_scale <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb83-9"><a href="#cb83-9" aria-hidden="true" tabindex="-1"></a>    std <span class="op">=</span> model.tunables.init_std</span>
<span id="cb83-10"><a href="#cb83-10" aria-hidden="true" tabindex="-1"></a>    torch.nn.init.trunc_normal_(m.weight, std<span class="op">=</span>std, a<span class="op">=-</span><span class="dv">3</span><span class="op">*</span>std, b<span class="op">=</span><span class="dv">3</span><span class="op">*</span>std)</span>
<span id="cb83-11"><a href="#cb83-11" aria-hidden="true" tabindex="-1"></a>train(<span class="st">"tsar-wx"</span>, model, train_ds, val_ds, half<span class="op">=</span><span class="va">True</span>, bs<span class="op">=</span><span class="dv">32</span>, lr<span class="op">=</span>model.tunables.lr0, epochs<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb83-12"><a href="#cb83-12" aria-hidden="true" tabindex="-1"></a>      warmup_steps<span class="op">=</span>model.tunables.warmup_steps, weight_decay<span class="op">=</span>model.tunables.weight_decay, clip_gradient_norm<span class="op">=</span>model.tunables.clip_gradient_norm,</span>
<span id="cb83-13"><a href="#cb83-13" aria-hidden="true" tabindex="-1"></a>      table_row_every_iters<span class="op">=</span><span class="dv">100000</span>, run_valid_every_iters<span class="op">=</span><span class="dv">25000</span>)</span>
<span id="cb83-14"><a href="#cb83-14" aria-hidden="true" tabindex="-1"></a>model.save_model(<span class="st">'t2s-tiny-nopreconv-cleaned.model'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="1" class="" max="1" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [1/1 07:40&lt;00:00]
    </div>
    

<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">samples</th>
<th data-quarto-table-cell-role="th">train</th>
<th data-quarto-table-cell-role="th">val</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>100000</td>
<td>2.06768</td>
<td>2.32964</td>
<td>03:58</td>
</tr>
<tr class="even">
<td>194048</td>
<td>1.70456</td>
<td>1.86111</td>
<td>07:41</td>
</tr>
</tbody>
</table>
<p>

    </p><div>
      <progress value="6064" class="" max="6064" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [6064/6064 07:40&lt;00:00 #194048/194040 loss: 1.705 / 1.861]
    </div>
    
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/root/workspace/spear-tts-pytorch/whisperspeech/train.py:63: UserWarning: Attempt to set non-positive xlim on a log-scaled axis will be ignored.
  loss_p.clear()
/root/workspace/spear-tts-pytorch/whisperspeech/train.py:66: UserWarning: Attempt to set non-positive xlim on a log-scaled axis will be ignored.
  loss_p.set_xlim(500, self.total_steps)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-60-output-5.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb85"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a><span class="co"># cleaned data</span></span>
<span id="cb85-2"><a href="#cb85-2" aria-hidden="true" tabindex="-1"></a>vqmodel <span class="op">=</span> RQBottleneckTransformer.load_model(local_filename<span class="op">=</span><span class="st">'vq-base.en-2d-4096c-cosine32-padfix-premlp-learnpos-5e-cleaned.model'</span>)</span>
<span id="cb85-3"><a href="#cb85-3" aria-hidden="true" tabindex="-1"></a>train_ds, val_ds <span class="op">=</span> load_datasets(<span class="st">'txts-large-6454.feather'</span>, <span class="st">'stoks-base.en-2d-4096c-cosine32-padfix-premlp-learnpos-5e-cleaned.feather'</span>)</span>
<span id="cb85-4"><a href="#cb85-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> make_model(<span class="st">'base'</span>, dataset<span class="op">=</span>train_ds, ttoks_codes<span class="op">=</span><span class="dv">256</span>, stoks_width<span class="op">=</span><span class="dv">32</span>, tunables<span class="op">=</span>Tunables(eot_dropout_p<span class="op">=</span><span class="dv">0</span>)).cuda()</span>
<span id="cb85-5"><a href="#cb85-5" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad(): model.decoder.embedding.weight[:] <span class="op">=</span> vqmodel.rq.layers[<span class="dv">0</span>]._codebook.embed[<span class="dv">0</span>]</span>
<span id="cb85-6"><a href="#cb85-6" aria-hidden="true" tabindex="-1"></a>model.decoder.embedding.lr_scale <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb85-7"><a href="#cb85-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> m <span class="kw">in</span> [model.decoder.emb_to_hidden, model.decoder.hidden_to_emb]:</span>
<span id="cb85-8"><a href="#cb85-8" aria-hidden="true" tabindex="-1"></a>    m.lr_scale <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb85-9"><a href="#cb85-9" aria-hidden="true" tabindex="-1"></a>    std <span class="op">=</span> model.tunables.init_std</span>
<span id="cb85-10"><a href="#cb85-10" aria-hidden="true" tabindex="-1"></a>    torch.nn.init.trunc_normal_(m.weight, std<span class="op">=</span>std, a<span class="op">=-</span><span class="dv">3</span><span class="op">*</span>std, b<span class="op">=</span><span class="dv">3</span><span class="op">*</span>std)</span>
<span id="cb85-11"><a href="#cb85-11" aria-hidden="true" tabindex="-1"></a>train(<span class="st">"tsar-wx"</span>, model, train_ds, val_ds, half<span class="op">=</span><span class="va">True</span>, bs<span class="op">=</span><span class="dv">32</span>, lr<span class="op">=</span>model.tunables.lr0, epochs<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb85-12"><a href="#cb85-12" aria-hidden="true" tabindex="-1"></a>      warmup_steps<span class="op">=</span>model.tunables.warmup_steps, weight_decay<span class="op">=</span>model.tunables.weight_decay, clip_gradient_norm<span class="op">=</span>model.tunables.clip_gradient_norm,</span>
<span id="cb85-13"><a href="#cb85-13" aria-hidden="true" tabindex="-1"></a>      table_row_every_iters<span class="op">=</span><span class="dv">100000</span>, run_valid_every_iters<span class="op">=</span><span class="dv">25000</span>)</span>
<span id="cb85-14"><a href="#cb85-14" aria-hidden="true" tabindex="-1"></a>model.save_model(<span class="st">'t2s-base-nopreconv-cleaned.model'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="5" class="" max="5" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [5/5 1:09:45&lt;00:00]
    </div>
    

<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">samples</th>
<th data-quarto-table-cell-role="th">train</th>
<th data-quarto-table-cell-role="th">val</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>100000</td>
<td>2.11192</td>
<td>2.53749</td>
<td>07:11</td>
</tr>
<tr class="even">
<td>200000</td>
<td>1.55551</td>
<td>1.72807</td>
<td>14:22</td>
</tr>
<tr class="odd">
<td>300000</td>
<td>1.45162</td>
<td>1.62413</td>
<td>21:32</td>
</tr>
<tr class="even">
<td>400000</td>
<td>1.41284</td>
<td>1.56698</td>
<td>28:44</td>
</tr>
<tr class="odd">
<td>500000</td>
<td>1.37127</td>
<td>1.52728</td>
<td>35:56</td>
</tr>
<tr class="even">
<td>600000</td>
<td>1.31131</td>
<td>1.48980</td>
<td>43:08</td>
</tr>
<tr class="odd">
<td>700000</td>
<td>1.32659</td>
<td>1.46523</td>
<td>50:19</td>
</tr>
<tr class="even">
<td>800000</td>
<td>1.23844</td>
<td>1.43754</td>
<td>57:31</td>
</tr>
<tr class="odd">
<td>900000</td>
<td>1.21430</td>
<td>1.42486</td>
<td>1:04:42</td>
</tr>
<tr class="even">
<td>970240</td>
<td>1.21257</td>
<td>1.42089</td>
<td>1:09:45</td>
</tr>
</tbody>
</table>
<p>

    </p><div>
      <progress value="6064" class="" max="6064" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [6064/6064 13:56&lt;00:00 #194048/194040 loss: 1.213 / 1.421]
    </div>
    
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/root/workspace/spear-tts-pytorch/whisperspeech/train.py:63: UserWarning: Attempt to set non-positive xlim on a log-scaled axis will be ignored.
  loss_p.clear()
/root/workspace/spear-tts-pytorch/whisperspeech/train.py:66: UserWarning: Attempt to set non-positive xlim on a log-scaled axis will be ignored.
  loss_p.set_xlim(500, self.total_steps)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-61-output-5.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb87"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a><span class="co"># cleaned data</span></span>
<span id="cb87-2"><a href="#cb87-2" aria-hidden="true" tabindex="-1"></a>vq_name <span class="op">=</span> <span class="st">"base.en-2d-4096c-cosine32-padfix-premlp-premean-learnpos-5e-cleaned"</span></span>
<span id="cb87-3"><a href="#cb87-3" aria-hidden="true" tabindex="-1"></a>vqmodel <span class="op">=</span> RQBottleneckTransformer.load_model(local_filename<span class="op">=</span><span class="ss">f'vq-</span><span class="sc">{</span>vq_name<span class="sc">}</span><span class="ss">.model'</span>)</span>
<span id="cb87-4"><a href="#cb87-4" aria-hidden="true" tabindex="-1"></a>train_ds, val_ds <span class="op">=</span> load_datasets(<span class="st">'txts-large-6454-eqvad.feather'</span>, <span class="ss">f'stoks-</span><span class="sc">{</span>vq_name<span class="sc">}</span><span class="ss">.feather'</span>)</span>
<span id="cb87-5"><a href="#cb87-5" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> make_model(<span class="st">'base'</span>, dataset<span class="op">=</span>train_ds, ttoks_codes<span class="op">=</span><span class="dv">256</span>, stoks_width<span class="op">=</span><span class="dv">32</span>, tunables<span class="op">=</span>Tunables(eot_dropout_p<span class="op">=</span><span class="dv">0</span>)).cuda()</span>
<span id="cb87-6"><a href="#cb87-6" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad(): model.decoder.embedding.weight[:] <span class="op">=</span> vqmodel.rq.layers[<span class="dv">0</span>]._codebook.embed[<span class="dv">0</span>]</span>
<span id="cb87-7"><a href="#cb87-7" aria-hidden="true" tabindex="-1"></a>model.decoder.embedding.lr_scale <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb87-8"><a href="#cb87-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> m <span class="kw">in</span> [model.decoder.emb_to_hidden, model.decoder.hidden_to_emb]:</span>
<span id="cb87-9"><a href="#cb87-9" aria-hidden="true" tabindex="-1"></a>    m.lr_scale <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb87-10"><a href="#cb87-10" aria-hidden="true" tabindex="-1"></a>    std <span class="op">=</span> model.tunables.init_std</span>
<span id="cb87-11"><a href="#cb87-11" aria-hidden="true" tabindex="-1"></a>    torch.nn.init.trunc_normal_(m.weight, std<span class="op">=</span>std, a<span class="op">=-</span><span class="dv">3</span><span class="op">*</span>std, b<span class="op">=</span><span class="dv">3</span><span class="op">*</span>std)</span>
<span id="cb87-12"><a href="#cb87-12" aria-hidden="true" tabindex="-1"></a>train(<span class="st">"tsar-wx"</span>, model, train_ds, val_ds, half<span class="op">=</span><span class="va">True</span>, bs<span class="op">=</span><span class="dv">32</span>, lr<span class="op">=</span>model.tunables.lr0, epochs<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb87-13"><a href="#cb87-13" aria-hidden="true" tabindex="-1"></a>      warmup_steps<span class="op">=</span>model.tunables.warmup_steps, weight_decay<span class="op">=</span>model.tunables.weight_decay, clip_gradient_norm<span class="op">=</span>model.tunables.clip_gradient_norm,</span>
<span id="cb87-14"><a href="#cb87-14" aria-hidden="true" tabindex="-1"></a>      table_row_every_iters<span class="op">=</span><span class="dv">100000</span>, run_valid_every_iters<span class="op">=</span><span class="dv">25000</span>)</span>
<span id="cb87-15"><a href="#cb87-15" aria-hidden="true" tabindex="-1"></a>model.save_model(<span class="st">'t2s-base-premean-cleaned-eqvad.model'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="5" class="" max="5" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [5/5 1:53:19&lt;00:00]
    </div>
    

<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">samples</th>
<th data-quarto-table-cell-role="th">train</th>
<th data-quarto-table-cell-role="th">val</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>100000</td>
<td>1.39675</td>
<td>1.01765</td>
<td>07:08</td>
</tr>
<tr class="even">
<td>200000</td>
<td>0.99473</td>
<td>0.70335</td>
<td>14:15</td>
</tr>
<tr class="odd">
<td>300000</td>
<td>0.98095</td>
<td>0.65620</td>
<td>21:23</td>
</tr>
<tr class="even">
<td>400000</td>
<td>0.91941</td>
<td>0.63601</td>
<td>28:31</td>
</tr>
<tr class="odd">
<td>500000</td>
<td>0.89299</td>
<td>0.62238</td>
<td>35:38</td>
</tr>
<tr class="even">
<td>600000</td>
<td>0.91047</td>
<td>0.61567</td>
<td>42:45</td>
</tr>
<tr class="odd">
<td>700000</td>
<td>0.84376</td>
<td>0.60385</td>
<td>49:54</td>
</tr>
<tr class="even">
<td>800000</td>
<td>0.83167</td>
<td>0.59419</td>
<td>57:02</td>
</tr>
<tr class="odd">
<td>900000</td>
<td>0.85216</td>
<td>0.58662</td>
<td>1:04:11</td>
</tr>
<tr class="even">
<td>1000000</td>
<td>0.80380</td>
<td>0.57944</td>
<td>1:11:20</td>
</tr>
<tr class="odd">
<td>1100000</td>
<td>0.75631</td>
<td>0.57185</td>
<td>1:18:28</td>
</tr>
<tr class="even">
<td>1200000</td>
<td>0.85797</td>
<td>0.56436</td>
<td>1:25:36</td>
</tr>
<tr class="odd">
<td>1300000</td>
<td>0.77849</td>
<td>0.55731</td>
<td>1:32:45</td>
</tr>
<tr class="even">
<td>1400000</td>
<td>0.78297</td>
<td>0.55378</td>
<td>1:39:54</td>
</tr>
<tr class="odd">
<td>1500000</td>
<td>0.77391</td>
<td>0.55065</td>
<td>1:47:02</td>
</tr>
<tr class="even">
<td>1588160</td>
<td>0.79618</td>
<td>0.54950</td>
<td>1:53:19</td>
</tr>
</tbody>
</table>
<p>

    </p><div>
      <progress value="9926" class="" max="9926" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [9926/9926 22:40&lt;00:00 #317632/317625 loss: 0.796 / 0.549]
    </div>
    
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/root/workspace/spear-tts-pytorch/whisperspeech/train.py:63: UserWarning: Attempt to set non-positive xlim on a log-scaled axis will be ignored.
  loss_p.clear()
/root/workspace/spear-tts-pytorch/whisperspeech/train.py:66: UserWarning: Attempt to set non-positive xlim on a log-scaled axis will be ignored.
  loss_p.set_xlim(500, self.total_steps)
IOPub message rate exceeded.
The notebook server will temporarily stop sending output
to the client in order to avoid crashing it.
To change this limit, set the config variable
`--NotebookApp.iopub_msg_rate_limit`.

Current values:
NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
NotebookApp.rate_limit_window=3.0 (secs)
</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-62-output-5.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb89"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a><span class="co"># cleaned data</span></span>
<span id="cb89-2"><a href="#cb89-2" aria-hidden="true" tabindex="-1"></a>vqmodel <span class="op">=</span> RQBottleneckTransformer.load_model(local_filename<span class="op">=</span><span class="st">'vq-base.en-2d-4096c-cosine32-padfix-premlp-learnpos-5e.model'</span>)</span>
<span id="cb89-3"><a href="#cb89-3" aria-hidden="true" tabindex="-1"></a>train_ds, val_ds <span class="op">=</span> load_datasets(<span class="st">'txts-large-6454.feather'</span>, <span class="st">'stoks-base.en-2d-4096c-cosine32-padfix-premlp-learnpos-5e.feather'</span>)</span>
<span id="cb89-4"><a href="#cb89-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> make_model(<span class="st">'tiny'</span>, dataset<span class="op">=</span>train_ds, ttoks_codes<span class="op">=</span><span class="dv">256</span>, stoks_width<span class="op">=</span><span class="dv">32</span>, tunables<span class="op">=</span>Tunables(eot_dropout_p<span class="op">=</span><span class="dv">0</span>)).cuda()</span>
<span id="cb89-5"><a href="#cb89-5" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad(): model.decoder.embedding.weight[:] <span class="op">=</span> vqmodel.rq.layers[<span class="dv">0</span>]._codebook.embed[<span class="dv">0</span>]</span>
<span id="cb89-6"><a href="#cb89-6" aria-hidden="true" tabindex="-1"></a>model.decoder.embedding.lr_scale <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb89-7"><a href="#cb89-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> m <span class="kw">in</span> [model.decoder.emb_to_hidden, model.decoder.hidden_to_emb]:</span>
<span id="cb89-8"><a href="#cb89-8" aria-hidden="true" tabindex="-1"></a>    m.lr_scale <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb89-9"><a href="#cb89-9" aria-hidden="true" tabindex="-1"></a>    std <span class="op">=</span> model.tunables.init_std</span>
<span id="cb89-10"><a href="#cb89-10" aria-hidden="true" tabindex="-1"></a>    torch.nn.init.trunc_normal_(m.weight, std<span class="op">=</span>std, a<span class="op">=-</span><span class="dv">3</span><span class="op">*</span>std, b<span class="op">=</span><span class="dv">3</span><span class="op">*</span>std)</span>
<span id="cb89-11"><a href="#cb89-11" aria-hidden="true" tabindex="-1"></a>train(<span class="st">"tsar-wx"</span>, model, train_ds, val_ds, half<span class="op">=</span><span class="va">True</span>, bs<span class="op">=</span><span class="dv">32</span>, lr<span class="op">=</span>model.tunables.lr0, epochs<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb89-12"><a href="#cb89-12" aria-hidden="true" tabindex="-1"></a>      warmup_steps<span class="op">=</span>model.tunables.warmup_steps, weight_decay<span class="op">=</span>model.tunables.weight_decay, clip_gradient_norm<span class="op">=</span>model.tunables.clip_gradient_norm,</span>
<span id="cb89-13"><a href="#cb89-13" aria-hidden="true" tabindex="-1"></a>      table_row_every_iters<span class="op">=</span><span class="dv">100000</span>, run_valid_every_iters<span class="op">=</span><span class="dv">25000</span>)</span>
<span id="cb89-14"><a href="#cb89-14" aria-hidden="true" tabindex="-1"></a>model.save_model(<span class="st">'t2s-tiny-nocleanvq.model'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="0" class="" max="1" style="width:300px; height:20px; vertical-align: middle;"></progress>
      0.00% [0/1 00:00&lt;?]
    </div>
    

<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">samples</th>
<th data-quarto-table-cell-role="th">train</th>
<th data-quarto-table-cell-role="th">val</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>26976</td>
<td>2.87742</td>
<td>2.94360</td>
<td>01:05</td>
</tr>
</tbody>
</table>
<p>

    </p><div>
      <progress value="842" class="" max="6064" style="width:300px; height:20px; vertical-align: middle;"></progress>
      13.89% [842/6064 01:05&lt;06:46 #26944/194040 loss: 2.843 / 2.944]
    </div>
    
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/root/workspace/spear-tts-pytorch/whisperspeech/train.py:63: UserWarning: Attempt to set non-positive xlim on a log-scaled axis will be ignored.
  loss_p.clear()
/root/workspace/spear-tts-pytorch/whisperspeech/train.py:66: UserWarning: Attempt to set non-positive xlim on a log-scaled axis will be ignored.
  loss_p.set_xlim(500, self.total_steps)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-63-output-5.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb91"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="co"># reuse the VQ stoks padding token</span></span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a>train_ds, val_ds <span class="op">=</span> load_datasets(<span class="st">'txts-large-6454-cleaned.feather'</span>, <span class="st">'stoks-base.en-2d-4096c-cosine32-padfix-premlp-learnpos-5e.feather'</span>)</span>
<span id="cb91-3"><a href="#cb91-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> make_model(<span class="st">'base'</span>, dataset<span class="op">=</span>train_ds, ttoks_codes<span class="op">=</span><span class="dv">256</span>, stoks_width<span class="op">=</span><span class="dv">32</span>).cuda()</span>
<span id="cb91-4"><a href="#cb91-4" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad(): model.decoder.embedding.weight[:] <span class="op">=</span> vqmodel.rq.layers[<span class="dv">0</span>]._codebook.embed[<span class="dv">0</span>]</span>
<span id="cb91-5"><a href="#cb91-5" aria-hidden="true" tabindex="-1"></a>model.decoder.embedding.lr_scale <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb91-6"><a href="#cb91-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> m <span class="kw">in</span> [model.decoder.emb_to_hidden, model.decoder.hidden_to_emb]:</span>
<span id="cb91-7"><a href="#cb91-7" aria-hidden="true" tabindex="-1"></a>    m.lr_scale <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb91-8"><a href="#cb91-8" aria-hidden="true" tabindex="-1"></a>    std <span class="op">=</span> model.tunables.init_std</span>
<span id="cb91-9"><a href="#cb91-9" aria-hidden="true" tabindex="-1"></a>    torch.nn.init.trunc_normal_(m.weight, std<span class="op">=</span>std, a<span class="op">=-</span><span class="dv">3</span><span class="op">*</span>std, b<span class="op">=</span><span class="dv">3</span><span class="op">*</span>std)</span>
<span id="cb91-10"><a href="#cb91-10" aria-hidden="true" tabindex="-1"></a>train(<span class="st">"tsar-wx"</span>, model, train_ds, val_ds, half<span class="op">=</span><span class="va">True</span>, bs<span class="op">=</span><span class="dv">32</span>, lr<span class="op">=</span>model.tunables.lr0, epochs<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb91-11"><a href="#cb91-11" aria-hidden="true" tabindex="-1"></a>      warmup_steps<span class="op">=</span>model.tunables.warmup_steps, weight_decay<span class="op">=</span>model.tunables.weight_decay, clip_gradient_norm<span class="op">=</span>model.tunables.clip_gradient_norm,</span>
<span id="cb91-12"><a href="#cb91-12" aria-hidden="true" tabindex="-1"></a>      table_row_every_iters<span class="op">=</span><span class="dv">100000</span>, run_valid_every_iters<span class="op">=</span><span class="dv">25000</span>)</span>
<span id="cb91-13"><a href="#cb91-13" aria-hidden="true" tabindex="-1"></a>model.save_model(<span class="st">'t2s-chr-base.en-2d-4096c-cosine32-padfix-premlp-learnpos-5e-large-6454-cleaned.model'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="5" class="" max="5" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [5/5 1:07:10&lt;00:00]
    </div>
    

<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">samples</th>
<th data-quarto-table-cell-role="th">train</th>
<th data-quarto-table-cell-role="th">val</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>100000</td>
<td>2.05248</td>
<td>2.78820</td>
<td>07:10</td>
</tr>
<tr class="even">
<td>200000</td>
<td>1.52021</td>
<td>1.95092</td>
<td>14:20</td>
</tr>
<tr class="odd">
<td>300000</td>
<td>1.45599</td>
<td>1.82633</td>
<td>21:30</td>
</tr>
<tr class="even">
<td>400000</td>
<td>1.39701</td>
<td>1.77782</td>
<td>28:40</td>
</tr>
<tr class="odd">
<td>500000</td>
<td>1.33500</td>
<td>1.72368</td>
<td>35:49</td>
</tr>
<tr class="even">
<td>600000</td>
<td>1.33470</td>
<td>1.69579</td>
<td>43:00</td>
</tr>
<tr class="odd">
<td>700000</td>
<td>1.26856</td>
<td>1.66998</td>
<td>50:11</td>
</tr>
<tr class="even">
<td>800000</td>
<td>1.23700</td>
<td>1.64218</td>
<td>57:22</td>
</tr>
<tr class="odd">
<td>900000</td>
<td>1.24926</td>
<td>1.62649</td>
<td>1:04:33</td>
</tr>
<tr class="even">
<td>936480</td>
<td>1.19744</td>
<td>1.62555</td>
<td>1:07:10</td>
</tr>
</tbody>
</table>
<p>

    </p><div>
      <progress value="5853" class="" max="5853" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [5853/5853 13:27&lt;00:00 #187296/187286 loss: 1.197 / 1.626]
    </div>
    
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/root/workspace/spear-tts-pytorch/whisperspeech/train.py:63: UserWarning: Attempt to set non-positive xlim on a log-scaled axis will be ignored.
  loss_p.clear()
/root/workspace/spear-tts-pytorch/whisperspeech/train.py:66: UserWarning: Attempt to set non-positive xlim on a log-scaled axis will be ignored.
  loss_p.set_xlim(500, self.total_steps)
IOPub message rate exceeded.
The notebook server will temporarily stop sending output
to the client in order to avoid crashing it.
To change this limit, set the config variable
`--NotebookApp.iopub_msg_rate_limit`.

Current values:
NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
NotebookApp.rate_limit_window=3.0 (secs)
</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-64-output-5.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb93"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a><span class="co"># reuse the VQ stoks padding token</span></span>
<span id="cb93-2"><a href="#cb93-2" aria-hidden="true" tabindex="-1"></a>train_ds, val_ds <span class="op">=</span> load_datasets(<span class="st">'txts-large-6454-cleaned.feather'</span>, <span class="st">'stoks-base.en-2d-4096c-cosine32-padfix-premlp-learnpos-5e.feather'</span>)</span>
<span id="cb93-3"><a href="#cb93-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> make_model(<span class="st">'base'</span>, dataset<span class="op">=</span>train_ds, ttoks_codes<span class="op">=</span><span class="dv">256</span>, stoks_width<span class="op">=</span><span class="dv">32</span>).cuda()</span>
<span id="cb93-4"><a href="#cb93-4" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad(): model.decoder.embedding.weight[:] <span class="op">=</span> vqmodel.rq.layers[<span class="dv">0</span>]._codebook.embed[<span class="dv">0</span>]</span>
<span id="cb93-5"><a href="#cb93-5" aria-hidden="true" tabindex="-1"></a>model.decoder.embedding.lr_scale <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb93-6"><a href="#cb93-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> m <span class="kw">in</span> [model.decoder.emb_to_hidden, model.decoder.hidden_to_emb]:</span>
<span id="cb93-7"><a href="#cb93-7" aria-hidden="true" tabindex="-1"></a>    m.lr_scale <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb93-8"><a href="#cb93-8" aria-hidden="true" tabindex="-1"></a>    std <span class="op">=</span> model.tunables.init_std</span>
<span id="cb93-9"><a href="#cb93-9" aria-hidden="true" tabindex="-1"></a>    torch.nn.init.trunc_normal_(m.weight, std<span class="op">=</span>std, a<span class="op">=-</span><span class="dv">3</span><span class="op">*</span>std, b<span class="op">=</span><span class="dv">3</span><span class="op">*</span>std)</span>
<span id="cb93-10"><a href="#cb93-10" aria-hidden="true" tabindex="-1"></a>train(<span class="st">"tsar-wx"</span>, model, train_ds, val_ds, half<span class="op">=</span><span class="va">True</span>, bs<span class="op">=</span><span class="dv">32</span>, lr<span class="op">=</span>model.tunables.lr0, epochs<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb93-11"><a href="#cb93-11" aria-hidden="true" tabindex="-1"></a>      warmup_steps<span class="op">=</span>model.tunables.warmup_steps, weight_decay<span class="op">=</span>model.tunables.weight_decay, clip_gradient_norm<span class="op">=</span>model.tunables.clip_gradient_norm,</span>
<span id="cb93-12"><a href="#cb93-12" aria-hidden="true" tabindex="-1"></a>      table_row_every_iters<span class="op">=</span><span class="dv">100000</span>, run_valid_every_iters<span class="op">=</span><span class="dv">25000</span>)</span>
<span id="cb93-13"><a href="#cb93-13" aria-hidden="true" tabindex="-1"></a>model.save_model(<span class="st">'t2s-chr-eot10x-base.en-2d-4096c-cosine32-padfix-premlp-learnpos-5e-large-6454-cleaned.model'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="5" class="" max="5" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [5/5 1:06:52&lt;00:00]
    </div>
    

<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">samples</th>
<th data-quarto-table-cell-role="th">train</th>
<th data-quarto-table-cell-role="th">val</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>100000</td>
<td>2.18693</td>
<td>2.79553</td>
<td>07:09</td>
</tr>
<tr class="even">
<td>200000</td>
<td>1.72759</td>
<td>2.21211</td>
<td>14:17</td>
</tr>
<tr class="odd">
<td>300000</td>
<td>1.58026</td>
<td>2.02650</td>
<td>21:25</td>
</tr>
<tr class="even">
<td>400000</td>
<td>1.50245</td>
<td>1.91226</td>
<td>28:32</td>
</tr>
<tr class="odd">
<td>500000</td>
<td>1.46347</td>
<td>1.84637</td>
<td>35:40</td>
</tr>
<tr class="even">
<td>600000</td>
<td>1.41378</td>
<td>1.78844</td>
<td>42:49</td>
</tr>
<tr class="odd">
<td>700000</td>
<td>1.36574</td>
<td>1.75137</td>
<td>49:59</td>
</tr>
<tr class="even">
<td>800000</td>
<td>1.32156</td>
<td>1.73190</td>
<td>57:07</td>
</tr>
<tr class="odd">
<td>900000</td>
<td>1.30705</td>
<td>1.71549</td>
<td>1:04:16</td>
</tr>
<tr class="even">
<td>936480</td>
<td>1.25838</td>
<td>1.71270</td>
<td>1:06:52</td>
</tr>
</tbody>
</table>
<p>

    </p><div>
      <progress value="5853" class="" max="5853" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [5853/5853 13:22&lt;00:00 #187296/187286 loss: 1.258 / 1.713]
    </div>
    
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/root/workspace/spear-tts-pytorch/whisperspeech/train.py:63: UserWarning: Attempt to set non-positive xlim on a log-scaled axis will be ignored.
  loss_p.clear()
/root/workspace/spear-tts-pytorch/whisperspeech/train.py:66: UserWarning: Attempt to set non-positive xlim on a log-scaled axis will be ignored.
  loss_p.set_xlim(500, self.total_steps)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-65-output-5.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="optimize-the-sampling-parameters" class="level2">
<h2 class="anchored" data-anchor-id="optimize-the-sampling-parameters">Optimize the sampling parameters</h2>
<p>Few things to keep in mind:</p>
<ul>
<li>decoding with quantized Whisper is not the ultimate goal (and quantized Whisper itself has an average WER of &gt; 6%)</li>
<li>the dots on the plots don’t show perfect samples (WER=0%) because of logscale, the green line average line does</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb95"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a>vqmodel <span class="op">=</span> vq_stoks.RQBottleneckTransformer.load_model(local_filename<span class="op">=</span><span class="st">'vqmodel-512c-dim64-4e-hyptuned-32gpu.model'</span>).cuda()</span>
<span id="cb95-2"><a href="#cb95-2" aria-hidden="true" tabindex="-1"></a>t2s <span class="op">=</span> TSARTransformer.load_model(local_filename<span class="op">=</span><span class="st">'t2s-chr-base-base.en-2d-512c-dim64-deccps.model'</span>).cuda()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb96"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> search_infer_hyp(T_range<span class="op">=</span>(<span class="fl">.1</span>,<span class="dv">10</span>), top_k_range<span class="op">=</span>(<span class="dv">1</span>,<span class="dv">128</span>)):</span>
<span id="cb96-2"><a href="#cb96-2" aria-hidden="true" tabindex="-1"></a>    stats <span class="op">=</span> WERStats()</span>
<span id="cb96-3"><a href="#cb96-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> snd, gt_text <span class="kw">in</span> progress_bar(librispeech_data(<span class="st">'/data/LibriSpeech/test-clean'</span>), total<span class="op">=</span><span class="dv">1000</span>):</span>
<span id="cb96-4"><a href="#cb96-4" aria-hidden="true" tabindex="-1"></a>        T <span class="op">=</span> <span class="dv">10</span><span class="op">**</span>rand(<span class="op">*</span>np.log10(T_range))</span>
<span id="cb96-5"><a href="#cb96-5" aria-hidden="true" tabindex="-1"></a>        top_k <span class="op">=</span> <span class="bu">round</span>(<span class="dv">10</span><span class="op">**</span>rand(<span class="op">*</span>np.log10([top_k_range[<span class="dv">0</span>]<span class="op">-</span><span class="fl">.5</span>,top_k_range[<span class="dv">1</span>]<span class="op">+</span><span class="fl">.5</span>])))</span>
<span id="cb96-6"><a href="#cb96-6" aria-hidden="true" tabindex="-1"></a>        stoks <span class="op">=</span> t2s.generate(gt_text.lower(), show_progress_bar<span class="op">=</span><span class="va">False</span>, top_k<span class="op">=</span>top_k, T<span class="op">=</span>T)</span>
<span id="cb96-7"><a href="#cb96-7" aria-hidden="true" tabindex="-1"></a>        text <span class="op">=</span> vqmodel.decode_text(stoks)[<span class="dv">0</span>].text</span>
<span id="cb96-8"><a href="#cb96-8" aria-hidden="true" tabindex="-1"></a>        stats.push_sample(snd, gt_text, text)</span>
<span id="cb96-9"><a href="#cb96-9" aria-hidden="true" tabindex="-1"></a>        stats.push(top_k <span class="op">=</span> top_k, T <span class="op">=</span> T)</span>
<span id="cb96-10"><a href="#cb96-10" aria-hidden="true" tabindex="-1"></a>    stats <span class="op">=</span> stats.df().sort_values(<span class="st">'wer'</span>)</span>
<span id="cb96-11"><a href="#cb96-11" aria-hidden="true" tabindex="-1"></a>    ax <span class="op">=</span> stats.plot.scatter(<span class="st">'top_k'</span>, <span class="st">'wer'</span>, logx<span class="op">=</span><span class="va">True</span>, logy<span class="op">=</span><span class="va">True</span>, alpha<span class="op">=</span><span class="fl">.5</span>)</span>
<span id="cb96-12"><a href="#cb96-12" aria-hidden="true" tabindex="-1"></a>    ax.plot(stats.groupby(<span class="st">'top_k'</span>)[<span class="st">'wer'</span>].mean(), c<span class="op">=</span><span class="st">'green'</span>, alpha<span class="op">=</span><span class="fl">.3</span>)</span>
<span id="cb96-13"><a href="#cb96-13" aria-hidden="true" tabindex="-1"></a>    stats.plot.scatter(<span class="st">'T'</span>, <span class="st">'wer'</span>, logx<span class="op">=</span><span class="va">True</span>, logy<span class="op">=</span><span class="va">True</span>, alpha<span class="op">=</span><span class="fl">.5</span>)</span>
<span id="cb96-14"><a href="#cb96-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> stats</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb97"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb97-1"><a href="#cb97-1" aria-hidden="true" tabindex="-1"></a>search_infer_hyp()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="1000" class="" max="1000" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [1000/1000 11:34&lt;00:00]
    </div>
    
</div>
<div class="cell-output cell-output-display">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">secs</th>
<th data-quarto-table-cell-role="th">idx</th>
<th data-quarto-table-cell-role="th">gt_text</th>
<th data-quarto-table-cell-role="th">text</th>
<th data-quarto-table-cell-role="th">wer</th>
<th data-quarto-table-cell-role="th">mer</th>
<th data-quarto-table-cell-role="th">wil</th>
<th data-quarto-table-cell-role="th">wip</th>
<th data-quarto-table-cell-role="th">top_k</th>
<th data-quarto-table-cell-role="th">T</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">315</td>
<td>8.510</td>
<td>None</td>
<td>NO ONE SAW HIM DO THIS FOR ALL WERE LOOKING AT...</td>
<td>No one saw him do this, for all were looking a...</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>1.000000</td>
<td>1</td>
<td>0.108978</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">445</td>
<td>5.645</td>
<td>None</td>
<td>FINALLY THE ONE PARTY WENT OFF EXULTING AND TH...</td>
<td>Finally the one party went off exulting, and t...</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>1.000000</td>
<td>15</td>
<td>0.504203</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">451</td>
<td>2.665</td>
<td>None</td>
<td>SHE FOUND THE DOOR BUT IT WAS LOCKED OUTSIDE</td>
<td>She found the door but it was locked outside.</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>1.000000</td>
<td>6</td>
<td>3.195216</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">127</td>
<td>6.270</td>
<td>None</td>
<td>THE GOLDEN STAR OF TINSEL WAS STILL ON THE TOP...</td>
<td>The golden star of tinsel was still on the top...</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>1.000000</td>
<td>95</td>
<td>0.233646</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">711</td>
<td>2.690</td>
<td>None</td>
<td>BY REASON AND AFFECTION</td>
<td>by reason and affection.</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>1.000000</td>
<td>2</td>
<td>0.599798</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">482</td>
<td>7.605</td>
<td>None</td>
<td>HE PASSED THROUGH HENLEY SAINT ALBANS AND CAME...</td>
<td>He's a successful cook and he's not going to b...</td>
<td>9.647059</td>
<td>0.987952</td>
<td>0.998583</td>
<td>0.001417</td>
<td>63</td>
<td>6.728842</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">387</td>
<td>2.735</td>
<td>None</td>
<td>A ROUTE SLIGHTLY LESS DIRECT THAT'S ALL</td>
<td>I am right, right, right, right, right, right,...</td>
<td>14.125000</td>
<td>1.000000</td>
<td>1.000000</td>
<td>0.000000</td>
<td>49</td>
<td>9.033729</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">89</td>
<td>4.000</td>
<td>None</td>
<td>CRIED THE YOUNG LADIES AND THEY QUICKLY PUT OU...</td>
<td>Grandma, you're a real man. You're a significa...</td>
<td>14.545455</td>
<td>1.000000</td>
<td>1.000000</td>
<td>0.000000</td>
<td>51</td>
<td>5.997146</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">598</td>
<td>2.900</td>
<td>None</td>
<td>EACH OF US IS LASHED TO SOME PART OF THE RAFT</td>
<td>He's not going to die on gas. He's not going t...</td>
<td>14.636364</td>
<td>0.987730</td>
<td>0.997769</td>
<td>0.002231</td>
<td>113</td>
<td>7.302803</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">226</td>
<td>6.750</td>
<td>None</td>
<td>HE CONTINUED HIS PRETENDED SEARCH AND TO GIVE ...</td>
<td>He can see that he can see that he can see tha...</td>
<td>14.800000</td>
<td>0.995516</td>
<td>0.999701</td>
<td>0.000299</td>
<td>1</td>
<td>0.294595</td>
</tr>
</tbody>
</table>

<p>1000 rows × 10 columns</p>
</div>
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-68-output-4.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-68-output-5.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb98"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a>stats <span class="op">=</span> search_infer_hyp(T_range<span class="op">=</span>(<span class="fl">.5</span>,<span class="dv">1</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="1000" class="" max="1000" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [1000/1000 10:59&lt;00:00]
    </div>
    
</div>
<div class="cell-output cell-output-display">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">secs</th>
<th data-quarto-table-cell-role="th">idx</th>
<th data-quarto-table-cell-role="th">gt_text</th>
<th data-quarto-table-cell-role="th">text</th>
<th data-quarto-table-cell-role="th">wer</th>
<th data-quarto-table-cell-role="th">mer</th>
<th data-quarto-table-cell-role="th">wil</th>
<th data-quarto-table-cell-role="th">wip</th>
<th data-quarto-table-cell-role="th">top_k</th>
<th data-quarto-table-cell-role="th">T</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>8.230</td>
<td>None</td>
<td>AND OFTEN HAS MY MOTHER SAID WHILE ON HER LAP ...</td>
<td>And often has my mother said while on her lap,...</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>1.000000</td>
<td>49</td>
<td>0.933901</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">268</td>
<td>2.825</td>
<td>None</td>
<td>SHE'S GOING TO PUT THE IRONING THINGS AWAY</td>
<td>She's going to put the ironing things away.</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>1.000000</td>
<td>3</td>
<td>0.848717</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">267</td>
<td>3.595</td>
<td>None</td>
<td>COLD IS IT MY DARLING BLESS YOUR SWEET FACE</td>
<td>Cold is it my darling bless your sweet face?</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>1.000000</td>
<td>3</td>
<td>0.691180</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">620</td>
<td>4.730</td>
<td>None</td>
<td>THE SHADOW OF THE RAFT WAS CLEARLY OUTLINED UP...</td>
<td>The shadow of the raft was clearly outlined up...</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>1.000000</td>
<td>8</td>
<td>0.729119</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">623</td>
<td>7.000</td>
<td>None</td>
<td>THESE THOUGHTS AGITATED ME ALL DAY AND MY IMAG...</td>
<td>These thoughts agitated me all day, and my ima...</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>1.000000</td>
<td>113</td>
<td>0.880830</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">393</td>
<td>5.980</td>
<td>None</td>
<td>I LEFT INSTRUCTIONS FOR SHIPPING MY CONTAINERS...</td>
<td>And if you are not, you can see that the video...</td>
<td>7.625000</td>
<td>0.983871</td>
<td>0.997984</td>
<td>0.002016</td>
<td>1</td>
<td>0.519047</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">322</td>
<td>3.200</td>
<td>None</td>
<td>I NOW USE THEM AS ORNAMENTAL STATUARY IN MY GA...</td>
<td>Now you know, I'm not going to be able to do t...</td>
<td>9.200000</td>
<td>0.989247</td>
<td>0.998925</td>
<td>0.001075</td>
<td>1</td>
<td>0.907901</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">676</td>
<td>4.280</td>
<td>None</td>
<td>THAT IS A VERY FINE CAP YOU HAVE HE SAID</td>
<td>That is a very, very, very, very, very, very, ...</td>
<td>10.900000</td>
<td>0.964602</td>
<td>0.985841</td>
<td>0.014159</td>
<td>1</td>
<td>0.594969</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">592</td>
<td>1.805</td>
<td>None</td>
<td>HANS STIRS NOT</td>
<td>hands, stirs, stirs, stirs, stirs, stirs, stir...</td>
<td>24.666667</td>
<td>0.986667</td>
<td>0.995556</td>
<td>0.004444</td>
<td>29</td>
<td>0.569005</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">693</td>
<td>2.110</td>
<td>None</td>
<td>I AM VERY GLAD</td>
<td>I am very happy. I am very happy. I am very ha...</td>
<td>28.250000</td>
<td>0.974138</td>
<td>0.980603</td>
<td>0.019397</td>
<td>19</td>
<td>0.974444</td>
</tr>
</tbody>
</table>

<p>1000 rows × 10 columns</p>
</div>
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-69-output-4.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-69-output-5.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb99"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb99-1"><a href="#cb99-1" aria-hidden="true" tabindex="-1"></a>stats <span class="op">=</span> search_infer_hyp(T_range<span class="op">=</span>(<span class="fl">.5</span>,<span class="dv">1</span>), top_k_range<span class="op">=</span>(<span class="dv">3</span>,<span class="dv">128</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="1000" class="" max="1000" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [1000/1000 10:40&lt;00:00]
    </div>
    
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-70-output-3.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-70-output-4.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb100"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb100-1"><a href="#cb100-1" aria-hidden="true" tabindex="-1"></a>stats <span class="op">=</span> search_infer_hyp(T_range<span class="op">=</span>(<span class="fl">.7</span>,<span class="dv">1</span>), top_k_range<span class="op">=</span>(<span class="dv">3</span>,<span class="dv">64</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="1000" class="" max="1000" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [1000/1000 10:45&lt;00:00]
    </div>
    
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-71-output-3.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-71-output-4.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb101"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb101-1"><a href="#cb101-1" aria-hidden="true" tabindex="-1"></a>stats <span class="op">=</span> search_infer_hyp(T_range<span class="op">=</span>(<span class="fl">.7</span>,<span class="dv">1</span>), top_k_range<span class="op">=</span>(<span class="dv">3</span>,<span class="dv">10</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="1000" class="" max="1000" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [1000/1000 10:52&lt;00:00]
    </div>
    
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-72-output-3.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-72-output-4.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb102"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb102-1"><a href="#cb102-1" aria-hidden="true" tabindex="-1"></a>stats <span class="op">=</span> search_infer_hyp(T_range<span class="op">=</span>(<span class="fl">.7</span>,<span class="dv">1</span>), top_k_range<span class="op">=</span>(<span class="dv">8</span>,<span class="dv">8</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="1000" class="" max="1000" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [1000/1000 10:46&lt;00:00]
    </div>
    
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-73-output-3.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-73-output-4.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb103"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb103-1"><a href="#cb103-1" aria-hidden="true" tabindex="-1"></a>stats.plot.scatter(<span class="st">'secs'</span>, <span class="st">'wer'</span>, logx<span class="op">=</span><span class="va">True</span>, logy<span class="op">=</span><span class="va">True</span>, alpha<span class="op">=</span><span class="fl">.5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>&lt;Axes: xlabel='secs', ylabel='wer'&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="5B. Text to semantic token modeling_files/figure-html/cell-74-output-2.png" class="img-fluid"></p>
</div>
</div>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>